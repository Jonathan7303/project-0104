{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 實驗一：房價預測模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/taipeitechmmslab/MMSLAB-TF2/blob/master/Lab2.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "    \n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/taipeitechmmslab/MMSLAB-TF2/blob/master/Lab2.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import必要套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下載 House Sales in King County, USA 資料集\n",
    "\n",
    "https://www.kaggle.com/harlfoxem/housesalesprediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 數據讀取並分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21613, 21)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"kc_house_data.csv\")\n",
    "# 顯示dataset的形狀，共21613比資料，每一比資料有21種不同資訊。\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000  221900.0         3       1.00         1180   \n",
       "1  6414100192  20141209T000000  538000.0         3       2.25         2570   \n",
       "2  5631500400  20150225T000000  180000.0         2       1.00          770   \n",
       "3  2487200875  20141209T000000  604000.0         4       3.00         1960   \n",
       "4  1954400510  20150218T000000  510000.0         3       2.00         1680   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view  condition  grade  sqft_above  \\\n",
       "0      5650     1.0           0     0          3      7        1180   \n",
       "1      7242     2.0           0     0          3      7        2170   \n",
       "2     10000     1.0           0     0          3      6         770   \n",
       "3      5000     1.0           0     0          5      7        1050   \n",
       "4      8080     1.0           0     0          3      8        1680   \n",
       "\n",
       "   sqft_basement  yr_built  yr_renovated  zipcode      lat     long  \\\n",
       "0              0      1955             0    98178  47.5112 -122.257   \n",
       "1            400      1951          1991    98125  47.7210 -122.319   \n",
       "2              0      1933             0    98028  47.7379 -122.233   \n",
       "3            910      1965             0    98136  47.5208 -122.393   \n",
       "4              0      1987             0    98074  47.6168 -122.045   \n",
       "\n",
       "   sqft_living15  sqft_lot15  \n",
       "0           1340        5650  \n",
       "1           1690        7639  \n",
       "2           2720        8062  \n",
       "3           1360        5000  \n",
       "4           1800        7503  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 將顯示列數設定為25，不然會有部份資料無法顯示\n",
    "pd.options.display.max_columns = 25\n",
    "# head 會顯示前五行的數據\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各個數據的簡寫分別代表下面意思：\n",
    "- date：房屋出售日期。\n",
    "- price：房屋價格（目標）。\n",
    "- bedrooms：臥室數量。\n",
    "- bathrooms：浴室數量。\n",
    "- sqft_living：居住的坪數（平方英尺）。\n",
    "- sqft_lot：實際的坪數（平方英尺）。\n",
    "- floors：房屋總共樓層。\n",
    "- waterfront：海景房。\n",
    "- view：房屋是否看過。\n",
    "- condition：整體條件有多好。\n",
    "- grade：房屋的整體等級（根據King County評分系統）。\n",
    "- sqft_above：除了地下室外的坪數（平方英尺）。\n",
    "- sqft_basement：地下室的坪數（平方英尺）。\n",
    "- yr_built：房屋建造時間。\n",
    "- yr_renovated：何時重新裝修過（一些沒重新裝修過或是裝修紀錄沒被記錄到的數值都為0）。\n",
    "- zipcode：郵政編碼。\n",
    "- lat：緯度座標。\n",
    "- long：經度座標。\n",
    "- sqft_living15：2015年紀錄的居住坪數（可能是翻新的原因導致sqft_living15與sqft_living不同）。\n",
    "- sqft_lot15：2015年紀錄的實際坪數（可能是翻新的原因導致sqft_lot15與sqft_lot不同）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 檢查資料的型態\n",
    "\n",
    "資料型態總共有五種：object(string),booleab, integer, float and categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                 int64\n",
       "date              object\n",
       "price            float64\n",
       "bedrooms           int64\n",
       "bathrooms        float64\n",
       "sqft_living        int64\n",
       "sqft_lot           int64\n",
       "floors           float64\n",
       "waterfront         int64\n",
       "view               int64\n",
       "condition          int64\n",
       "grade              int64\n",
       "sqft_above         int64\n",
       "sqft_basement      int64\n",
       "yr_built           int64\n",
       "yr_renovated       int64\n",
       "zipcode            int64\n",
       "lat              float64\n",
       "long             float64\n",
       "sqft_living15      int64\n",
       "sqft_lot15         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 數據前處理\n",
    "轉換資料型態：\n",
    "因為數據集裡的date數據是字串（string）格式，而模型的輸入只接受數值格式，所以可以透過以下程式碼將其轉為數值，並分成年、月及日三種數據。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  bedrooms  bathrooms  sqft_living  sqft_lot  floors  waterfront  \\\n",
       "0  221900.0         3       1.00         1180      5650     1.0           0   \n",
       "1  538000.0         3       2.25         2570      7242     2.0           0   \n",
       "2  180000.0         2       1.00          770     10000     1.0           0   \n",
       "3  604000.0         4       3.00         1960      5000     1.0           0   \n",
       "4  510000.0         3       2.00         1680      8080     1.0           0   \n",
       "\n",
       "   view  condition  grade  sqft_above  sqft_basement  yr_built  yr_renovated  \\\n",
       "0     0          3      7        1180              0      1955             0   \n",
       "1     0          3      7        2170            400      1951          1991   \n",
       "2     0          3      6         770              0      1933             0   \n",
       "3     0          5      7        1050            910      1965             0   \n",
       "4     0          3      8        1680              0      1987             0   \n",
       "\n",
       "   zipcode      lat     long  sqft_living15  sqft_lot15  year  month  day  \n",
       "0    98178  47.5112 -122.257           1340        5650  2014     10   13  \n",
       "1    98125  47.7210 -122.319           1690        7639  2014     12    9  \n",
       "2    98028  47.7379 -122.233           2720        8062  2015      2   25  \n",
       "3    98136  47.5208 -122.393           1360        5000  2014     12    9  \n",
       "4    98074  47.6168 -122.045           1800        7503  2015      2   18  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 將date日期拆為年、月和日並轉成數值\n",
    "data['year'] = pd.to_numeric(data['date'].str.slice(0, 4))\n",
    "data['month'] = pd.to_numeric(data['date'].str.slice(4, 6))\n",
    "data['day'] = pd.to_numeric(data['date'].str.slice(6, 8))\n",
    "\n",
    "# 刪除沒有用的數據，inplace則是將更新後的資料存回原本的地方\n",
    "data.drop(['id'], axis=\"columns\", inplace=True)\n",
    "data.drop(['date'], axis=\"columns\", inplace=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分割數據集（Dataset）：將數據集切割成三個部份，訓練數據（Training data）、驗證數據（Validation data）和測試數據（Testing data）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num = data.shape[0]\n",
    "# 取得一筆與data數量相同的亂數索引，主要目的是用於打散資料\n",
    "indexes = np.random.permutation(data_num)\n",
    "# 並將亂數索引值分為Train、validation和test分為，這裡的劃分比例為6:2:2\n",
    "train_indexes = indexes[:int(data_num *0.6)]\n",
    "val_indexes = indexes[int(data_num *0.6):int(data_num *0.8)]\n",
    "test_indexes = indexes[int(data_num *0.8):]\n",
    "# 透過索引值從data取出訓練資料、驗證資料和測試資料\n",
    "train_data = data.loc[train_indexes]\n",
    "val_data = data.loc[val_indexes]\n",
    "test_data = data.loc[test_indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization 正規化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用標準分數(Standard Score, 又稱z-score)將數據正規化，經過z-score正規化後數據的都會聚集在0附近， 標準差為1。 \n",
    "\n",
    "(x - 平均值) / 標準差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_validation_data = pd.concat([train_data, val_data])\n",
    "mean = train_validation_data.mean()\n",
    "std = train_validation_data.std()\n",
    "\n",
    "train_data = (train_data - mean) / std\n",
    "val_data = (val_data - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立Numpy array格式的訓練數據"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(train_data.drop('price', axis='columns'))\n",
    "y_train = np.array(train_data['price'])\n",
    "x_val = np.array(val_data.drop('price', axis='columns'))\n",
    "y_val = np.array(val_data['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "整理過後的資料共12967筆，且一筆資料有21種資訊(所以網路輸入必須為21)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12967, 21)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立並訓練網路模型\n",
    "\n",
    "這裡建構三層全連接層的網路架構，並且使用ReLU作為隱藏層的激活函數，而由於需得到線性輸出，故輸出層不使用任何激活函數。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model-1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                1408      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 5,633\n",
      "Trainable params: 5,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 建立一個Sequential型態的model\n",
    "model = keras.Sequential(name='model-1')\n",
    "# 第1層全連接層設為64個unit，將輸入形狀設定為(21, )，而實際上我們輸入的數據形狀為(batch_size, 21)\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(21,)))\n",
    "# 第2層全連接層設為64個unit\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# 最後一層全連接層設為1個unit\n",
    "model.add(layers.Dense(1))\n",
    "# 顯示網路模型架構\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "設定訓練使用的優化器、損失函數和指標函數："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(keras.optimizers.Adam(0.001),\n",
    "              loss=keras.losses.MeanSquaredError(),\n",
    "              metrics=[keras.metrics.MeanAbsoluteError()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "創建模型儲存目錄："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'lab2-logs/models/'\n",
    "os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "設定回調函數："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard回調函數會幫忙紀錄訓練資訊，並存成TensorBoard的紀錄檔\n",
    "log_dir = os.path.join('lab2-logs', 'model-1')\n",
    "model_cbk = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "# ModelCheckpoint回調函數幫忙儲存網路模型，可以設定只儲存最好的模型，「monitor」表示被監測的數據，「mode」min則代表監測數據越小越好。\n",
    "model_mckp = keras.callbacks.ModelCheckpoint(model_dir + '/Best-model-1.h5', \n",
    "                                        monitor='val_mean_absolute_error', \n",
    "                                        save_best_only=True, \n",
    "                                        mode='min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "訓練網路模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "  1/203 [..............................] - ETA: 0s - loss: 0.7274 - mean_absolute_error: 0.7365WARNING:tensorflow:From C:\\Users\\m9303\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0309s). Check your callbacks.\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.3255 - mean_absolute_error: 0.3489 - val_loss: 0.2396 - val_mean_absolute_error: 0.3071\n",
      "Epoch 2/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.2048 - mean_absolute_error: 0.2805 - val_loss: 0.2024 - val_mean_absolute_error: 0.2797\n",
      "Epoch 3/300\n",
      "203/203 [==============================] - 0s 965us/step - loss: 0.1767 - mean_absolute_error: 0.2610 - val_loss: 0.1670 - val_mean_absolute_error: 0.2556\n",
      "Epoch 4/300\n",
      "203/203 [==============================] - 0s 921us/step - loss: 0.1556 - mean_absolute_error: 0.2461 - val_loss: 0.1685 - val_mean_absolute_error: 0.2456\n",
      "Epoch 5/300\n",
      "203/203 [==============================] - 0s 869us/step - loss: 0.1419 - mean_absolute_error: 0.2364 - val_loss: 0.1458 - val_mean_absolute_error: 0.2291\n",
      "Epoch 6/300\n",
      "203/203 [==============================] - 0s 903us/step - loss: 0.1293 - mean_absolute_error: 0.2245 - val_loss: 0.1371 - val_mean_absolute_error: 0.2196\n",
      "Epoch 7/300\n",
      "203/203 [==============================] - 0s 870us/step - loss: 0.1166 - mean_absolute_error: 0.2150 - val_loss: 0.1417 - val_mean_absolute_error: 0.2187\n",
      "Epoch 8/300\n",
      "203/203 [==============================] - 0s 743us/step - loss: 0.1142 - mean_absolute_error: 0.2122 - val_loss: 0.1415 - val_mean_absolute_error: 0.2200\n",
      "Epoch 9/300\n",
      "203/203 [==============================] - 0s 788us/step - loss: 0.1076 - mean_absolute_error: 0.2077 - val_loss: 0.1389 - val_mean_absolute_error: 0.2149\n",
      "Epoch 10/300\n",
      "203/203 [==============================] - 0s 729us/step - loss: 0.1021 - mean_absolute_error: 0.2014 - val_loss: 0.1440 - val_mean_absolute_error: 0.2161\n",
      "Epoch 11/300\n",
      "203/203 [==============================] - 0s 798us/step - loss: 0.0983 - mean_absolute_error: 0.1988 - val_loss: 0.1245 - val_mean_absolute_error: 0.2057\n",
      "Epoch 12/300\n",
      "203/203 [==============================] - 0s 732us/step - loss: 0.0972 - mean_absolute_error: 0.1977 - val_loss: 0.1262 - val_mean_absolute_error: 0.2081\n",
      "Epoch 13/300\n",
      "203/203 [==============================] - 0s 748us/step - loss: 0.0932 - mean_absolute_error: 0.1947 - val_loss: 0.1364 - val_mean_absolute_error: 0.2086\n",
      "Epoch 14/300\n",
      "203/203 [==============================] - 0s 778us/step - loss: 0.0900 - mean_absolute_error: 0.1916 - val_loss: 0.1204 - val_mean_absolute_error: 0.2001\n",
      "Epoch 15/300\n",
      "203/203 [==============================] - 0s 852us/step - loss: 0.0865 - mean_absolute_error: 0.1903 - val_loss: 0.1190 - val_mean_absolute_error: 0.2032\n",
      "Epoch 16/300\n",
      "203/203 [==============================] - 0s 916us/step - loss: 0.0846 - mean_absolute_error: 0.1883 - val_loss: 0.1169 - val_mean_absolute_error: 0.1978\n",
      "Epoch 17/300\n",
      "203/203 [==============================] - 0s 831us/step - loss: 0.0861 - mean_absolute_error: 0.1902 - val_loss: 0.1242 - val_mean_absolute_error: 0.2054\n",
      "Epoch 18/300\n",
      "203/203 [==============================] - 0s 873us/step - loss: 0.0821 - mean_absolute_error: 0.1854 - val_loss: 0.1277 - val_mean_absolute_error: 0.2052\n",
      "Epoch 19/300\n",
      "203/203 [==============================] - 0s 966us/step - loss: 0.0817 - mean_absolute_error: 0.1850 - val_loss: 0.1185 - val_mean_absolute_error: 0.1956\n",
      "Epoch 20/300\n",
      "203/203 [==============================] - 0s 911us/step - loss: 0.0811 - mean_absolute_error: 0.1863 - val_loss: 0.1175 - val_mean_absolute_error: 0.1972\n",
      "Epoch 21/300\n",
      "203/203 [==============================] - 0s 947us/step - loss: 0.0791 - mean_absolute_error: 0.1838 - val_loss: 0.1161 - val_mean_absolute_error: 0.1952\n",
      "Epoch 22/300\n",
      "203/203 [==============================] - 0s 923us/step - loss: 0.0767 - mean_absolute_error: 0.1814 - val_loss: 0.1270 - val_mean_absolute_error: 0.2142\n",
      "Epoch 23/300\n",
      "203/203 [==============================] - 0s 873us/step - loss: 0.0761 - mean_absolute_error: 0.1813 - val_loss: 0.1277 - val_mean_absolute_error: 0.1997\n",
      "Epoch 24/300\n",
      "203/203 [==============================] - 0s 933us/step - loss: 0.0733 - mean_absolute_error: 0.1782 - val_loss: 0.1215 - val_mean_absolute_error: 0.1980\n",
      "Epoch 25/300\n",
      "203/203 [==============================] - 0s 860us/step - loss: 0.0752 - mean_absolute_error: 0.1804 - val_loss: 0.1327 - val_mean_absolute_error: 0.2028\n",
      "Epoch 26/300\n",
      "203/203 [==============================] - 0s 940us/step - loss: 0.0727 - mean_absolute_error: 0.1772 - val_loss: 0.1281 - val_mean_absolute_error: 0.2159\n",
      "Epoch 27/300\n",
      "203/203 [==============================] - 0s 863us/step - loss: 0.0720 - mean_absolute_error: 0.1785 - val_loss: 0.1241 - val_mean_absolute_error: 0.1987\n",
      "Epoch 28/300\n",
      "203/203 [==============================] - 0s 910us/step - loss: 0.0692 - mean_absolute_error: 0.1749 - val_loss: 0.1179 - val_mean_absolute_error: 0.1986\n",
      "Epoch 29/300\n",
      "203/203 [==============================] - 0s 931us/step - loss: 0.0708 - mean_absolute_error: 0.1761 - val_loss: 0.1289 - val_mean_absolute_error: 0.1996\n",
      "Epoch 30/300\n",
      "203/203 [==============================] - 0s 884us/step - loss: 0.0699 - mean_absolute_error: 0.1747 - val_loss: 0.1188 - val_mean_absolute_error: 0.2009\n",
      "Epoch 31/300\n",
      "203/203 [==============================] - 0s 890us/step - loss: 0.0692 - mean_absolute_error: 0.1755 - val_loss: 0.1253 - val_mean_absolute_error: 0.2108\n",
      "Epoch 32/300\n",
      "203/203 [==============================] - 0s 879us/step - loss: 0.0647 - mean_absolute_error: 0.1709 - val_loss: 0.1251 - val_mean_absolute_error: 0.2009\n",
      "Epoch 33/300\n",
      "203/203 [==============================] - 0s 886us/step - loss: 0.0652 - mean_absolute_error: 0.1704 - val_loss: 0.1215 - val_mean_absolute_error: 0.1975\n",
      "Epoch 34/300\n",
      "203/203 [==============================] - 0s 945us/step - loss: 0.0670 - mean_absolute_error: 0.1737 - val_loss: 0.1234 - val_mean_absolute_error: 0.2005\n",
      "Epoch 35/300\n",
      "203/203 [==============================] - 0s 896us/step - loss: 0.0630 - mean_absolute_error: 0.1687 - val_loss: 0.1224 - val_mean_absolute_error: 0.2002\n",
      "Epoch 36/300\n",
      "203/203 [==============================] - 0s 997us/step - loss: 0.0664 - mean_absolute_error: 0.1727 - val_loss: 0.1159 - val_mean_absolute_error: 0.1950\n",
      "Epoch 37/300\n",
      "203/203 [==============================] - 0s 845us/step - loss: 0.0644 - mean_absolute_error: 0.1704 - val_loss: 0.1253 - val_mean_absolute_error: 0.2008\n",
      "Epoch 38/300\n",
      "203/203 [==============================] - 0s 913us/step - loss: 0.0613 - mean_absolute_error: 0.1675 - val_loss: 0.1196 - val_mean_absolute_error: 0.1973\n",
      "Epoch 39/300\n",
      "203/203 [==============================] - 0s 861us/step - loss: 0.0630 - mean_absolute_error: 0.1679 - val_loss: 0.1279 - val_mean_absolute_error: 0.2133\n",
      "Epoch 40/300\n",
      "203/203 [==============================] - 0s 942us/step - loss: 0.0609 - mean_absolute_error: 0.1672 - val_loss: 0.1296 - val_mean_absolute_error: 0.1980\n",
      "Epoch 41/300\n",
      "203/203 [==============================] - 0s 849us/step - loss: 0.0624 - mean_absolute_error: 0.1679 - val_loss: 0.1167 - val_mean_absolute_error: 0.1971\n",
      "Epoch 42/300\n",
      "203/203 [==============================] - 0s 950us/step - loss: 0.0583 - mean_absolute_error: 0.1644 - val_loss: 0.1151 - val_mean_absolute_error: 0.1970\n",
      "Epoch 43/300\n",
      "203/203 [==============================] - 0s 884us/step - loss: 0.0592 - mean_absolute_error: 0.1666 - val_loss: 0.1238 - val_mean_absolute_error: 0.2045\n",
      "Epoch 44/300\n",
      "203/203 [==============================] - 0s 962us/step - loss: 0.0567 - mean_absolute_error: 0.1631 - val_loss: 0.1193 - val_mean_absolute_error: 0.1995\n",
      "Epoch 45/300\n",
      "203/203 [==============================] - 0s 814us/step - loss: 0.0579 - mean_absolute_error: 0.1634 - val_loss: 0.1309 - val_mean_absolute_error: 0.2104\n",
      "Epoch 46/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 0s 746us/step - loss: 0.0587 - mean_absolute_error: 0.1650 - val_loss: 0.1288 - val_mean_absolute_error: 0.2063\n",
      "Epoch 47/300\n",
      "203/203 [==============================] - 0s 731us/step - loss: 0.0563 - mean_absolute_error: 0.1621 - val_loss: 0.1272 - val_mean_absolute_error: 0.2151\n",
      "Epoch 48/300\n",
      "203/203 [==============================] - 0s 725us/step - loss: 0.0595 - mean_absolute_error: 0.1647 - val_loss: 0.1239 - val_mean_absolute_error: 0.1988\n",
      "Epoch 49/300\n",
      "203/203 [==============================] - 0s 751us/step - loss: 0.0552 - mean_absolute_error: 0.1606 - val_loss: 0.1346 - val_mean_absolute_error: 0.2006\n",
      "Epoch 50/300\n",
      "203/203 [==============================] - 0s 812us/step - loss: 0.0558 - mean_absolute_error: 0.1610 - val_loss: 0.1149 - val_mean_absolute_error: 0.1937\n",
      "Epoch 51/300\n",
      "203/203 [==============================] - 0s 957us/step - loss: 0.0554 - mean_absolute_error: 0.1611 - val_loss: 0.1174 - val_mean_absolute_error: 0.2015\n",
      "Epoch 52/300\n",
      "203/203 [==============================] - 0s 844us/step - loss: 0.0544 - mean_absolute_error: 0.1602 - val_loss: 0.1230 - val_mean_absolute_error: 0.2128\n",
      "Epoch 53/300\n",
      "203/203 [==============================] - 0s 765us/step - loss: 0.0541 - mean_absolute_error: 0.1592 - val_loss: 0.1169 - val_mean_absolute_error: 0.1956\n",
      "Epoch 54/300\n",
      "203/203 [==============================] - 0s 827us/step - loss: 0.0532 - mean_absolute_error: 0.1600 - val_loss: 0.1231 - val_mean_absolute_error: 0.1987\n",
      "Epoch 55/300\n",
      "203/203 [==============================] - 0s 797us/step - loss: 0.0520 - mean_absolute_error: 0.1584 - val_loss: 0.1168 - val_mean_absolute_error: 0.1949\n",
      "Epoch 56/300\n",
      "203/203 [==============================] - 0s 897us/step - loss: 0.0545 - mean_absolute_error: 0.1605 - val_loss: 0.1136 - val_mean_absolute_error: 0.1941\n",
      "Epoch 57/300\n",
      "203/203 [==============================] - 0s 750us/step - loss: 0.0526 - mean_absolute_error: 0.1582 - val_loss: 0.1159 - val_mean_absolute_error: 0.1956\n",
      "Epoch 58/300\n",
      "203/203 [==============================] - 0s 803us/step - loss: 0.0532 - mean_absolute_error: 0.1599 - val_loss: 0.1183 - val_mean_absolute_error: 0.2001\n",
      "Epoch 59/300\n",
      "203/203 [==============================] - 0s 724us/step - loss: 0.0536 - mean_absolute_error: 0.1584 - val_loss: 0.1197 - val_mean_absolute_error: 0.1956\n",
      "Epoch 60/300\n",
      "203/203 [==============================] - 0s 735us/step - loss: 0.0516 - mean_absolute_error: 0.1564 - val_loss: 0.1307 - val_mean_absolute_error: 0.2120\n",
      "Epoch 61/300\n",
      "203/203 [==============================] - 0s 721us/step - loss: 0.0510 - mean_absolute_error: 0.1573 - val_loss: 0.1227 - val_mean_absolute_error: 0.2040\n",
      "Epoch 62/300\n",
      "203/203 [==============================] - 0s 738us/step - loss: 0.0498 - mean_absolute_error: 0.1554 - val_loss: 0.1186 - val_mean_absolute_error: 0.1953\n",
      "Epoch 63/300\n",
      "203/203 [==============================] - 0s 734us/step - loss: 0.0474 - mean_absolute_error: 0.1526 - val_loss: 0.1213 - val_mean_absolute_error: 0.2009\n",
      "Epoch 64/300\n",
      "203/203 [==============================] - 0s 903us/step - loss: 0.0497 - mean_absolute_error: 0.1561 - val_loss: 0.1271 - val_mean_absolute_error: 0.2006\n",
      "Epoch 65/300\n",
      "203/203 [==============================] - 0s 822us/step - loss: 0.0492 - mean_absolute_error: 0.1556 - val_loss: 0.1197 - val_mean_absolute_error: 0.1976\n",
      "Epoch 66/300\n",
      "203/203 [==============================] - 0s 714us/step - loss: 0.0517 - mean_absolute_error: 0.1577 - val_loss: 0.1224 - val_mean_absolute_error: 0.1993\n",
      "Epoch 67/300\n",
      "203/203 [==============================] - 0s 774us/step - loss: 0.0540 - mean_absolute_error: 0.1594 - val_loss: 0.1207 - val_mean_absolute_error: 0.2008\n",
      "Epoch 68/300\n",
      "203/203 [==============================] - 0s 866us/step - loss: 0.0480 - mean_absolute_error: 0.1535 - val_loss: 0.1236 - val_mean_absolute_error: 0.2046\n",
      "Epoch 69/300\n",
      "203/203 [==============================] - 0s 817us/step - loss: 0.0492 - mean_absolute_error: 0.1550 - val_loss: 0.1180 - val_mean_absolute_error: 0.1983\n",
      "Epoch 70/300\n",
      "203/203 [==============================] - 0s 749us/step - loss: 0.0472 - mean_absolute_error: 0.1524 - val_loss: 0.1212 - val_mean_absolute_error: 0.1992\n",
      "Epoch 71/300\n",
      "203/203 [==============================] - 0s 845us/step - loss: 0.0464 - mean_absolute_error: 0.1519 - val_loss: 0.1199 - val_mean_absolute_error: 0.1971\n",
      "Epoch 72/300\n",
      "203/203 [==============================] - 0s 850us/step - loss: 0.0469 - mean_absolute_error: 0.1529 - val_loss: 0.1270 - val_mean_absolute_error: 0.2059\n",
      "Epoch 73/300\n",
      "203/203 [==============================] - 0s 783us/step - loss: 0.0450 - mean_absolute_error: 0.1496 - val_loss: 0.1277 - val_mean_absolute_error: 0.2032\n",
      "Epoch 74/300\n",
      "203/203 [==============================] - 0s 843us/step - loss: 0.0503 - mean_absolute_error: 0.1552 - val_loss: 0.1249 - val_mean_absolute_error: 0.1983\n",
      "Epoch 75/300\n",
      "203/203 [==============================] - 0s 852us/step - loss: 0.0472 - mean_absolute_error: 0.1535 - val_loss: 0.1243 - val_mean_absolute_error: 0.2005\n",
      "Epoch 76/300\n",
      "203/203 [==============================] - 0s 850us/step - loss: 0.0463 - mean_absolute_error: 0.1515 - val_loss: 0.1203 - val_mean_absolute_error: 0.2005\n",
      "Epoch 77/300\n",
      "203/203 [==============================] - 0s 852us/step - loss: 0.0455 - mean_absolute_error: 0.1503 - val_loss: 0.1217 - val_mean_absolute_error: 0.1986\n",
      "Epoch 78/300\n",
      "203/203 [==============================] - 0s 731us/step - loss: 0.0471 - mean_absolute_error: 0.1511 - val_loss: 0.1205 - val_mean_absolute_error: 0.1977\n",
      "Epoch 79/300\n",
      "203/203 [==============================] - 0s 732us/step - loss: 0.0438 - mean_absolute_error: 0.1485 - val_loss: 0.1220 - val_mean_absolute_error: 0.2009\n",
      "Epoch 80/300\n",
      "203/203 [==============================] - 0s 723us/step - loss: 0.0438 - mean_absolute_error: 0.1489 - val_loss: 0.1248 - val_mean_absolute_error: 0.2014\n",
      "Epoch 81/300\n",
      "203/203 [==============================] - 0s 743us/step - loss: 0.0449 - mean_absolute_error: 0.1489 - val_loss: 0.1251 - val_mean_absolute_error: 0.2028\n",
      "Epoch 82/300\n",
      "203/203 [==============================] - 0s 838us/step - loss: 0.0443 - mean_absolute_error: 0.1492 - val_loss: 0.1203 - val_mean_absolute_error: 0.1984\n",
      "Epoch 83/300\n",
      "203/203 [==============================] - 0s 733us/step - loss: 0.0467 - mean_absolute_error: 0.1511 - val_loss: 0.1241 - val_mean_absolute_error: 0.1990\n",
      "Epoch 84/300\n",
      "203/203 [==============================] - 0s 732us/step - loss: 0.0495 - mean_absolute_error: 0.1537 - val_loss: 0.1184 - val_mean_absolute_error: 0.1966\n",
      "Epoch 85/300\n",
      "203/203 [==============================] - 0s 737us/step - loss: 0.0480 - mean_absolute_error: 0.1509 - val_loss: 0.1219 - val_mean_absolute_error: 0.1974\n",
      "Epoch 86/300\n",
      "203/203 [==============================] - 0s 780us/step - loss: 0.0412 - mean_absolute_error: 0.1443 - val_loss: 0.1208 - val_mean_absolute_error: 0.1998\n",
      "Epoch 87/300\n",
      "203/203 [==============================] - 0s 742us/step - loss: 0.0415 - mean_absolute_error: 0.1448 - val_loss: 0.1239 - val_mean_absolute_error: 0.2002\n",
      "Epoch 88/300\n",
      "203/203 [==============================] - 0s 727us/step - loss: 0.0412 - mean_absolute_error: 0.1454 - val_loss: 0.1248 - val_mean_absolute_error: 0.2011\n",
      "Epoch 89/300\n",
      "203/203 [==============================] - 0s 746us/step - loss: 0.0413 - mean_absolute_error: 0.1456 - val_loss: 0.1268 - val_mean_absolute_error: 0.2021\n",
      "Epoch 90/300\n",
      "203/203 [==============================] - 0s 920us/step - loss: 0.0417 - mean_absolute_error: 0.1458 - val_loss: 0.1265 - val_mean_absolute_error: 0.2054\n",
      "Epoch 91/300\n",
      "203/203 [==============================] - 0s 869us/step - loss: 0.0408 - mean_absolute_error: 0.1455 - val_loss: 0.1245 - val_mean_absolute_error: 0.2044\n",
      "Epoch 92/300\n",
      "203/203 [==============================] - 0s 870us/step - loss: 0.0491 - mean_absolute_error: 0.1521 - val_loss: 0.1242 - val_mean_absolute_error: 0.2062\n",
      "Epoch 93/300\n",
      "203/203 [==============================] - 0s 880us/step - loss: 0.0467 - mean_absolute_error: 0.1497 - val_loss: 0.1239 - val_mean_absolute_error: 0.1995\n",
      "Epoch 94/300\n",
      "203/203 [==============================] - 0s 747us/step - loss: 0.0475 - mean_absolute_error: 0.1507 - val_loss: 0.1313 - val_mean_absolute_error: 0.2035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/300\n",
      "203/203 [==============================] - 0s 768us/step - loss: 0.0415 - mean_absolute_error: 0.1451 - val_loss: 0.1246 - val_mean_absolute_error: 0.1996\n",
      "Epoch 96/300\n",
      "203/203 [==============================] - 0s 735us/step - loss: 0.0389 - mean_absolute_error: 0.1424 - val_loss: 0.1227 - val_mean_absolute_error: 0.2037\n",
      "Epoch 97/300\n",
      "203/203 [==============================] - 0s 744us/step - loss: 0.0402 - mean_absolute_error: 0.1434 - val_loss: 0.1263 - val_mean_absolute_error: 0.2057\n",
      "Epoch 98/300\n",
      "203/203 [==============================] - 0s 792us/step - loss: 0.0414 - mean_absolute_error: 0.1461 - val_loss: 0.1242 - val_mean_absolute_error: 0.2050\n",
      "Epoch 99/300\n",
      "203/203 [==============================] - 0s 744us/step - loss: 0.0406 - mean_absolute_error: 0.1433 - val_loss: 0.1239 - val_mean_absolute_error: 0.2012\n",
      "Epoch 100/300\n",
      "203/203 [==============================] - 0s 741us/step - loss: 0.0429 - mean_absolute_error: 0.1461 - val_loss: 0.1218 - val_mean_absolute_error: 0.1997\n",
      "Epoch 101/300\n",
      "203/203 [==============================] - 0s 765us/step - loss: 0.0411 - mean_absolute_error: 0.1446 - val_loss: 0.1206 - val_mean_absolute_error: 0.1999\n",
      "Epoch 102/300\n",
      "203/203 [==============================] - 0s 751us/step - loss: 0.0388 - mean_absolute_error: 0.1427 - val_loss: 0.1240 - val_mean_absolute_error: 0.2005\n",
      "Epoch 103/300\n",
      "203/203 [==============================] - 0s 727us/step - loss: 0.0383 - mean_absolute_error: 0.1406 - val_loss: 0.1263 - val_mean_absolute_error: 0.2020\n",
      "Epoch 104/300\n",
      "203/203 [==============================] - 0s 731us/step - loss: 0.0393 - mean_absolute_error: 0.1427 - val_loss: 0.1230 - val_mean_absolute_error: 0.2029\n",
      "Epoch 105/300\n",
      "203/203 [==============================] - 0s 729us/step - loss: 0.0391 - mean_absolute_error: 0.1429 - val_loss: 0.1247 - val_mean_absolute_error: 0.2017\n",
      "Epoch 106/300\n",
      "203/203 [==============================] - 0s 737us/step - loss: 0.0383 - mean_absolute_error: 0.1408 - val_loss: 0.1341 - val_mean_absolute_error: 0.2036\n",
      "Epoch 107/300\n",
      "203/203 [==============================] - 0s 754us/step - loss: 0.0398 - mean_absolute_error: 0.1435 - val_loss: 0.1278 - val_mean_absolute_error: 0.2062\n",
      "Epoch 108/300\n",
      "203/203 [==============================] - 0s 723us/step - loss: 0.0407 - mean_absolute_error: 0.1443 - val_loss: 0.1256 - val_mean_absolute_error: 0.2046\n",
      "Epoch 109/300\n",
      "203/203 [==============================] - 0s 733us/step - loss: 0.0446 - mean_absolute_error: 0.1479 - val_loss: 0.1239 - val_mean_absolute_error: 0.2056\n",
      "Epoch 110/300\n",
      "203/203 [==============================] - 0s 729us/step - loss: 0.0432 - mean_absolute_error: 0.1459 - val_loss: 0.1226 - val_mean_absolute_error: 0.2018\n",
      "Epoch 111/300\n",
      "203/203 [==============================] - 0s 745us/step - loss: 0.0429 - mean_absolute_error: 0.1446 - val_loss: 0.1291 - val_mean_absolute_error: 0.2048\n",
      "Epoch 112/300\n",
      "203/203 [==============================] - 0s 725us/step - loss: 0.0394 - mean_absolute_error: 0.1421 - val_loss: 0.1235 - val_mean_absolute_error: 0.2028\n",
      "Epoch 113/300\n",
      "203/203 [==============================] - 0s 743us/step - loss: 0.0373 - mean_absolute_error: 0.1388 - val_loss: 0.1295 - val_mean_absolute_error: 0.2077\n",
      "Epoch 114/300\n",
      "203/203 [==============================] - 0s 756us/step - loss: 0.0390 - mean_absolute_error: 0.1418 - val_loss: 0.1317 - val_mean_absolute_error: 0.2138\n",
      "Epoch 115/300\n",
      "203/203 [==============================] - 0s 726us/step - loss: 0.0412 - mean_absolute_error: 0.1457 - val_loss: 0.1245 - val_mean_absolute_error: 0.2020\n",
      "Epoch 116/300\n",
      "203/203 [==============================] - 0s 723us/step - loss: 0.0361 - mean_absolute_error: 0.1375 - val_loss: 0.1272 - val_mean_absolute_error: 0.2030\n",
      "Epoch 117/300\n",
      "203/203 [==============================] - 0s 721us/step - loss: 0.0364 - mean_absolute_error: 0.1389 - val_loss: 0.1261 - val_mean_absolute_error: 0.2051\n",
      "Epoch 118/300\n",
      "203/203 [==============================] - 0s 720us/step - loss: 0.0357 - mean_absolute_error: 0.1379 - val_loss: 0.1258 - val_mean_absolute_error: 0.2113\n",
      "Epoch 119/300\n",
      "203/203 [==============================] - 0s 725us/step - loss: 0.0368 - mean_absolute_error: 0.1396 - val_loss: 0.1263 - val_mean_absolute_error: 0.2034\n",
      "Epoch 120/300\n",
      "203/203 [==============================] - 0s 758us/step - loss: 0.0379 - mean_absolute_error: 0.1401 - val_loss: 0.1280 - val_mean_absolute_error: 0.2026\n",
      "Epoch 121/300\n",
      "203/203 [==============================] - 0s 721us/step - loss: 0.0375 - mean_absolute_error: 0.1403 - val_loss: 0.1231 - val_mean_absolute_error: 0.2017\n",
      "Epoch 122/300\n",
      "203/203 [==============================] - 0s 743us/step - loss: 0.0355 - mean_absolute_error: 0.1373 - val_loss: 0.1299 - val_mean_absolute_error: 0.2064\n",
      "Epoch 123/300\n",
      "203/203 [==============================] - 0s 728us/step - loss: 0.0406 - mean_absolute_error: 0.1426 - val_loss: 0.1253 - val_mean_absolute_error: 0.2063\n",
      "Epoch 124/300\n",
      "203/203 [==============================] - 0s 747us/step - loss: 0.0473 - mean_absolute_error: 0.1493 - val_loss: 0.1246 - val_mean_absolute_error: 0.2031\n",
      "Epoch 125/300\n",
      "203/203 [==============================] - 0s 761us/step - loss: 0.0435 - mean_absolute_error: 0.1461 - val_loss: 0.1292 - val_mean_absolute_error: 0.2084\n",
      "Epoch 126/300\n",
      "203/203 [==============================] - 0s 756us/step - loss: 0.0386 - mean_absolute_error: 0.1403 - val_loss: 0.1277 - val_mean_absolute_error: 0.2023\n",
      "Epoch 127/300\n",
      "203/203 [==============================] - 0s 757us/step - loss: 0.0356 - mean_absolute_error: 0.1372 - val_loss: 0.1223 - val_mean_absolute_error: 0.2027\n",
      "Epoch 128/300\n",
      "203/203 [==============================] - 0s 730us/step - loss: 0.0349 - mean_absolute_error: 0.1358 - val_loss: 0.1225 - val_mean_absolute_error: 0.2013\n",
      "Epoch 129/300\n",
      "203/203 [==============================] - 0s 766us/step - loss: 0.0396 - mean_absolute_error: 0.1419 - val_loss: 0.1263 - val_mean_absolute_error: 0.2090\n",
      "Epoch 130/300\n",
      "203/203 [==============================] - 0s 775us/step - loss: 0.0381 - mean_absolute_error: 0.1386 - val_loss: 0.1322 - val_mean_absolute_error: 0.2040\n",
      "Epoch 131/300\n",
      "203/203 [==============================] - 0s 777us/step - loss: 0.0354 - mean_absolute_error: 0.1367 - val_loss: 0.1259 - val_mean_absolute_error: 0.2013\n",
      "Epoch 132/300\n",
      "203/203 [==============================] - 0s 777us/step - loss: 0.0339 - mean_absolute_error: 0.1346 - val_loss: 0.1255 - val_mean_absolute_error: 0.2018\n",
      "Epoch 133/300\n",
      "203/203 [==============================] - 0s 871us/step - loss: 0.0337 - mean_absolute_error: 0.1344 - val_loss: 0.1248 - val_mean_absolute_error: 0.2041\n",
      "Epoch 134/300\n",
      "203/203 [==============================] - 0s 757us/step - loss: 0.0341 - mean_absolute_error: 0.1348 - val_loss: 0.1284 - val_mean_absolute_error: 0.2047\n",
      "Epoch 135/300\n",
      "203/203 [==============================] - 0s 748us/step - loss: 0.0373 - mean_absolute_error: 0.1397 - val_loss: 0.1302 - val_mean_absolute_error: 0.2083\n",
      "Epoch 136/300\n",
      "203/203 [==============================] - 0s 736us/step - loss: 0.0392 - mean_absolute_error: 0.1432 - val_loss: 0.1254 - val_mean_absolute_error: 0.2024\n",
      "Epoch 137/300\n",
      "203/203 [==============================] - 0s 722us/step - loss: 0.0445 - mean_absolute_error: 0.1449 - val_loss: 0.1317 - val_mean_absolute_error: 0.2104\n",
      "Epoch 138/300\n",
      "203/203 [==============================] - 0s 786us/step - loss: 0.0366 - mean_absolute_error: 0.1378 - val_loss: 0.1364 - val_mean_absolute_error: 0.2048\n",
      "Epoch 139/300\n",
      "203/203 [==============================] - 0s 835us/step - loss: 0.0368 - mean_absolute_error: 0.1378 - val_loss: 0.1298 - val_mean_absolute_error: 0.2054\n",
      "Epoch 140/300\n",
      "203/203 [==============================] - 0s 841us/step - loss: 0.0341 - mean_absolute_error: 0.1346 - val_loss: 0.1332 - val_mean_absolute_error: 0.2058\n",
      "Epoch 141/300\n",
      "203/203 [==============================] - 0s 784us/step - loss: 0.0376 - mean_absolute_error: 0.1379 - val_loss: 0.1260 - val_mean_absolute_error: 0.2051\n",
      "Epoch 142/300\n",
      "203/203 [==============================] - 0s 767us/step - loss: 0.0359 - mean_absolute_error: 0.1376 - val_loss: 0.1295 - val_mean_absolute_error: 0.2080\n",
      "Epoch 143/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 0s 816us/step - loss: 0.0393 - mean_absolute_error: 0.1411 - val_loss: 0.1258 - val_mean_absolute_error: 0.2025\n",
      "Epoch 144/300\n",
      "203/203 [==============================] - 0s 776us/step - loss: 0.0341 - mean_absolute_error: 0.1349 - val_loss: 0.1328 - val_mean_absolute_error: 0.2049\n",
      "Epoch 145/300\n",
      "203/203 [==============================] - 0s 869us/step - loss: 0.0343 - mean_absolute_error: 0.1343 - val_loss: 0.1299 - val_mean_absolute_error: 0.2072\n",
      "Epoch 146/300\n",
      "203/203 [==============================] - 0s 787us/step - loss: 0.0348 - mean_absolute_error: 0.1352 - val_loss: 0.1294 - val_mean_absolute_error: 0.2036\n",
      "Epoch 147/300\n",
      "203/203 [==============================] - 0s 841us/step - loss: 0.0373 - mean_absolute_error: 0.1388 - val_loss: 0.1359 - val_mean_absolute_error: 0.2080\n",
      "Epoch 148/300\n",
      "203/203 [==============================] - 0s 785us/step - loss: 0.0440 - mean_absolute_error: 0.1446 - val_loss: 0.1281 - val_mean_absolute_error: 0.2074\n",
      "Epoch 149/300\n",
      "203/203 [==============================] - 0s 750us/step - loss: 0.0393 - mean_absolute_error: 0.1404 - val_loss: 0.1293 - val_mean_absolute_error: 0.2066\n",
      "Epoch 150/300\n",
      "203/203 [==============================] - 0s 802us/step - loss: 0.0353 - mean_absolute_error: 0.1359 - val_loss: 0.1298 - val_mean_absolute_error: 0.2042\n",
      "Epoch 151/300\n",
      "203/203 [==============================] - 0s 794us/step - loss: 0.0323 - mean_absolute_error: 0.1316 - val_loss: 0.1353 - val_mean_absolute_error: 0.2043\n",
      "Epoch 152/300\n",
      "203/203 [==============================] - 0s 746us/step - loss: 0.0339 - mean_absolute_error: 0.1343 - val_loss: 0.1348 - val_mean_absolute_error: 0.2062\n",
      "Epoch 153/300\n",
      "203/203 [==============================] - 0s 742us/step - loss: 0.0328 - mean_absolute_error: 0.1328 - val_loss: 0.1289 - val_mean_absolute_error: 0.2054\n",
      "Epoch 154/300\n",
      "203/203 [==============================] - 0s 746us/step - loss: 0.0323 - mean_absolute_error: 0.1323 - val_loss: 0.1309 - val_mean_absolute_error: 0.2044\n",
      "Epoch 155/300\n",
      "203/203 [==============================] - 0s 731us/step - loss: 0.0324 - mean_absolute_error: 0.1322 - val_loss: 0.1289 - val_mean_absolute_error: 0.2062\n",
      "Epoch 156/300\n",
      "203/203 [==============================] - 0s 786us/step - loss: 0.0331 - mean_absolute_error: 0.1331 - val_loss: 0.1408 - val_mean_absolute_error: 0.2151\n",
      "Epoch 157/300\n",
      "203/203 [==============================] - 0s 847us/step - loss: 0.0376 - mean_absolute_error: 0.1390 - val_loss: 0.1280 - val_mean_absolute_error: 0.2032\n",
      "Epoch 158/300\n",
      "203/203 [==============================] - 0s 807us/step - loss: 0.0345 - mean_absolute_error: 0.1341 - val_loss: 0.1378 - val_mean_absolute_error: 0.2153\n",
      "Epoch 159/300\n",
      "203/203 [==============================] - 0s 787us/step - loss: 0.0387 - mean_absolute_error: 0.1412 - val_loss: 0.1360 - val_mean_absolute_error: 0.2091\n",
      "Epoch 160/300\n",
      "203/203 [==============================] - 0s 748us/step - loss: 0.0380 - mean_absolute_error: 0.1397 - val_loss: 0.1340 - val_mean_absolute_error: 0.2067\n",
      "Epoch 161/300\n",
      "203/203 [==============================] - 0s 816us/step - loss: 0.0341 - mean_absolute_error: 0.1348 - val_loss: 0.1329 - val_mean_absolute_error: 0.2049\n",
      "Epoch 162/300\n",
      "203/203 [==============================] - 0s 782us/step - loss: 0.0319 - mean_absolute_error: 0.1309 - val_loss: 0.1297 - val_mean_absolute_error: 0.2067\n",
      "Epoch 163/300\n",
      "203/203 [==============================] - 0s 737us/step - loss: 0.0326 - mean_absolute_error: 0.1322 - val_loss: 0.1298 - val_mean_absolute_error: 0.2024\n",
      "Epoch 164/300\n",
      "203/203 [==============================] - 0s 746us/step - loss: 0.0314 - mean_absolute_error: 0.1306 - val_loss: 0.1301 - val_mean_absolute_error: 0.2061\n",
      "Epoch 165/300\n",
      "203/203 [==============================] - 0s 744us/step - loss: 0.0332 - mean_absolute_error: 0.1329 - val_loss: 0.1358 - val_mean_absolute_error: 0.2134\n",
      "Epoch 166/300\n",
      "203/203 [==============================] - 0s 846us/step - loss: 0.0413 - mean_absolute_error: 0.1404 - val_loss: 0.1309 - val_mean_absolute_error: 0.2069\n",
      "Epoch 167/300\n",
      "203/203 [==============================] - 0s 770us/step - loss: 0.0363 - mean_absolute_error: 0.1363 - val_loss: 0.1268 - val_mean_absolute_error: 0.2046\n",
      "Epoch 168/300\n",
      "203/203 [==============================] - 0s 851us/step - loss: 0.0348 - mean_absolute_error: 0.1347 - val_loss: 0.1368 - val_mean_absolute_error: 0.2082\n",
      "Epoch 169/300\n",
      "203/203 [==============================] - 0s 810us/step - loss: 0.0344 - mean_absolute_error: 0.1340 - val_loss: 0.1264 - val_mean_absolute_error: 0.2050\n",
      "Epoch 170/300\n",
      "203/203 [==============================] - 0s 782us/step - loss: 0.0322 - mean_absolute_error: 0.1312 - val_loss: 0.1317 - val_mean_absolute_error: 0.2094\n",
      "Epoch 171/300\n",
      "203/203 [==============================] - 0s 771us/step - loss: 0.0328 - mean_absolute_error: 0.1319 - val_loss: 0.1301 - val_mean_absolute_error: 0.2065\n",
      "Epoch 172/300\n",
      "203/203 [==============================] - 0s 753us/step - loss: 0.0343 - mean_absolute_error: 0.1350 - val_loss: 0.1302 - val_mean_absolute_error: 0.2082\n",
      "Epoch 173/300\n",
      "203/203 [==============================] - 0s 811us/step - loss: 0.0333 - mean_absolute_error: 0.1323 - val_loss: 0.1288 - val_mean_absolute_error: 0.2064\n",
      "Epoch 174/300\n",
      "203/203 [==============================] - 0s 801us/step - loss: 0.0314 - mean_absolute_error: 0.1306 - val_loss: 0.1268 - val_mean_absolute_error: 0.2056\n",
      "Epoch 175/300\n",
      "203/203 [==============================] - 0s 820us/step - loss: 0.0315 - mean_absolute_error: 0.1307 - val_loss: 0.1315 - val_mean_absolute_error: 0.2060\n",
      "Epoch 176/300\n",
      "203/203 [==============================] - 0s 802us/step - loss: 0.0320 - mean_absolute_error: 0.1316 - val_loss: 0.1354 - val_mean_absolute_error: 0.2127\n",
      "Epoch 177/300\n",
      "203/203 [==============================] - 0s 760us/step - loss: 0.0341 - mean_absolute_error: 0.1337 - val_loss: 0.1365 - val_mean_absolute_error: 0.2093\n",
      "Epoch 178/300\n",
      "203/203 [==============================] - 0s 761us/step - loss: 0.0378 - mean_absolute_error: 0.1384 - val_loss: 0.1325 - val_mean_absolute_error: 0.2074\n",
      "Epoch 179/300\n",
      "203/203 [==============================] - 0s 748us/step - loss: 0.0324 - mean_absolute_error: 0.1316 - val_loss: 0.1310 - val_mean_absolute_error: 0.2108\n",
      "Epoch 180/300\n",
      "203/203 [==============================] - 0s 819us/step - loss: 0.0307 - mean_absolute_error: 0.1292 - val_loss: 0.1302 - val_mean_absolute_error: 0.2051\n",
      "Epoch 181/300\n",
      "203/203 [==============================] - 0s 788us/step - loss: 0.0305 - mean_absolute_error: 0.1292 - val_loss: 0.1286 - val_mean_absolute_error: 0.2080\n",
      "Epoch 182/300\n",
      "203/203 [==============================] - 0s 770us/step - loss: 0.0349 - mean_absolute_error: 0.1352 - val_loss: 0.1303 - val_mean_absolute_error: 0.2081\n",
      "Epoch 183/300\n",
      "203/203 [==============================] - 0s 829us/step - loss: 0.0329 - mean_absolute_error: 0.1323 - val_loss: 0.1321 - val_mean_absolute_error: 0.2081\n",
      "Epoch 184/300\n",
      "203/203 [==============================] - 0s 779us/step - loss: 0.0328 - mean_absolute_error: 0.1312 - val_loss: 0.1319 - val_mean_absolute_error: 0.2064\n",
      "Epoch 185/300\n",
      "203/203 [==============================] - 0s 789us/step - loss: 0.0314 - mean_absolute_error: 0.1299 - val_loss: 0.1324 - val_mean_absolute_error: 0.2111\n",
      "Epoch 186/300\n",
      "203/203 [==============================] - 0s 803us/step - loss: 0.0330 - mean_absolute_error: 0.1319 - val_loss: 0.1359 - val_mean_absolute_error: 0.2096\n",
      "Epoch 187/300\n",
      "203/203 [==============================] - 0s 809us/step - loss: 0.0347 - mean_absolute_error: 0.1349 - val_loss: 0.1292 - val_mean_absolute_error: 0.2057\n",
      "Epoch 188/300\n",
      "203/203 [==============================] - 0s 772us/step - loss: 0.0384 - mean_absolute_error: 0.1381 - val_loss: 0.1382 - val_mean_absolute_error: 0.2150\n",
      "Epoch 189/300\n",
      "203/203 [==============================] - 0s 769us/step - loss: 0.0330 - mean_absolute_error: 0.1330 - val_loss: 0.1340 - val_mean_absolute_error: 0.2124\n",
      "Epoch 190/300\n",
      "203/203 [==============================] - 0s 742us/step - loss: 0.0311 - mean_absolute_error: 0.1298 - val_loss: 0.1289 - val_mean_absolute_error: 0.2095\n",
      "Epoch 191/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 0s 829us/step - loss: 0.0298 - mean_absolute_error: 0.1275 - val_loss: 0.1300 - val_mean_absolute_error: 0.2066\n",
      "Epoch 192/300\n",
      "203/203 [==============================] - 0s 794us/step - loss: 0.0300 - mean_absolute_error: 0.1278 - val_loss: 0.1307 - val_mean_absolute_error: 0.2064\n",
      "Epoch 193/300\n",
      "203/203 [==============================] - 0s 777us/step - loss: 0.0318 - mean_absolute_error: 0.1308 - val_loss: 0.1275 - val_mean_absolute_error: 0.2069\n",
      "Epoch 194/300\n",
      "203/203 [==============================] - 0s 741us/step - loss: 0.0324 - mean_absolute_error: 0.1320 - val_loss: 0.1332 - val_mean_absolute_error: 0.2093\n",
      "Epoch 195/300\n",
      "203/203 [==============================] - 0s 761us/step - loss: 0.0409 - mean_absolute_error: 0.1404 - val_loss: 0.1309 - val_mean_absolute_error: 0.2071\n",
      "Epoch 196/300\n",
      "203/203 [==============================] - 0s 898us/step - loss: 0.0355 - mean_absolute_error: 0.1337 - val_loss: 0.1378 - val_mean_absolute_error: 0.2151\n",
      "Epoch 197/300\n",
      "203/203 [==============================] - 0s 845us/step - loss: 0.0325 - mean_absolute_error: 0.1313 - val_loss: 0.1296 - val_mean_absolute_error: 0.2095\n",
      "Epoch 198/300\n",
      "203/203 [==============================] - 0s 779us/step - loss: 0.0295 - mean_absolute_error: 0.1270 - val_loss: 0.1296 - val_mean_absolute_error: 0.2069\n",
      "Epoch 199/300\n",
      "203/203 [==============================] - 0s 737us/step - loss: 0.0307 - mean_absolute_error: 0.1293 - val_loss: 0.1310 - val_mean_absolute_error: 0.2075\n",
      "Epoch 200/300\n",
      "203/203 [==============================] - 0s 747us/step - loss: 0.0309 - mean_absolute_error: 0.1287 - val_loss: 0.1375 - val_mean_absolute_error: 0.2159\n",
      "Epoch 201/300\n",
      "203/203 [==============================] - 0s 749us/step - loss: 0.0303 - mean_absolute_error: 0.1277 - val_loss: 0.1387 - val_mean_absolute_error: 0.2137\n",
      "Epoch 202/300\n",
      "203/203 [==============================] - 0s 771us/step - loss: 0.0299 - mean_absolute_error: 0.1272 - val_loss: 0.1301 - val_mean_absolute_error: 0.2089\n",
      "Epoch 203/300\n",
      "203/203 [==============================] - 0s 840us/step - loss: 0.0297 - mean_absolute_error: 0.1281 - val_loss: 0.1329 - val_mean_absolute_error: 0.2097\n",
      "Epoch 204/300\n",
      "203/203 [==============================] - 0s 775us/step - loss: 0.0309 - mean_absolute_error: 0.1287 - val_loss: 0.1370 - val_mean_absolute_error: 0.2121\n",
      "Epoch 205/300\n",
      "203/203 [==============================] - 0s 744us/step - loss: 0.0332 - mean_absolute_error: 0.1321 - val_loss: 0.1560 - val_mean_absolute_error: 0.2212\n",
      "Epoch 206/300\n",
      "203/203 [==============================] - 0s 748us/step - loss: 0.0328 - mean_absolute_error: 0.1321 - val_loss: 0.1384 - val_mean_absolute_error: 0.2109\n",
      "Epoch 207/300\n",
      "203/203 [==============================] - 0s 823us/step - loss: 0.0316 - mean_absolute_error: 0.1291 - val_loss: 0.1392 - val_mean_absolute_error: 0.2110\n",
      "Epoch 208/300\n",
      "203/203 [==============================] - 0s 774us/step - loss: 0.0304 - mean_absolute_error: 0.1285 - val_loss: 0.1388 - val_mean_absolute_error: 0.2116\n",
      "Epoch 209/300\n",
      "203/203 [==============================] - 0s 738us/step - loss: 0.0378 - mean_absolute_error: 0.1366 - val_loss: 0.1311 - val_mean_absolute_error: 0.2076\n",
      "Epoch 210/300\n",
      "203/203 [==============================] - 0s 779us/step - loss: 0.0315 - mean_absolute_error: 0.1281 - val_loss: 0.1398 - val_mean_absolute_error: 0.2117\n",
      "Epoch 211/300\n",
      "203/203 [==============================] - 0s 774us/step - loss: 0.0294 - mean_absolute_error: 0.1265 - val_loss: 0.1300 - val_mean_absolute_error: 0.2070\n",
      "Epoch 212/300\n",
      "203/203 [==============================] - 0s 751us/step - loss: 0.0287 - mean_absolute_error: 0.1256 - val_loss: 0.1341 - val_mean_absolute_error: 0.2073\n",
      "Epoch 213/300\n",
      "203/203 [==============================] - 0s 795us/step - loss: 0.0301 - mean_absolute_error: 0.1280 - val_loss: 0.1347 - val_mean_absolute_error: 0.2080\n",
      "Epoch 214/300\n",
      "203/203 [==============================] - 0s 857us/step - loss: 0.0430 - mean_absolute_error: 0.1414 - val_loss: 0.1336 - val_mean_absolute_error: 0.2075\n",
      "Epoch 215/300\n",
      "203/203 [==============================] - 0s 825us/step - loss: 0.0349 - mean_absolute_error: 0.1336 - val_loss: 0.1295 - val_mean_absolute_error: 0.2081\n",
      "Epoch 216/300\n",
      "203/203 [==============================] - 0s 815us/step - loss: 0.0303 - mean_absolute_error: 0.1278 - val_loss: 0.1356 - val_mean_absolute_error: 0.2083\n",
      "Epoch 217/300\n",
      "203/203 [==============================] - 0s 755us/step - loss: 0.0277 - mean_absolute_error: 0.1229 - val_loss: 0.1339 - val_mean_absolute_error: 0.2081\n",
      "Epoch 218/300\n",
      "203/203 [==============================] - 0s 738us/step - loss: 0.0281 - mean_absolute_error: 0.1237 - val_loss: 0.1307 - val_mean_absolute_error: 0.2061\n",
      "Epoch 219/300\n",
      "203/203 [==============================] - 0s 754us/step - loss: 0.0282 - mean_absolute_error: 0.1250 - val_loss: 0.1358 - val_mean_absolute_error: 0.2109\n",
      "Epoch 220/300\n",
      "203/203 [==============================] - 0s 765us/step - loss: 0.0294 - mean_absolute_error: 0.1263 - val_loss: 0.1328 - val_mean_absolute_error: 0.2091\n",
      "Epoch 221/300\n",
      "203/203 [==============================] - 0s 776us/step - loss: 0.0301 - mean_absolute_error: 0.1277 - val_loss: 0.1324 - val_mean_absolute_error: 0.2082\n",
      "Epoch 222/300\n",
      "203/203 [==============================] - 0s 786us/step - loss: 0.0297 - mean_absolute_error: 0.1272 - val_loss: 0.1374 - val_mean_absolute_error: 0.2082\n",
      "Epoch 223/300\n",
      "203/203 [==============================] - 0s 791us/step - loss: 0.0286 - mean_absolute_error: 0.1250 - val_loss: 0.1339 - val_mean_absolute_error: 0.2077\n",
      "Epoch 224/300\n",
      "203/203 [==============================] - 0s 748us/step - loss: 0.0307 - mean_absolute_error: 0.1284 - val_loss: 0.1341 - val_mean_absolute_error: 0.2084\n",
      "Epoch 225/300\n",
      "203/203 [==============================] - 0s 747us/step - loss: 0.0383 - mean_absolute_error: 0.1360 - val_loss: 0.1332 - val_mean_absolute_error: 0.2076\n",
      "Epoch 226/300\n",
      "203/203 [==============================] - 0s 778us/step - loss: 0.0356 - mean_absolute_error: 0.1333 - val_loss: 0.1300 - val_mean_absolute_error: 0.2048\n",
      "Epoch 227/300\n",
      "203/203 [==============================] - 0s 779us/step - loss: 0.0295 - mean_absolute_error: 0.1267 - val_loss: 0.1322 - val_mean_absolute_error: 0.2076\n",
      "Epoch 228/300\n",
      "203/203 [==============================] - 0s 756us/step - loss: 0.0288 - mean_absolute_error: 0.1263 - val_loss: 0.1327 - val_mean_absolute_error: 0.2091\n",
      "Epoch 229/300\n",
      "203/203 [==============================] - 0s 757us/step - loss: 0.0277 - mean_absolute_error: 0.1226 - val_loss: 0.1337 - val_mean_absolute_error: 0.2099\n",
      "Epoch 230/300\n",
      "203/203 [==============================] - 0s 774us/step - loss: 0.0300 - mean_absolute_error: 0.1278 - val_loss: 0.1414 - val_mean_absolute_error: 0.2133\n",
      "Epoch 231/300\n",
      "203/203 [==============================] - 0s 787us/step - loss: 0.0298 - mean_absolute_error: 0.1268 - val_loss: 0.1312 - val_mean_absolute_error: 0.2065\n",
      "Epoch 232/300\n",
      "203/203 [==============================] - 0s 758us/step - loss: 0.0304 - mean_absolute_error: 0.1273 - val_loss: 0.1356 - val_mean_absolute_error: 0.2099\n",
      "Epoch 233/300\n",
      "203/203 [==============================] - 0s 788us/step - loss: 0.0286 - mean_absolute_error: 0.1249 - val_loss: 0.1347 - val_mean_absolute_error: 0.2120\n",
      "Epoch 234/300\n",
      "203/203 [==============================] - 0s 769us/step - loss: 0.0274 - mean_absolute_error: 0.1232 - val_loss: 0.1374 - val_mean_absolute_error: 0.2142\n",
      "Epoch 235/300\n",
      "203/203 [==============================] - 0s 754us/step - loss: 0.0281 - mean_absolute_error: 0.1244 - val_loss: 0.1344 - val_mean_absolute_error: 0.2106\n",
      "Epoch 236/300\n",
      "203/203 [==============================] - 0s 759us/step - loss: 0.0345 - mean_absolute_error: 0.1325 - val_loss: 0.1375 - val_mean_absolute_error: 0.2117\n",
      "Epoch 237/300\n",
      "203/203 [==============================] - 0s 747us/step - loss: 0.0309 - mean_absolute_error: 0.1289 - val_loss: 0.1370 - val_mean_absolute_error: 0.2099\n",
      "Epoch 238/300\n",
      "203/203 [==============================] - 0s 750us/step - loss: 0.0283 - mean_absolute_error: 0.1244 - val_loss: 0.1421 - val_mean_absolute_error: 0.2116\n",
      "Epoch 239/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 0s 840us/step - loss: 0.0283 - mean_absolute_error: 0.1252 - val_loss: 0.1348 - val_mean_absolute_error: 0.2111\n",
      "Epoch 240/300\n",
      "203/203 [==============================] - 0s 850us/step - loss: 0.0281 - mean_absolute_error: 0.1240 - val_loss: 0.1289 - val_mean_absolute_error: 0.2079\n",
      "Epoch 241/300\n",
      "203/203 [==============================] - 0s 796us/step - loss: 0.0303 - mean_absolute_error: 0.1274 - val_loss: 0.1331 - val_mean_absolute_error: 0.2068\n",
      "Epoch 242/300\n",
      "203/203 [==============================] - 0s 792us/step - loss: 0.0353 - mean_absolute_error: 0.1337 - val_loss: 0.1355 - val_mean_absolute_error: 0.2116\n",
      "Epoch 243/300\n",
      "203/203 [==============================] - 0s 779us/step - loss: 0.0306 - mean_absolute_error: 0.1275 - val_loss: 0.1795 - val_mean_absolute_error: 0.2259\n",
      "Epoch 244/300\n",
      "203/203 [==============================] - 0s 729us/step - loss: 0.0449 - mean_absolute_error: 0.1415 - val_loss: 0.1384 - val_mean_absolute_error: 0.2135\n",
      "Epoch 245/300\n",
      "203/203 [==============================] - 0s 804us/step - loss: 0.0402 - mean_absolute_error: 0.1361 - val_loss: 0.1352 - val_mean_absolute_error: 0.2162\n",
      "Epoch 246/300\n",
      "203/203 [==============================] - 0s 782us/step - loss: 0.0283 - mean_absolute_error: 0.1235 - val_loss: 0.1330 - val_mean_absolute_error: 0.2103\n",
      "Epoch 247/300\n",
      "203/203 [==============================] - 0s 751us/step - loss: 0.0283 - mean_absolute_error: 0.1241 - val_loss: 0.1328 - val_mean_absolute_error: 0.2081\n",
      "Epoch 248/300\n",
      "203/203 [==============================] - 0s 753us/step - loss: 0.0260 - mean_absolute_error: 0.1202 - val_loss: 0.1349 - val_mean_absolute_error: 0.2096\n",
      "Epoch 249/300\n",
      "203/203 [==============================] - 0s 748us/step - loss: 0.0264 - mean_absolute_error: 0.1215 - val_loss: 0.1311 - val_mean_absolute_error: 0.2081\n",
      "Epoch 250/300\n",
      "203/203 [==============================] - 0s 765us/step - loss: 0.0268 - mean_absolute_error: 0.1227 - val_loss: 0.1370 - val_mean_absolute_error: 0.2112\n",
      "Epoch 251/300\n",
      "203/203 [==============================] - 0s 821us/step - loss: 0.0267 - mean_absolute_error: 0.1213 - val_loss: 0.1321 - val_mean_absolute_error: 0.2112\n",
      "Epoch 252/300\n",
      "203/203 [==============================] - 0s 786us/step - loss: 0.0275 - mean_absolute_error: 0.1228 - val_loss: 0.1379 - val_mean_absolute_error: 0.2143\n",
      "Epoch 253/300\n",
      "203/203 [==============================] - 0s 766us/step - loss: 0.0352 - mean_absolute_error: 0.1324 - val_loss: 0.1370 - val_mean_absolute_error: 0.2104\n",
      "Epoch 254/300\n",
      "203/203 [==============================] - 0s 754us/step - loss: 0.0308 - mean_absolute_error: 0.1259 - val_loss: 0.1604 - val_mean_absolute_error: 0.2212\n",
      "Epoch 255/300\n",
      "203/203 [==============================] - 0s 749us/step - loss: 0.0351 - mean_absolute_error: 0.1329 - val_loss: 0.1405 - val_mean_absolute_error: 0.2170\n",
      "Epoch 256/300\n",
      "203/203 [==============================] - 0s 746us/step - loss: 0.0300 - mean_absolute_error: 0.1269 - val_loss: 0.1333 - val_mean_absolute_error: 0.2073\n",
      "Epoch 257/300\n",
      "203/203 [==============================] - 0s 754us/step - loss: 0.0287 - mean_absolute_error: 0.1255 - val_loss: 0.1303 - val_mean_absolute_error: 0.2074\n",
      "Epoch 258/300\n",
      "203/203 [==============================] - 0s 788us/step - loss: 0.0314 - mean_absolute_error: 0.1279 - val_loss: 0.1338 - val_mean_absolute_error: 0.2084\n",
      "Epoch 259/300\n",
      "203/203 [==============================] - 0s 752us/step - loss: 0.0312 - mean_absolute_error: 0.1272 - val_loss: 0.1342 - val_mean_absolute_error: 0.2099\n",
      "Epoch 260/300\n",
      "203/203 [==============================] - 0s 762us/step - loss: 0.0280 - mean_absolute_error: 0.1243 - val_loss: 0.1377 - val_mean_absolute_error: 0.2170\n",
      "Epoch 261/300\n",
      "203/203 [==============================] - 0s 739us/step - loss: 0.0269 - mean_absolute_error: 0.1223 - val_loss: 0.1325 - val_mean_absolute_error: 0.2080\n",
      "Epoch 262/300\n",
      "203/203 [==============================] - 0s 751us/step - loss: 0.0262 - mean_absolute_error: 0.1205 - val_loss: 0.1338 - val_mean_absolute_error: 0.2079\n",
      "Epoch 263/300\n",
      "203/203 [==============================] - 0s 748us/step - loss: 0.0266 - mean_absolute_error: 0.1221 - val_loss: 0.1331 - val_mean_absolute_error: 0.2084\n",
      "Epoch 264/300\n",
      "203/203 [==============================] - 0s 754us/step - loss: 0.0262 - mean_absolute_error: 0.1206 - val_loss: 0.1353 - val_mean_absolute_error: 0.2104\n",
      "Epoch 265/300\n",
      "203/203 [==============================] - 0s 756us/step - loss: 0.0271 - mean_absolute_error: 0.1225 - val_loss: 0.1322 - val_mean_absolute_error: 0.2089\n",
      "Epoch 266/300\n",
      "203/203 [==============================] - 0s 738us/step - loss: 0.0269 - mean_absolute_error: 0.1223 - val_loss: 0.1356 - val_mean_absolute_error: 0.2126\n",
      "Epoch 267/300\n",
      "203/203 [==============================] - 0s 755us/step - loss: 0.0267 - mean_absolute_error: 0.1219 - val_loss: 0.1391 - val_mean_absolute_error: 0.2118\n",
      "Epoch 268/300\n",
      "203/203 [==============================] - 0s 759us/step - loss: 0.0275 - mean_absolute_error: 0.1231 - val_loss: 0.1369 - val_mean_absolute_error: 0.2105\n",
      "Epoch 269/300\n",
      "203/203 [==============================] - 0s 756us/step - loss: 0.0336 - mean_absolute_error: 0.1319 - val_loss: 0.1440 - val_mean_absolute_error: 0.2161\n",
      "Epoch 270/300\n",
      "203/203 [==============================] - 0s 753us/step - loss: 0.0388 - mean_absolute_error: 0.1382 - val_loss: 0.1397 - val_mean_absolute_error: 0.2105\n",
      "Epoch 271/300\n",
      "203/203 [==============================] - 0s 821us/step - loss: 0.0340 - mean_absolute_error: 0.1297 - val_loss: 0.1317 - val_mean_absolute_error: 0.2095\n",
      "Epoch 272/300\n",
      "203/203 [==============================] - 0s 792us/step - loss: 0.0293 - mean_absolute_error: 0.1254 - val_loss: 0.1343 - val_mean_absolute_error: 0.2135\n",
      "Epoch 273/300\n",
      "203/203 [==============================] - 0s 800us/step - loss: 0.0287 - mean_absolute_error: 0.1241 - val_loss: 0.1337 - val_mean_absolute_error: 0.2074\n",
      "Epoch 274/300\n",
      "203/203 [==============================] - 0s 767us/step - loss: 0.0265 - mean_absolute_error: 0.1211 - val_loss: 0.1287 - val_mean_absolute_error: 0.2059\n",
      "Epoch 275/300\n",
      "203/203 [==============================] - 0s 749us/step - loss: 0.0265 - mean_absolute_error: 0.1209 - val_loss: 0.1329 - val_mean_absolute_error: 0.2083\n",
      "Epoch 276/300\n",
      "203/203 [==============================] - 0s 740us/step - loss: 0.0273 - mean_absolute_error: 0.1227 - val_loss: 0.1330 - val_mean_absolute_error: 0.2076\n",
      "Epoch 277/300\n",
      "203/203 [==============================] - 0s 813us/step - loss: 0.0265 - mean_absolute_error: 0.1207 - val_loss: 0.1317 - val_mean_absolute_error: 0.2087\n",
      "Epoch 278/300\n",
      "203/203 [==============================] - 0s 798us/step - loss: 0.0260 - mean_absolute_error: 0.1203 - val_loss: 0.1332 - val_mean_absolute_error: 0.2104\n",
      "Epoch 279/300\n",
      "203/203 [==============================] - 0s 752us/step - loss: 0.0289 - mean_absolute_error: 0.1249 - val_loss: 0.1374 - val_mean_absolute_error: 0.2115\n",
      "Epoch 280/300\n",
      "203/203 [==============================] - 0s 804us/step - loss: 0.0289 - mean_absolute_error: 0.1234 - val_loss: 0.1487 - val_mean_absolute_error: 0.2280\n",
      "Epoch 281/300\n",
      "203/203 [==============================] - 0s 800us/step - loss: 0.0340 - mean_absolute_error: 0.1313 - val_loss: 0.1359 - val_mean_absolute_error: 0.2175\n",
      "Epoch 282/300\n",
      "203/203 [==============================] - 0s 763us/step - loss: 0.0279 - mean_absolute_error: 0.1228 - val_loss: 0.1361 - val_mean_absolute_error: 0.2108\n",
      "Epoch 283/300\n",
      "203/203 [==============================] - 0s 869us/step - loss: 0.0265 - mean_absolute_error: 0.1216 - val_loss: 0.1363 - val_mean_absolute_error: 0.2111\n",
      "Epoch 284/300\n",
      "203/203 [==============================] - 0s 797us/step - loss: 0.0261 - mean_absolute_error: 0.1208 - val_loss: 0.1344 - val_mean_absolute_error: 0.2085\n",
      "Epoch 285/300\n",
      "203/203 [==============================] - 0s 815us/step - loss: 0.0263 - mean_absolute_error: 0.1212 - val_loss: 0.1373 - val_mean_absolute_error: 0.2115\n",
      "Epoch 286/300\n",
      "203/203 [==============================] - 0s 790us/step - loss: 0.0308 - mean_absolute_error: 0.1280 - val_loss: 0.1321 - val_mean_absolute_error: 0.2082\n",
      "Epoch 287/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 0s 808us/step - loss: 0.0315 - mean_absolute_error: 0.1266 - val_loss: 0.1450 - val_mean_absolute_error: 0.2181\n",
      "Epoch 288/300\n",
      "203/203 [==============================] - 0s 809us/step - loss: 0.0410 - mean_absolute_error: 0.1374 - val_loss: 0.1335 - val_mean_absolute_error: 0.2103\n",
      "Epoch 289/300\n",
      "203/203 [==============================] - 0s 857us/step - loss: 0.0324 - mean_absolute_error: 0.1291 - val_loss: 0.1484 - val_mean_absolute_error: 0.2184\n",
      "Epoch 290/300\n",
      "203/203 [==============================] - 0s 794us/step - loss: 0.0286 - mean_absolute_error: 0.1244 - val_loss: 0.1341 - val_mean_absolute_error: 0.2157\n",
      "Epoch 291/300\n",
      "203/203 [==============================] - 0s 850us/step - loss: 0.0264 - mean_absolute_error: 0.1211 - val_loss: 0.1345 - val_mean_absolute_error: 0.2100\n",
      "Epoch 292/300\n",
      "203/203 [==============================] - 0s 788us/step - loss: 0.0254 - mean_absolute_error: 0.1184 - val_loss: 0.1348 - val_mean_absolute_error: 0.2118\n",
      "Epoch 293/300\n",
      "203/203 [==============================] - 0s 793us/step - loss: 0.0246 - mean_absolute_error: 0.1170 - val_loss: 0.1337 - val_mean_absolute_error: 0.2097\n",
      "Epoch 294/300\n",
      "203/203 [==============================] - 0s 748us/step - loss: 0.0254 - mean_absolute_error: 0.1188 - val_loss: 0.1358 - val_mean_absolute_error: 0.2131\n",
      "Epoch 295/300\n",
      "203/203 [==============================] - 0s 845us/step - loss: 0.0254 - mean_absolute_error: 0.1193 - val_loss: 0.1345 - val_mean_absolute_error: 0.2142\n",
      "Epoch 296/300\n",
      "203/203 [==============================] - 0s 767us/step - loss: 0.0361 - mean_absolute_error: 0.1341 - val_loss: 0.1410 - val_mean_absolute_error: 0.2129\n",
      "Epoch 297/300\n",
      "203/203 [==============================] - 0s 847us/step - loss: 0.0308 - mean_absolute_error: 0.1260 - val_loss: 0.1384 - val_mean_absolute_error: 0.2131\n",
      "Epoch 298/300\n",
      "203/203 [==============================] - 0s 781us/step - loss: 0.0267 - mean_absolute_error: 0.1204 - val_loss: 0.1387 - val_mean_absolute_error: 0.2114\n",
      "Epoch 299/300\n",
      "203/203 [==============================] - 0s 785us/step - loss: 0.0254 - mean_absolute_error: 0.1187 - val_loss: 0.1356 - val_mean_absolute_error: 0.2104\n",
      "Epoch 300/300\n",
      "203/203 [==============================] - 0s 794us/step - loss: 0.0255 - mean_absolute_error: 0.1193 - val_loss: 0.1348 - val_mean_absolute_error: 0.2101\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,  # 傳入訓練數據\n",
    "               batch_size=64,  # 批次大小設為64\n",
    "               epochs=300,  # 整個dataset訓練300遍\n",
    "               validation_data=(x_val, y_val),  # 驗證數據\n",
    "               callbacks=[model_cbk, model_mckp])  # Tensorboard回調函數紀錄訓練過程，ModelCheckpoint回調函數儲存最好的模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'mean_absolute_error', 'val_loss', 'val_mean_absolute_error'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()  # 查看history儲存的資訊有哪些"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1f49177cc88>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAABjpklEQVR4nO2dd3gc1fW/3yNp1Xu1Lbn3ihu2wWB6MYTeDKGG4EAghCQkkArJN/mFJISSRg29ODQDoZfQwbh3495ky7IsWcXq0t7fH3dGu5J2pZWttST7vM+jZ2dn7sze0Ur3M6fcc8UYg6IoiqKESkRXd0BRFEXpWahwKIqiKB1ChUNRFEXpECociqIoSodQ4VAURVE6hAqHoiiK0iFUOBRFUZQOocKh9AhEZIuI1IlIZov9S0XEiMiALuqaohx2qHAoPYnNwKXuGxEZC8R1XXe6FhGJCuO1RUQiWuzr0OeFs39K16LCofQkngau9Ht/FfCUfwMRiRGRu0Vkm4gUisiDIhLnHEsTkTdEpEhE9jrbeX7nfiwi/yciX4hIhYi819LC8Wub6ZxfKiIlIvKZO9CKyAQRWexc4z8iMkdEfu8cu1pEPm9xLSMiQ5ztM0VkiYiUi8h2EbnTr90Ap+21IrIN+J+z/zsissa5p3dFpH+wX6CITBORL51+LxOR41vc/x9E5AugChjkfN6NIrIeWO+0u05ENjj3/bqI9GlxL83aK4ceKhxKT2IekCwiI0UkErgEeKZFmz8Bw4DxwBAgF/iNcywCeBzoD/QDqoF/tDj/MuAaIBuIBm4N0pefAPlAFpAD/AIwIhINvIoVuXTgReCCDtxjJVYcU4EzgRtE5NwWbY4DRgKnOcd+AZzv9OUz4PlAFxaRXOBN4PdO324FXhaRLL9mVwCzgSRgq7PvXGAqMEpETgT+CFwM9HbazGnxUU3tQ7xnpYehwqH0NFyr4xTgG2CHe0BEBLgO+JExpsQYUwH8P2AWgDGm2BjzsjGmyjn2B+wg7M/jxph1xphq4AWsAAWiHjtw9jfG1BtjPjO28Ns0wAPc5+x/CVgQ6s0ZYz42xqwwxniNMcuxItCyj3caYyqdPn4P+KMxZo0xpsG53/FBrI7LgbeMMW85138fWAic4dfmCWPMKmNMgzGm3tn3R+f3WQ18G3jMGLPYGFML/Bw4qkWMyb+9cgiiwqH0NJ7GWgVX08JNhX3ijgcWOa6YUuAdZz8iEi8iD4nIVhEpBz4FUh3rxWWX33YVkBikH38BNgDvicgmEbnd2d8H2GGaVw/d2ursIIjIVBH5yHGnlQHXAy3dZdv9tvsD9/vdbwkgWEurJf2Bi9y2TvtjsAIY6NqB9vXxvx9jzD6guMXnBbqGcgihwqH0KIwxW7FB8jOAV1oc3oN1P402xqQ6PynGGHfw/wkwHJhqjEkGZjj7ZT/6UWGM+YkxZhBwFvBjETkJKAByHevHpZ/fdiVW3OwHi/RqcenngNeBvsaYFODBAP3zF6XtwPf87jfVGBNnjPkyQLe3A0+3aJtgjLkryLUD7duJFSC3/wlABn6WX5BrKIcQKhxKT+Ra4ERjTKX/TmOMF3gEuFdEssH69UXkNKdJElZYSkUkHbhjfzsgIt8SkSGOQJQDjc7PV0ADcLOIRInI+cAUv1OXAaNFZLyIxAJ3trh0ElBijKkRkSlY66otHgR+LiKjnX6liMhFQdo+A5wlIqeJSKSIxIrI8f4JAiHwHHCN0/8YrGvsa2PMlg5cQ+nhqHAoPQ5jzEZjzMIgh2/DupDmOe6oD7BWBsB92PTdPdhA+zsH0I2hzrX3YcXiX058og4bqL4a2IsN4DdZRsaYdcDvnHPXA583vyzfB34nIhXYoP4LbXXCGDMXmxAwx7nflcDMIG23A+dgg+lFWAvkp3RgHDDGfAj8GngZa10NxokhKYcPogs5KUp4EZEngHxjzK+6ui+K0hmoxaEoiqJ0iLAKh4icLiJrnclCtwc4/m0RWe78fCkiR7R3roiki8j7IrLeeU0L5z0oiqIozQmbq8pJcVyHzbfPx+ayX2qMWe3X5mhgjTFmr4jMxOanT23rXBH5MzZ4eJcjKGnGmNvCchOKoihKK8JpcUwBNhhjNjkBwznYwFwTxpgvjTF7nbfzgLwQzj0HeNLZfhI7S1VRFEU5SISzCFkuzScC5WPLEATjWuDtEM7NMcYUABhjCty0y5aIyGxs6QQSEhImjRgxosM3AFBdsoO4mt3UZ4/DExXZ/gmKoiiHCIsWLdpjjMlquT+cwhFoUlVAv5iInIAVjmM6em4wjDEPAw8DTJ482SxcGCx7s21WvvA7xqz+K1u+9x4Derf6/SmKohyyiEjAqgfhdFXlA3393udhZ502Q0TGAY8C5xhjikM4t1BEejvn9gZ2d3K/mxERFQNAXZ2W3VEURYHwCscCYKiIDHQqhs7CllJoQkT6YSdHXeFMjArl3Nex5bRxXl8L4z0Q4YkGoKG2NpwfoyiK0mMIm6vKGNMgIjcB7wKR2Iqaq0Tkeuf4g9iZsRnAv5zSPg3GmMnBznUufRfwgohcC2wDgpVX6BQiHYujvl6FQ1EUBcIb48AY8xbwVot9D/ptfxf4bqjnOvuLgZM6t6fBcS2OerU4FKVbUF9fT35+PjU1NV3dlUOG2NhY8vLy8Hg8IbXXpR3bIcpjLY6Gev0jVZTuQH5+PklJSQwYMIDmRYiV/cEYQ3FxMfn5+QwcODCkc7TkSDtERjsxjrq6Lu6JoigANTU1ZGRkqGh0EiJCRkZGhyw4FY52cGMcDRrjUJRug4pG59LR36cKRzt4omMBaFThUBRFAVQ42iUq2locKhyKoriUlpbyr3/9q8PnnXHGGZSWlnZ+hw4yKhzt4HGFo0FjHIqiWIIJR2NjY5vnvfXWW6SmpoapVwcPzapqB1c4vPUqHIqiWG6//XY2btzI+PHj8Xg8JCYm0rt3b5YuXcrq1as599xz2b59OzU1Nfzwhz9k9uzZAAwYMICFCxeyb98+Zs6cyTHHHMOXX35Jbm4ur732GnFxcV18Z6GhwtEOHicd16sWh6J0O37731Ws3lneqdcc1SeZO84a3Wabu+66i5UrV7J06VI+/vhjzjzzTFauXNmUzvrYY4+Rnp5OdXU1Rx55JBdccAEZGRnNrrF+/Xqef/55HnnkES6++GJefvllLr/88k69l3ChwtEOEuUKh8Y4FEUJzJQpU5rNgfjb3/7G3LlzAdi+fTvr169vJRwDBw5k/PjxAEyaNIktW7YcrO4eMCoc7RFpZ1KaRrU4FKW70Z5lcLBISEho2v7444/54IMP+Oqrr4iPj+f4448POEciJiamaTsyMpLq6p5TSFWD4+0RaScAqqtKURSXpKQkKioqAh4rKysjLS2N+Ph4vvnmG+bNm3eQexd+1OJoD0c4UOFQFMUhIyOD6dOnM2bMGOLi4sjJyWk6dvrpp/Pggw8ybtw4hg8fzrRp07qwp+FBhaM9HFcVjfVd2w9FUboVzz33XMD9MTExvP322wGPuXGMzMxMVq5c2bT/1ltv7fT+hRN1VbWHY3GYRg2OK4qigApH+7iuKrU4FEVRABWO9omIxEsEosKhKIoCqHCERANRiFeD44qiKKDCERINEqUWh6IoioMKRwg0RniI8KpwKMohgfFCxS7weru6Jz0WFY4QaBQPosKhKIcGdZVQUQD1lQftIxMTEwHYuXMnF154YcA2xx9/PAsXLmzzOvfddx9VVVVN77uqTLsKRwh4xUOEUeFQlEMCY5q/HkT69OnDSy+9tN/ntxSOrirTHlbhEJHTRWStiGwQkdsDHB8hIl+JSK2I3Oq3f7iILPX7KReRW5xjd4rIDr9jZ4TzHgC8EVFEqsWhKIcIBy4ct912W7P1OO68805++9vfctJJJzFx4kTGjh3La6+91uq8LVu2MGbMGACqq6uZNWsW48aN45JLLmlWq+qGG25g8uTJjB49mjvuuAOwhRN37tzJCSecwAknnADYMu179uwB4J577mHMmDGMGTOG++67r+nzRo4cyXXXXcfo0aM59dRTO6UmVthmjotIJPBP4BQgH1ggIq8bY1b7NSsBbgbO9T/XGLMWGO93nR3AXL8m9xpj7g5X31vijVCLQ1G6JW/fDrtWdOwcbwM0VENULER4Wh/vNRZm3tXmJWbNmsUtt9zC97//fQBeeOEF3nnnHX70ox+RnJzMnj17mDZtGmeffXbQ9bwfeOAB4uPjWb58OcuXL2fixIlNx/7whz+Qnp5OY2MjJ510EsuXL+fmm2/mnnvu4aOPPiIzM7PZtRYtWsTjjz/O119/jTGGqVOnctxxx5GWlhaW8u3htDimABuMMZuMMXXAHOAc/wbGmN3GmAVAW6PyScBGY8zW8HW1bUxENJHeekwXmLaKonQ2B/5/PGHCBHbv3s3OnTtZtmwZaWlp9O7dm1/84heMGzeOk08+mR07dlBYWBj0Gp9++mnTAD5u3DjGjRvXdOyFF15g4sSJTJgwgVWrVrF69epglwHg888/57zzziMhIYHExETOP/98PvvsMyA85dvDWasqF9ju9z4fmLof15kFPN9i300iciWwEPiJMWbv/nUxNEykBw8N1DZ4ifVEhvOjFEXpCO1YBgGpKoHSrZDaD+Iz2m8fhAsvvJCXXnqJXbt2MWvWLJ599lmKiopYtGgRHo+HAQMGBCyn7k8ga2Tz5s3cfffdLFiwgLS0NK6++up2r9PWQ204yreH0+IIZJ91SOpFJBo4G3jRb/cDwGCsK6sA+GuQc2eLyEIRWVhUVNSRj21NRDQeGqmua3s9YUVRegKdExyfNWsWc+bM4aWXXuLCCy+krKyM7OxsPB4PH330EVu3tu0kmTFjBs8++ywAK1euZPny5QCUl5eTkJBASkoKhYWFzQomBivnPmPGDF599VWqqqqorKxk7ty5HHvssQd0f20RTosjH+jr9z4P2NnBa8wEFhtjmuw9/20ReQR4I9CJxpiHgYcBJk+efGB/IZEePFJBdX0jaQd0IUVRupwmwTiwYWH06NFUVFSQm5tL7969+fa3v81ZZ53F5MmTGT9+PCNGjGjz/BtuuIFrrrmGcePGMX78eKZMmQLAEUccwYQJExg9ejSDBg1i+vTpTefMnj2bmTNn0rt3bz766KOm/RMnTuTqq69uusZ3v/tdJkyYELZVBSVcfnsRiQLWYWMUO4AFwGXGmFUB2t4J7GsZ8BaROcC7xpjH/fb1NsYUONs/AqYaY2a11ZfJkyeb9vKj22LXA2dRWJBP4g8+Y3BW4n5fR1GUA2fNmjWMHDly/y9QWQRl+ZCcC4nZndexHk6g36uILDLGTG7ZNmwWhzGmQURuAt4FIoHHjDGrROR65/iDItILG6dIBrxOyu0oY0y5iMRjM7K+1+LSfxaR8djHhS0Bjnc6EhlNNA3qqlKUQwHTakPpIGFdyMkY8xbwVot9D/pt78K6sAKdWwW0ilwZY67o5G62S0RUNB4a2FevwqEoPZ+umwB4qKAzx0PAFQ61OBSle3BALvZOinEcSnT096nCEQIRUTGkyj4i96zp6q4oymFPbGwsxcXFByAeanH4Y4yhuLiY2NjYkM/RNcdDIMITTYpUMf29s+Dosq7ujqIc1uTl5ZGfn89+p9nXlNmfmBqI0/9nsGKclxcwahAQFY4QiCv2SwRrbIBI/bUpSlfh8XgYOHDg/l/gw9/BZ3+Fo26C0/7QeR07jFBXVQg0HOFX16XhwGddKorShbiLsjXqqp77iwpHCERMvppf119t39S3PfVfUZRujrfBvuqqnvuNCkcIxERFUEO0fVNf1XZjRVG6N65g6FIJ+40KRwiICCbSyThoUItDUXo0rmA0NnRtP3owKhwh4o2KsxtqcShKz8YVDI1x7DcqHCHijXIsDo1xKErPxquuqgNFhSNU1OJQlEODRnVVHSgqHCEi0Y5waIxDUXo2HbU4lj4H5QXh608PRIUjVDzx9rVe53EoSo/G69ScCyXGUVsBr94Ay+eEt089DBWOEIlwLQ4VDkXp2XTEVVXnuKbrKsPXnx6ICkeIREQ7Foe6qhSlZ9MRV5VbKaJOY5v+qHCESGSMBscV5ZCgsQMzx10PQ71aHP6ocIRIlGtxaDquooRG6TYbI+huNE0A7IBwqMXRDBWOEImNjqbORKnFoSih8vgZ8OndXd2L1nSk5Ijrmtb/+2aocIRIQkwU1UTj1eC4ooTGvkL7093YL4tDXVX+qHCESEqchxqiqa/RPyBFaZfGepvuWrevq3vSGjfG4Q0hq6opxqEWhz8qHCGSHOeh2sRQX6t/QIrSLu4Tend8Uvd2YD0OdVUFRIUjRJJjo6ghmsYa/QNSlHap78bzHxo1OH6ghFU4ROR0EVkrIhtE5PYAx0eIyFciUisit7Y4tkVEVojIUhFZ6Lc/XUTeF5H1zmtaOO/BxXVVefXJQ1Haxx1oa7uhq8qdOR6Kq0otjoCETThEJBL4JzATGAVcKiKjWjQrAW4GgqVenGCMGW+Mmey373bgQ2PMUOBD533YSXaFQ588FKV93NhGd4xxdCg47lpO+n/vTzgtjinABmPMJmNMHTAHOMe/gTFmtzFmAdCR+sbnAE86208C53ZCX9vFxjiidR6HooRCj3BVhRDjcP/fdQJgM8IpHLnAdr/3+c6+UDHAeyKySERm++3PMcYUADiv2YFOFpHZIrJQRBYWFRV1sOutcV1V0qDpuIrSLt25xpProjKNYEzbbd3/d28DNIR54afynbB9ftttjPG52rqQcAqHBNjXzrfUjOnGmIlYV9eNIjKjIx9ujHnYGDPZGDM5KyurI6cGJCE6khpiiNBaVYrSPq6LqqG6+6174e+ias9d5e9hCLfV8dk98PysttusfQv+PLDLY0fhFI58oK/f+zxgZ6gnG2N2Oq+7gblY1xdAoYj0BnBed3dKb9tBRPBGxhDZqMKhKO3iH0zubm4ebz1EeHzbbdHsPsLsbdhXCFXFbVsURWuhpgwqD8qwF5RwCscCYKiIDBSRaGAW8HooJ4pIgogkudvAqcBK5/DrwFXO9lXAa53a6zbwRsUR6VXhUJR28XdRdSd3lTHW7eRxipa2F+fw9zCEO0Bevde+1pYHb+PW/qppo81BICpcFzbGNIjITcC7QCTwmDFmlYhc7xx/UER6AQuBZMArIrdgM7Aygbki4vbxOWPMO86l7wJeEJFrgW3AReG6h1ZExRFdU2P/+CSQJ05RFKD7Cocb3/DE2QG6PTeav5URbsupqsS+VpdCXJBZBq6otCUuB4GwCQeAMeYt4K0W+x70296FdWG1pBw4Isg1i4GTOrGbIdMQk0JUTaNV/djkruiCovQM/F083Skl141puBZHe66qg2pxOMJRU9r62IYP4OO7IMXx/nexxaEzxztAbawTZPcv3LZnA7zzC/B6u6ZTitId8bcyutMkQFcoPAn2td3geDVIpLO9HxbH/Edg8VPttzOmucXRku3zIX8B7N1s33exxaHC0QEa4p3M34pdvp1Pnwfz/gnlO7qmU4rSHem2rion8NwU4whBOOIz7Pb+WBxfPwRf/r39dnWV0Fhrt2vKWh939+3d4rxX4egxeBN72Q1/i6Nsm30NZTKRohwudBdXVV0VLHnGN19jf1xV8el2u6NlR4yBsnzYs7598XTdVBDYVeVaIaEE0A8CKhwdICLJCod33oPw50Ew9wbfwe70VKUoXU1dJcSm+rbDRclm+Prh4MdXvgyv3QgFy+x7VyiiO+Cqci2OjgpHVYkzgdDArpXtt3UJ5KpqKSaBrBI4aJMDVTg6QExSOrXGQ8SOBTbfetlzvoNaBE3pLN75BXx+b1f34sCoq4REx7UbTotjydPw9k+DD6RF39jXMqeIRUctjgNxVZX5Fc5whSsYoVocLoEsjm1fw+/SIX9h62OdjApHB0iO87DbpNo3fadBZIzvoFocSmex7m3Y8GFX9+LAqK+CBFc4/P43Fj0B697tvM8pd+YUV+4JfLxJOPLtq5uOGxVijKOhGhIybYDcf3APBfczAXa1IxztWhwthDFQjGPLp/Z1fhsWWCehwtEBkuM87CbVvuk3FQYd7zuoFofSWVTvDfzU2d3ZudQ3wNVVQmyK3f7oD/DoKVC4Gj75Cyx4tPM+0xWOquLAx3e3EI6WFkcoJUeiEyC5D5R1IAHms7/a+wbIHg1F69pu78YuYlOCBMdLm78PZHG4YrL1K/jmrbBmeqpwdIAUf4sjZyxM/g5EJ9r3WnZZ6Qy8XvvEWV1mB0X/DL6DRe0++O8tzZ+CW1K5p/nAtOVzePg4+OiP9n1dJUTH+44XfQOf/MkmllQeeNHRJposjgDXrCmHckcwmiyOFjGOtsqIrP/AWhxRcZCc2zpzsr4mcEyhsR4+/SvsXm0tlV5joaKg7ftwf9dpA0NzVQWyONyMq7JtMOdSWPdO6zadhApHB0iO9ROOXmNg+Olwk+NP7G71eJSeSW0ZYOzgMfd7Nt27vQqunc32r2HR47agXiCq98K9Y2zgGayAvOokirgDZH0VeOLhshfh+/Ogz3goXGkH7mBupUCsecMnRi0xprWrqnAVvHwd7FgEfx1u90mkb9B3Z4rnjAGJsO1asme9FZpnL3A/CFLymscsvF745xRrWbSkYJlvPDCNkNzb/l7asgCqiiEmxbrF/EWicLWd+NeyKncgi6N0KwycAWc4yxtt+ij45x0gKhwdICXOwzLvYMrj+kLGULvTfaqqq7Izypc+d/D/0ZWuxxibs9/WU3oouINGbbl9gty9Gjb+r+1zvvwHPDaz7TY7FlkrIpSsm31OAb2dSwMfL95kB7KiNU77XVDqpKXX7bODc3WpdbsMOxWyR0JSHyjeYNtUFoX+P7LwMfj0L4EnEdaU+QboKkc4vn4IVrwAr97ocx8PPNbnZnItjoQM6H0EbP60+TXLdsA/p8L//uDblzbQEY4dvsF/z1o7UG//unW/tnzu23atFW9D25bWnnWQ1s/+zir32DjQ2ndsksTHLYQzISu4xZE5DKZcB0NOhk0fB/+8A0SFowMkxUbxincGTx05FyKdai3uDNT6Klj1qn3ycmd3KocPBcvg7Z/BipfabvfYTPtw4VJT1txd4vq6AUqdJ9yv/tn6Oitego/+n93escjOKg42GO8rgkdOtFZEYRtpocUb4R9TYOdi+37nksDt3LlLrhtt71b7GhkNFYV2UG2stS4al+Q+vu2GmtaZVuveg1Vz7faiJ+HD39ntom/sU3ugAdq1NsBmFH34O597pmgNDD4JbtsKfafaJ/7Gel9MI8IDA4+zvzf/4L37eWuceqzf+wzGX2aFw1vvG/y3fum094td1JRZ99XWL+yD5Y3z4ftfQVJv5/cVpDi4Mfbvp/d4W6OqbBs8d7Etsd7M6nPq46XkNbc4CpbD3yfZz0/tb/cNOt6KUUl4xiIVjg4Q64kkJiqC8hq/wmiRUfYfpq7SNzEwWGpgV1C0zprvSnjZvdq+lm4N3qZ6L2z7ErZ84dv36Mnwh16+LCp/4cBAfCZs/NAX5HVZ/JSdkez12sHMWx98UtiiJ3zbgVwzLt+8YQf9b9607wtXBi4C6FoXrlvK9a33nWqtjx2O8PSZ4DvHXzjA9nnVq76n4ucughevtiLn3lv5Tp+LyR2o/fEfiNe/a91G+wqtiwzsU3dcqh1ocdxa7vcTl2rdOt562PyZ9RbMvd5n3dXtg6hYx6UlzjXwxUq2feW832b/972N8NBx8OaPYds8GHAMZA2H9IHWVQVQHiTOUbbdZmz1GQ9HXgcn/ApmPeeMK34Cm+ysg5eSZx9U5z1orchP/uSz5tIc4RhxprV2nj7XlkXqZFQ4OkhKnIeyqhaZGJ54+0W6mR1u6ePuwDu3wRs/7upehJ+Vr8CCf3fd57vi3JZwuAOsOxjWVtinQrA1jaCFcABH3WgHsJZlK0o22b+50i2+v7tgsYP8BZA5HOLS2xYOd3B2+9dQ40tn9ccVDncgLN0KCOROsn3Inw/RSZA+2HeOO+i5vH4zvHgVPDfLrjHh8uXf7PvGOl/2VUQUfHa3PcffOnMtDjftF+yT/oxbbX+GnmL3pfbz9XP5fyBtAPQaBwOOtcK89FlYNgeWPd88lTV9EEQ4Q2STcGy3QfMNH0CMU+h0yTP2b2/vZnud2nIrHC5JjmjOuRQePr71g5w7x6P3BMgeAcf91A784y+z331TfwY6v0unL+/cZq3Ib97w9SV7tK/vV78BxhuWWeYqHB0kOc5DeU0L4YhOsDEO14ztSFG3cMdDKgq7lwUULhb8Gz6/r+s+3x0MijfZCXzFG33HSrdbF4nr0nEHvD3rfW1KNtnXlsKRNQKO/C4sfcZnldRX+wK1u9f4/u4CxVeMsWKRN9kO7K410BJvo03jdHEnvfm7tryN1h20bZ5932RxbLXumLT+gLFupz7jfYMutLY4tnwGg06w/zuv3eTbv+DfUOc8eH35D/t61I1WhBY/Ba84q0g3NljXVlSsTVQBGH853LQApt8CN3wBmU4cMn2Q85mfW+viiEutFREVDUfMgrVvw7x/Odf1Kx3kngc+4StaawUgNhXO+Ivd9/bP7CREsG4ugP7Tfecm+gnbziXw6vet6C551or1ziU2gJ8zqvnv6LT/Z11lLlkjAIGxF9mfa96BE39l3W7XvAU/3QiZQ3zt8ybDDxZD7kQ6GxWODpIS56GsOpDFUel74gvV4ijbAb9Nbd8vfiBUFR8eGV+Vu23qZbjWhfY2wurXgmfGuMKxe5UternaWV+svgbuGwOvXOezRtwB13UvDD3VPq16G1unXSZk2cEhcxi8f4fd5++33rXSZ3FUBbA4SrfZ/bkTrXDsXtNcYBpq7d/foiecjC6HvtPsgORvcexabt1BrpjUlFoR27vFPsU31XLb1XqwcoXDnXgHMPIsGHW2tVAAhp7m+1tNyPYV/TvpTrh5MRz7Yxt72LEYnjnfupVOv8t3vd7jrCBERELOaL/PzrOTdRc9CRgYebbv2KRr7JyOkk3W+gCfaGb4WUxxaVY8Fv7bisuZf4XR5/uODzkZjrvNbqcP8rmnwPbHJXeydWv+94fw2vdt1tyiJ2DAdN/cEpfoeMga5nt/1PfhylchbxJc8Cj0Pwpm/BR+ut7GkxIyaUWkp/W+TkCFo4Mkx0YFsDjircXh/uPWhSgc7lNmKNUz9wdj7KDSE+eYbJvXfOZte+zbbc1y/5RJfxY/Df+5Yv/7s/59eOFK2Pp562OVe6xwJfkNFm7fXbfPqrk+i6O23GbF7FlvU0KHnGwHo/KdrS2OhAw7oBxxKRSusBakKzgSYQOxxhGzBY/CnG83j0u4rqncSTD6XLv9xX2+4/MegJevtb757FHQ33GxpOTaJ3b/2Ir79wo+AagosIKY1h+ScnzHh57a/D7iM60QZY/07eszAfr4Cczka3zbV74G039on7pdy2XkWfb1mfOt++3Me+w5rgXXaxwBiYiwbp59u2wyS9Zw37HMIfCjVTD7Ezjp187nnG1dP32n+tqJwJCTbAxFIqHvFGuxnPgr+PZLcPnLcMIvYNQ5MK6NdcMnf8d+1xs/hMEnWkGrKrbiGIzpt9jXlL7NJx27BFv0KYyocHSQ5DgP5dUtAoaeBBsgq+xgjMNNF/TPDjlQPvw/+OTPvn5460Of1b5jkc0Z7w48d4kN+oVCQ51v0lSgjDZj4PWb7NNq/X4u/VvsuJX8XVBgn7jdgXzIyb79rmD4C9n2+b7tigJ7zdT+jgsCeHC6tVbi0n3tEpw1YAafYF83f+L7vP7Tm6eTbvjA+ruXPOXLHipYaoOs2aPtoD3uEpuyuvlT+3v7+kHodzRcMRe+96l9agfrXskabi2O8gLrfvMPULsWxM4l9u/X3+IAa7H4ExFhxcV1H4G1CnIn+d4PnGGvk5Bl3Tan/M66qVx6jbMuouq9MOlqOPJau9+1IFq6evxx4y29xzW3AMAuytZnvM+91P9ouG0LDD+jeTv3++19BMQk2e0ZP/XFUgAufgqOv63151/2AlzyjM8S8jbAsNPhkqesAOZNan2Oy8l3wq92h8162B9UODpIQFdVtOuq6mCMoymouZ8Lzxeutk+g/nx2ty11UL3Xd/36qtDKDyx/0eaMtzWb9mBQU2aFINRUQn8XTaBz8hf4toOtm7J3C3zw2+DzHNynbX9h2va1zYhys5b8nwbL8u2Pf38KV/hEYe8W62bKHObzpbuxqJgk+3QeFeurTNDrCPtkOe9fNp03IdsOcASIkb3xI7h3tH2QKVxlBSAq2h475bd2cH7mAvt3UlEAx/7Eefr1+ALJiTmQNdLe798nWkFb8Kh115x5D5x1v2339u32vHEX+3z5kTG+dHV/Zj1vxcAlKsb2zZNgRSc6AY75MUy7ofW5YAf8gTPs9sSrfPuPv90O9G6Jk0C4gWX/TK+WZA61MYXR59vPark89MDjrAgPPDb4NYIx7DRrMWUOoymtts8E+zfjCmAwROzvqhsR1qVjD0WSY21w3Os1REQ4fwCeeKhY7ZtcFKrF4e9rrimzf/jr3oV+R7W/NG3lHnjgKNv2OwFKCyx9vrmp3VDtK7MQtD+O0FQUNA8MHmzKAjytt8U+P+F1M5fAxhl2Lmke9yjLb+67dln5Mnx+D4y5wAY43/oZXPK0bzB0LQ3/63/qWHbLngfEPpHmTbFPk7tX29z62BSaMnzWv2cHilWv2Dx9gKnfa51xVLrVPnVHxfoGr4gIO6AtfAwyhli3imuN+DP8TBss/vRu+OAOK06utQKQ1Auu+i/8bYJ1WfWZYF0wLu48gIRsX6ZOfZV1ixmvHVyPvNY+HEXF2Yee43/u+3u56Ingg7Prrz/7H741LiIira/eHUwnXRXw1CaO/YkVzOwRvn0Rke27a9zvvPf4ttv1DuLuApvCO/tjn7juD9HxVrhLt9lU3x6KCkcHSYnzYAzsq2sgOdYxHaMTmueUhyoc/tU2C1fZAeG5i2Hmn+2A0hZf/s2++s9GNcb6X02jnTTmphCCjXO0Jxxuf8q7WDia3Dz51gJo6VpoSdPvQJoP7Mv+Axvety6I6CQbe2ppcdSUWxedm2K6a4UNAm+fB+/9Gs5/yO53LQf3tXRb8wq2KXl2YPnu+za7y51Et6/GpmNe9oLN/U8fbIUDrFtj1Dl2O28KpPa17qyhp1qXlOsOcfnWPbachOvz958XkOSUtRh+Oky80g7s85yJgy0HqMRs6wL65E9w/C+aP1kPnAHTvm/TSWvLrYDM/JO9ny//bv9GAWIS4ZYV9nfq/7cy+jzaZWKLWNOFjxPQcgpEn/H2p6MMONbGcFyLZX/xD7rvL32n2u/Av5ZXD0OFo4OkxFmxKKuq9wmHp8UfgH9wfNs8eOw0mxbnPvUsfsrW3/Ef2AuW+UztUArbLX3evvrnsNeWW9EYeqp9uv30L75j9ZVAgCdUf/wtDrCDT+EqWwk4EMbYwWTeA3DNm50nNu7g7m2wffH/PQXCtThyRtuB3xg7GJZutYHI7V/bJ/21b9nt2BSbJw/w+BnWheTOci5c6Qtsr3jR+pfj0hzrxxEmY5zYgrH3XLLJPkW6tOxvSp7tT/+j7fuhp9ptVzTACo6bmi0Cz1/qWwjJn2Yprn7B+Myh9neV6QR+j77JTzgCDHYzfmpdLwOmN98fkwin/9G3/VMnthOb3Fw4ABKzaPdvKhTas647g8yhdhZ3d+Cs+3zl3XsoYY1xiMjpIrJWRDaIyO0Bjo8Qka9EpFZEbvXb31dEPhKRNSKySkR+6HfsThHZISJLnZ8zWl43nCS7wuEf5/B/coiMaW5xfHaPfXX97HvWw+s/sBZK/nz7j57U26YYtpVW6U9DnS8u4l9J03V9jTrXurB2LfcdCyWzyv18N1i/4BF4fGbg9QHADp7v/9rei1suoqPU19hJUY+dbksnQPPy1aXbbGZPIDEt32l/3N/FpKud+kHz7SDsWh/1VTYwnJBt4xFzLoM1/3Vm1a+wbXb5vRautG1No90u3QoYGxStLXdmgM+zA/uoc+15zYSjb/N+prZ4/+0X4Zgftb4fEd/T/8VPwdl/C/w7C4QbmHaDz8l9fGmlgVwikZ7WotEWA2bA0T9oLnbK/uGJa21N9jDCJhwiEgn8E5gJjAIuFZGWaQ8lwM3A3S32NwA/McaMBKYBN7Y4915jzHjnJ0gJz/DgWhzl/sLh8XMBZQxuHhx3M2DciUVuSqZLfLozMWuRb+Cv3GMHp4ba1h2oKmnu+/ef3Oe6muLTm2d6QGiZVVVOKqhrcRSttYNnsLRYN8c/pZ+dRLU/rH7VxiF2LoX3fmn3le+wPnWwv6+nz4WXv9v8PGPgmQt9ZSo8CTZl1ZNgJ8tVlTQv19Ayt/7Fq+GhAG6L7V9bC2KMk6O/Z53vPt3f6ad/sa6kvlN9T/P+wuEKxTCn8GBLIQmFSE9oWTSzP4YL/m1FLWesL3YANsX03Accy+AAiYqGU3/feiKfclgSTotjCrDBGLPJGFMHzAGaPa4YY3YbYxYA9S32FxhjFjvbFcAaoEUEsWtICWRxuE+JfafaJz7X4mio82XhuHWs3Kf6SCfLJS7dTpYq2egTmdLtcO9Y+H22LSvtz0MzbM492PIK/taAOwcgLt0+IfrT3gqFDbU+F5trcbgB4WDCUbrNBnAnXG6Xq9y9pvnxxgabxnnvWMgPUOrCGFviIWMIzPiJtWDcktbugLzpYytkWz5rPtO6YJmdbJe/wP7eErOsa2XMeTY7bEeL5TPTB/tiAqffZX38Yy+Em5f4nsyzR9kyG2DdOHHpVji2z7eW5NE3Wx/+vH/Ze+831X53Etl8DkFyHxsAPut+awWNOpuw0WeCvY+jb4IbWswxSe1ry1YoSicTTuHIBfzTYvLZj8FfRAYAEwD/8pg3ichyEXlMRAKmU4jIbBFZKCILi4raKGfcQVLiAwiHmyo346dOENZ50i1Y6puc5frhXeHInWxfXYsDfMHW3at8g/jqV32fU19jrY3NThmC7BE2dtFYb90uu5wZvXFprQOI7Vkc/hlersVR4ghHuZ9wtMxQSsmDIy6xgeFHTmw+SWzjh9bPXrbNxhdeu7F5wbX3fmUtraNusumVkdG26N+ORXagT871VSkFW3nYrdi6zInxGK/9HPeJf/otdsbxm47n001nTR/kE6Pxl9m00HP+YfdnO8bs8bdbwZAIKwiZw6xYbZ9vB+jYZJs1dOHjttT28DPt+T9a2drCm3iFnRB31v3N5yooyiFAOIVDAuzrUGEmEUkEXgZuMca4lboeAAYD44ECIMBKKmCMedgYM9kYMzkrqxNMdYeAFsfU6+Ha9+3gEZPkszjcJ+SIqObCIRG+gT0+3fe06sZBXLFJ6WcnXc35tp357Pry3Xo47sSxmjLrevngDt81Iz32uu7TdF2lHeh3f2N/Wtbqd91cnnj7ZF5d6hM5N+aw5r/wpwG+0iqucKQNsHVz6qtgo9/iMWvftgN3Uh9bSG7JM7DGKcVRug2++oct+TDpaptlctUbNnBsjB1sx19mrxmXbrOJijfCK9+zx9e+ZdNfo2JtoHGqk/ufOdTW8XFLfw863op5YjZc+Jh137TM93eFI3OYnbF8+zabtpo51MY8CpbamcIuY86HHy71pYQm92md868ohzDhzKrKB/ydu3lAyFOkRcSDFY1njTGvuPuNMYV+bR4B3ghwethIiI4kMkKaC4cnzjewxCRa4TDGlx3UZ0Jz4YhL92UgxaXbgT7QWsPjLrYT+sp32IHy5Dt9xyTSNxu2utSXTgq+bJzvfWotlPvG2gH47dus6yVrhA3u/tTP9eOKRPZIG6T2dwttm2fXit613Fo4hatg0HH22u6TdtZwW1Zix2Kb52+MXRth8Al28uFap1R38Sb73hWYqdf7Bt1+U+2PmxW1r8hm8vQ7yi5OExVrZ4CveNHe71E32X2Ve+wEK5dTf2+roLrbpVvt9eLTm8cAXIacbFdLSxtg27mBy8xhvsqi/nNiFOUwJ5zCsQAYKiIDgR3ALCAkh6uICPBvYI0x5p4Wx3obY9wE9vOANlam6XxEJPDscZeYJMA4T/jbbXZOSl9fhlNVsbUC3Jms7kCWNtA+2bp44m3K6Gd320lZ1Xvha7+Sz4k5vnMrdjZPAXZn7Yr4Avd1VTYGUbrVWjyVu20QPybR1y+wcx52LPItIBOXbteQ2OZXbqJ4vVP7p9BaRe5n5U6Cb/4LL9dBv2nW5TVspo3zuMKxczH8ZZC9n6TezesG+X7Jzj1mweWv+ILaY86Hd39hCwa6fZ38HWuh+T/xJ2ZbC6gs3/bT/V0HY9ip9qclA6bb5TwHHmtnViuKAoTRVWWMaQBuAt7FBrdfMMasEpHrReR6ABHpJSL5wI+BX4lIvogkA9OBK4ATA6Td/llEVojIcuAEIEBeY3hpUzhcn3rdPuviScm1A5lrcVTvtcLRe4JNxXWLvDUNbs4AmNrfuppyxsBxP7PH/WMNSb18loX/egat+uOkCrtLkXobfFlC/pPl3BiHa0Esm2PLXvQ7qvU1v/y7tWKg+ZyF3EnWalrxgg3gJ+fZwd51BYGdUe0G8ftMaN/FM2C6zzqLTrCF71yyR1mXXKByDP2PgnEXtX3t9sidBD/fBrOe7dGTtRSlswnrBEAnVfatFvse9NvehXVhteRzAsdIMMYcQInTziG5LeFwSxsXLLNPvFnDrHDUltsaUFXFdiBMyICb/IrepTnCkdrPV200MsquKwB2Qp+74AvYp3XXV+8uBhSIqFhA7IDtxkZc9m7xrWXgCkfeFCt+FTvt0puuq2bcJVagasubB8CbCYcjgn0m2NjAKb+1brzeR9j9GUN9xQIHnWCzlDrK9FusCyxndPPJcIqiHDR05vh+YFcBDLLuw7DTrQi892s7MA8+0bqVwFodVcV2gZWWuBZH1ggrHG7NIBf3fXSSdS+lD7SZTBB4lTYXEfuk7i86Lm6qsNdrhSmpD3hibT2frZ/D8Jl24N/yGZz2Ryt2L15thSNrpH0K919XesjJtsrqwONsTMWNFWQMhus+snGJF6+y8YIrXw3e57aIjLKJCBqMVpQuQ4VjP0iJ87C9JEh6a1SMfdJ+4UqncZ5POHYt98U4WuJaHDmj7Epl/gMy+NYSTsyCK1+3ohHhfH1FjsXxrXvtU31LPPE+KyEiylfuwHVVrXzJzmI/x1kFLXeiIxxnWFfbEZf5nu7d60/9XvP1E8AO5m4soOXM2NyJvoVq3NIb+4uKhqJ0KSoc+0FKXFRwVxXAiG/5Nc6zA2XmMHjpO3bQDiQcmUNtplTmcLhleetqn6kD7GtCdvMSFpExdoGaiCiYeHVg9010PFRiPzcxxwbJs0f6CvbNf8RaOkdcat9P/6HNhkpxpt34XzNvsnV/+VdUDZXM4bZsdnsVUBVF6daok3g/cIPjJth64RGRdjY12Bz/6AS7iItbdiSQcCT1gus/t7OAEzJbV4R1J7i1LB/huqsSsoP7/N3Mql7j7Czt1L5WyEo2WfHIn2/XXnbPT8gMnkU09FS7tvH+lJaOiICT72henkNRlB6HCsd+MDAzkUavYcWOsuCNzrwXLn4a8o6077OG+8Qk2IIzOaOC1ydK7QtI82q44JuV7IkN3he3lMnoc+2M6YuetAHsvZtt+XWAMRcGP98fEV8Kr6IohyXqqtoPThmZgydSeH3pTsblpQZuFBXdukbRmffawPGQUwKf0xZRMXYyW8v4wAm/sHMu2irF3ugUSxxxlg1w4zevYcGjdj5EywquiqIoQQjJ4hCRH4pIslj+LSKLRSTAjKnDg5R4D8cNy+KN5QV4vR2oohIVbWeDu8t4dpSjb/KlvLr0Ggtn/tXONQjGSXfY+EWCn4us9xF2chvGluhQFEUJkVBdVd9xakWdil255RrgrrD1qgdw3LAsdpXXUFhR09VdgSO/2/bM5mN/DOc92HxfRKRd5S3Co2ssKIrSIUIVDjf/8QzgcWPMMoJM0Dtc6JtuZxJvL6nu4p4cAKf8FmY9F7h+k6IoShBCFY5FIvIeVjjeFZEkwBu+bnV/fMIRwgJJ3ZXMoYFrNCmKorRBqMHxa7FlzDcZY6pEJB3rrjpsyU2NQwS27+3BwqEoirIfhGpxHAWsNcaUisjlwK+ANnJRD31iPZHkJMX2bFeVoijKfhCqcDwAVInIEcDPgK3AU2HrVQ+hb3qcWhyKohx2hCocDcZOkz4HuN8Ycz+Q1M45hzx90+LJ78kxDkVRlP0gVOGoEJGfY9fIeFNEIoEgU5wPH/LS4ykor6Gu4bDOE1AU5TAjVOG4BKjFzufYBeQCfwlbr3oIAzLiMQa2qdWhKMphREjC4YjFs0CKiHwLqDHGHPYxjkFZtmbTpqJ9XdwTRVGUg0eoJUcuBuYDFwEXA1+LSIhV8Q5dBmbaqrOb91R2cU8URVEOHqHO4/glcKQxZjeAiGQBHwAvhatjPYGUOA+ZidFsKlLhUBTl8CHUGEeEKxoOxR0495BmUGYim/aoq0pRlMOHUC2Od0TkXeB55/0lwFvh6VLPYlBWAu+vLuzqbiiKohw0Qg2O/xR4GBgHHAE8bIy5rb3zROR0EVkrIhtE5PYAx0eIyFciUisit4Zyroiki8j7IrLeeU1red2DyeCsRIor6yiprOvKbiiKohw0QnY3GWNeNsb82BjzI2PM3PbaO3M9/gnMBEYBl4rIqBbNSoCbgbs7cO7twIfGmKHAh877LmNMrl3Nb9n20q7shqIoykGjTeEQkQoRKQ/wUyEi5e1cewqwwRizyRhTB8zBzjxvwhiz2xizAKjvwLnnAE86208C57Z3k+HkiL4pREYIi7bu7cpuKIqiHDTajHEYYw6krEgusN3vfT4wtRPOzTHGFDj9KxCR7JYnA4jIbGA2QL9+/TrQ7Y4RHx3FyN5JLN6mwqEoyuFBODOjAi30FOo6qwdyrm1szMPGmMnGmMlZWVkdObXDTOqXxtLtpdQ3aukRRVEOfcIpHPlAX7/3ecDOTji3UER6Azivu+liThyZQ1VdI395d21Xd0VRFCXshFM4FgBDRWSgiEQDs4DXO+Hc14GrnO2rgNc6sc/7xXHDsvj21H48/Ommnr0ioKIoSgiETTiMMQ3ATcC7wBrgBWPMKhG5XkSuBxCRXiKSD/wY+JWI5ItIcrBznUvfBZwiIuuBU5z3Xc6lU2wcZalmVymKcogT6gTA/cIY8xYtJgoaYx70296FdUOFdK6zvxg4qXN7euAM75VEdFQEK3aUcdYRfbq6O4qiKGFDy4Z0Ep7ICEb1Ttb5HIqiHPKocHQi4/JSWLmjjEZvhxLAFEVRehQqHJ3IEXmpVNY1sn53RVd3RVEUJWyocHQiUwamAzBvY3EX90RRFCV8qHB0In3T48lLi2PeppKu7oqiKErYUOHoZI4alMG8zcV4Nc6hKMohigpHJzNtUAalVfV8s0vjHIqiHJqocHQyRw3OAGDeJo1zKIpyaKLC0cn0SY2jf0Y8X6lwKIpyiKLCEQamDczg603FOp9DUZRDEhWOMHD0kAzKaxr4z4LtfPfJhZRW6bKyiqIcOqhwhIHTRvciIyGaX8xdwQdrCvl0/Z6u7pKiKEqnocIRBmI9kVx51ICm9yt3lHVdZxRFUTqZsFbHPZy5bsZAeqfG8vRXW7XwoaIohxRqcYSJ+OgoLp7cl0n901ihhQ8VRTmEUOEIM+PyUqiqa+SPb61hX21DV3dHURTlgFHhCDMzx/TmW+N68+8vNnPG/Z9RWF7T1V1SFEU5IFQ4wkxcdCT/uGwic66bRv7eKp78cktXd0lRFOWAUOE4SEwdlMHJI3P4z4Lt1DY0dnV3FEVR9hsVjoPI5dP6U1xZx/urC7u6K4qiKPuNCsdBZPqQTHKSY3h1yY6u7oqiKMp+E1bhEJHTRWStiGwQkdsDHBcR+ZtzfLmITHT2DxeRpX4/5SJyi3PsThHZ4XfsjHDeQ2cSGSGcMz6Xj9cWsbtCg+SKovRMwiYcIhIJ/BOYCYwCLhWRUS2azQSGOj+zgQcAjDFrjTHjjTHjgUlAFTDX77x73ePGmLfCdQ/h4MJJeQCc9ffP2V5S1cW9URRF6TjhtDimABuMMZuMMXXAHOCcFm3OAZ4ylnlAqoj0btHmJGCjMWZrGPt60BiWk8RLNxzN7opanpu/jXvfX0dRRW1Xd0tRFCVkwikcucB2v/f5zr6OtpkFPN9i302Oa+sxEUkL9OEiMltEForIwqKioo73PoyM75vKpH5pPPLpJu7/cD1PfbWlq7ukKIoSMuEUDgmwr2XdjTbbiEg0cDbwot/xB4DBwHigAPhroA83xjxsjJlsjJmclZXVgW4fHE4amUODU4bkzeUFGKMlSRRF6RmEUzjygb5+7/OAnR1sMxNYbIxpyl81xhQaYxqNMV7gEaxLrMcxc0wvoqMiOHlkNpv2VLJw696u7pKiKEpIhFM4FgBDRWSgYznMAl5v0eZ14Eonu2oaUGaMKfA7fikt3FQtYiDnASs7v+vhZ0BmAsvvOJW7LzqCrKQYrvz3fFbka/l1RVG6P2ETDmNMA3AT8C6wBnjBGLNKRK4XkeudZm8Bm4ANWOvh++75IhIPnAK80uLSfxaRFSKyHDgB+FG47iHcxHoiSY2P5o0fHIMI/GfhNrbsqaS+0dvVXVMURQmKHA6+9cmTJ5uFCxd2dTfaZPZTC/lqUzH7ahuYMTSLh6+cRExUZFd3S1GUwxgRWWSMmdxyv84c7yacPDKHipoG4j2RfLKuiKsfW0B5TX1Xd0tRFKUVKhzdhBNHZpMUE8UdZ43mvkvG89WmYp7+6pCYuqIoyiGGLh3bTchMjGHJb04hKtJq+f0frtdguaIo3RK1OLoRrmgAjOqTzKqCMowx/P6N1SzaWtKFPVMURfGhwtFNGd0nme0l1by+bCePfr6ZZ7/exgUPfKkLQSmK0uWoq6qbMrpPCgA/nLMUgPdXFVJR28D2kioum9oPT6RqvqIoXYOOPt2UUb2Tm7aH5yRRUdsAwO6KWt5bpQtBKYrSdajF0U3JSorhwcsnkpcWz559tVz9+AJykmOIEOG/y3Zy5riWRYQVRVEODioc3ZjTx1hxKKmsA2DqwAzioyN5c0UBs59ayLFDM7n4yL54IiKIiAhUL1JRFKXzUVdVDyA9IZpff2sU3ztuEDOGZVFR08B7qwv52/82MPbO9/jN6z2yXJeiKD0UFY4ewrXHDGR0nxSmD84kQiAhOpKiilrqGrw8M29bV3dPUZTDCBWOHkZKvIf/d95Ynrp2CgMy4gEQgX1O8FxRFCXcqHD0QGZN6cek/um8/cMZPHLlZIyB/32zm7Kq5rWt3lxewOvLWi6BoiiKcmBocLwHExcdycR+qQDc/PwSjh+exeNXH8mTX24hKymW//fWGjyRwtlH9OnajiqKckihwtHDyUiMITXeQ2lVPZ+t38PPXlrOi4vySYiOpLKuEYDymnqSYz1d3FNFUQ4V1FV1CPDfm47hueum0ug1vLgonyPyUppEA2DVjvIu7J2iKIcaKhyHAH3T4zlqUAYjeiUxuk8yz3x3KokxUSTHWoPyy417KKqo7eJeKopyqKArAB5ClFbVERUZQWJMFM/M20pUhPDLV1fS6DVER0Xww5OGcuMJQ7q6m4qi9BCCrQCoMY5DiNT46Kbty6f1B+CbXRXM31xC3/Q4/vLuWowxXHn0AJJjPczfXMLqnWVcPX1gSNc3xiCiM9QV5XBHheMQ586zRwPQ6DV87+mF3P3eOp79ehsvXn8Ud729hsXbSjl2WBaF5TXsrawPWgPr3VW7+MUrK/jop8droF1RDnNUOA4TIiOEh6+YzLxNxXzvmUVc9sjXbCupAuCSh75izz5bD2tUn+MZmJnQ6vxn5m2luLKODbv3MbFf2kHtu6Io3YuwBsdF5HQRWSsiG0Tk9gDHRUT+5hxfLiIT/Y5tEZEVIrJURBb67U8XkfdFZL3zqqNYiERECEcPyeShyyexfa8VjWOHZlJe08APTxqKJ1ICLhS1Z18tX24sBmBrceXB7LKiKN2QsFkcIhIJ/BM4BcgHFojI68aY1X7NZgJDnZ+pwAPOq8sJxpg9LS59O/ChMeYuR4xuB24L020ckhw9JJNfnzmKdYUV/Pac0VTWNpKeEM2W4kqen7+NCf1SOWd8blP7t1YU0Oi1SRRbi6u6qtuKonQTwmlxTAE2GGM2GWPqgDnAOS3anAM8ZSzzgFQRaW+hiXOAJ53tJ4FzO7HPhw3fOWYgd10wjpioSNITbFD9V2eOYlxeCrf8ZylfbvTp9etLdzI8J4nc1LiAwlFV18DfPlxPTX1jq2OKohx6hFM4coHtfu/znX2htjHAeyKySERm+7XJMcYUADiv2Z3a68OYrKQYnrhmCgMzEvjJC8v4fP0eTr7nExZu3cvZ4/vQPyOeLcWVrWpifbhmN/e8v473Vre9MmGj13D/B+vZXhLcaqmpb8TrPfRTxBWlJxNO4QiUt9lyRGirzXRjzESsO+tGEZnRoQ8XmS0iC0VkYVFRUUdOPaxJiInil2eOpKCshh88v5gNu/cBcNa4PvTPSGDJtlKO/MMHfLPLNxvdbfPF+pZexeYs2rqXez9Yxy9fDb5+yIhfv8PNc5Z0wp0oihIuwikc+UBfv/d5QMtSrUHbGGPc193AXKzrC6DQdWc5r7sDfbgx5mFjzGRjzOSsrKwDvJXDixnDskhPiGZvVT3XHjOQ9380g34Z8WQmWpdWXaOXJ7/c2tR+Q5EVjs837KGtCaX/+8Z+VZ+uK+LLDa1FptIpDf/G8gKKKmqpbVDXl6J0R8IpHAuAoSIyUESigVnA6y3avA5c6WRXTQPKjDEFIpIgIkkAIpIAnAqs9DvnKmf7KuC1MN7DYYknMoKznPkcl0/rz9CcJADOGd+Hs4/owxljezF3ST7zN5cwd0k+6wsriBDYUVrNqp3lVNTU839vrG5a8tblf98UMql/GiKwYMveVp9bWF7TtH3kHz7g7nfXhvEuA7NyRxkXP/iVrm+iKG0QtqwqY0yDiNwEvAtEAo8ZY1aJyPXO8QeBt4AzgA1AFXCNc3oOMNeZpRwFPGeMecc5dhfwgohcC2wDLgrXPRzO/PiU4Zw6ulezOR1DspP426UT2LynknmbSrj4oa+ajp0/IZdP1+/hu08u5OjBGbyyZAd5aXFc48xK31pcybrCffzqzJHk760if2/rOEdhefN6Wl9tKg7T3QXn0/VFzN9SwoItJZwwXMNnihKIsM7jMMa8ZYwZZowZbIz5g7PvQUc0cLKpbnSOjzXGLHT2bzLGHOH8jHbPdY4VG2NOMsYMdV5LwnkPhysp8R6mD8kMeGxgZgKv3HA0s2cMIirChqmmDkrn6WunUNfo5ZUlOwCa5n40NHp5belOROCMsb3JS4snf291q+vurrAWx/PXTeO00TmUVx/8p363X0u2traIFEWxaHVcZb8YkJnAL84YyS0nDwWsNTKydzKv3HA0l03tx4kjspm3qZiFW0oY99v3+NfHG5gyIJ0+qXHkpsaxo7S1cLiuqjG5yQzLSSJ/bxV1Dd4O9+2jb3bz6Geb9uu+3IyvxdtKQz7H6zU8+eUWymvq22+sdAu2l1Qx4PY3Wba9tKu70iNR4VAOiBtPGMIbPziGSf3tBP4BmQn8v/PGcs74PlTUNHDNEwvwREZQU+/lkiNtHkReWhw7S6ubJhW6FJbXEh8dSWJMFP0zEvAaAgpMe1zzxAJ+/+YaFmzpuDG6w7U4tu1t1b9grNpZzh2vr+LN5QUhtb/skXnMmb+tw31TOg/XDfrIfj5gHO6ocCgHhIgwJjel1f7jh2dz7NBMhuUk8fS1U1j861M4f2IeAHlp8TR4TbNgOFiLIyc5FhFhQEY8AFtalDh5b9WugBlZLg2NPgvlhmcW8dRXW0K+F6/XkL+3muykGCrrGtnoZIu1x4aiCgAKymraaWkzx77cWMwHa9qe83K48OLC7byyOP+gf25CtA3v7s+DiaLCoYSJlDgPT187lZdvOJpxealNs9MBctPigOb/tDtLq9lRagdtgP4ZNii/zW+mek19Iz9+YRk3z1kadJb6ukI72F8zfQC9UmL5vzdWhzyjvWhfLXWNXk4ameNcqyKk89x5LIUhCId7z9/sCu3ahzpPfbWVJwLURws3FY5bcUeAWJvSPiocykEnzxGOix78imufWMClD8/j6Lv+x5JtpaQ5a4pkJkaTEB3JpqJ9GGO48/VVfP/ZxeyrbWDPvtqgrp6ljs/66qMHcMtJw6hvNE1+7LW7Ktp0EbnxjeOHZxEZIawLcXDfuNtaRbvK2xcON5ssf2/1Aaf8Lt62l7lLDv7T+tbiypDdeO1RVl3fyvI8GFTU2N/97oraHlOpoLqusenvu6tR4VAOOnlpcYzolcTEfqlsLamivKaeCxw3VnaytThEhIn90/hkXREvL97BE19u4X/f7CY3NY4J/VJ56qutrSYbNjR6eWfVLlLjPfRLj2+Kuyx0MqROu+9Tbn9lBdV1gS0Qt2Lw4KwEBmTEszZUi8Nxae0KweLwzyZbe4BWx6OfbeJXc1e2OemysyneV8tJf/2EV53MuQOlvKaeooraZi7Gg0GFXyLDtjZK4HQnXly0nQse+JLSqrr2G4cZXY9DOejEREXyzi2tK8hcNrUvAzMTm96fPqYXv5y7kl+/upLJ/dM4fUwvBmQksGdfLbe/soJl+WWM6JXEztJq+qbH84c31/DpuiJ+deZIRIS0hGiG5SSyYEsJBWW+AXtj0b6AcZlNRZVERgh90+MZlpPU5E6qqKnn359v5rpjB5EQ0/xfpr7Ry5Y9wS2OdYUV9EuPJ9YTCbQWDlfc9oddZTVU1jWyo7SavLT4/b5OR8jfW02D17ByZxkXTMo7oGt5vYby6nq8Bvbsq6NXSmwn9bJ9ymt81t7Gon0MCLAGTXdjh5NQUlBW02y1z65ALQ6l2zCpf3qzWMgpo3IQAa8x/PnCcXz32EGcPCqHmWN7Ex0VwT/+t4FT7/2UE//6Cafd9ylPfbWFK4/qz3ePHdR0jakDM/h6UwlPfLGlaZ8bk2jJ+sJ99M+IJyYqkmE5SWwprqSmvpH/Livgvg/Wc+frq1qd801BBQ1ew6CsBMqq65tZMyWVdZz5t8+a+fC3l1QxKDOBxJgo1hSUt7peSxZt3cvnQWqAuRMmQ43FdIRgVtnuCvuZG4sOfF2WfXUNuF6ig+2uqvATjr1V4U2j/uib3Xy8NmBlpA6xp8JaGu530JWocCjdluykWG48fgh/PH8sg7J8lkhKnIfZxw7igzWF7NlXy89OH86OvdXER0dxy8nDml3jwkl5VNc38tCnmzhmSCZREcL63b6BdlPRPu7/YD27y2tYv7uCodn2c0b2TsYYWLGjrCmza+6SHa3cUU/P20KcJ5JvT7VrvLtWR1l1PfM3F1PfaFi90ycQ+XuryUuPZ2xuCsvyS4Pe+77aBqrqGrjqsflc/u+vebpFdpjXLyvNTQhoj7Lqel5b2r6L6Ztd5Yy9811W5Je1OuZ+5sYg4tsWC7aUNMtU86+yHEp86F8fb2DMHe92Skyioqae3FQbawu36+ePb6/hrre/OeDrFFdawdjdBTGhlqirSunW3Hra8KD7TxyZTUxUBKP7pDBjaBa1Dd5mFgvAEX1TGZubwoodZdx62nBufXEZ652BtrymnmufXMjmPZU8+MlGqusbmTnG1ug6alAGEQKfrC1iTUE5CdGRVNY18taKAr5zjC2jUlJZx6tLd3Lx5DxG9LL1vD5dV0RybBTH/OkjEmPtv5dr4Rhj2L63irF5KSTHevj355uoqW9scmP5M/uphUSINAXQH/p0E1ccNaDpeHFlHQ3OABpqEP/pr7Zw93vrGN83tSlrLRCfriuiwWtYsn0vY/Oau/Tcp90dpdVU1zUSF92678G4Zc5SxuQm89AVkwGaTZgMZTD88zu2dtmy/FImHODyxRU1DfROiWVXeQ2lYbQ46hu9bHZcmfWNXjyR+/+svmefIxxqcSjK/jOxXxqj+9iBbUxuStB4wZ1nj+LX3xrF+L6pDMlK5L3Vhdzx2kp+/J9lbCup4v/OGU21k7I7NMdaHCnxHib2s8H5b3ZVMHNsb4bnJPHe6l1N1/1sfRF1DV4untyXPs7T6x2vr+InLy6jur6RIucffNOefXi9huX5ZZRW1TO+byrj+6ZaaySAu6qh0WtdVM58lakD08nfW91UkgV8T/5RERJyaq+bJBDMVdfUzilAGciqKPLrw6Y9oVsdDY1eCsqqmy0EVlbdMYtjiGMNtrfuSyhU1NaTHOchJc5DaXX4LI6txVXUNxrqGw2bDtC9V7zP9rMoiHB4vYYv26lQ3VmocCiHPJP6p3OtYyVMHmDF5bn52/hgTSE/nzmi2ZO8OzgBHDcsixU7yiiqqGVEryROHZ3D/M0lTVV/v9iwh5Q4D6P7pDAgI577LhlP3/Q4Pl5bRKRTwysvLY6aei87Sqt5c0UBnkjhtFG9mNAvFYClAUqbbCmupNav1MpVRw9o1dZ1mZ08MofVBeXM39z2LHmv17DYEY62BjBjDItcgQkwAbKwvJZYjx022hMgf3ZX1OI1NoPJHdjK/YWjrP2n6CrH+npv1a52WgbH6zV8sLqQsup6kmKjSI3ztGlxbCzaR32jl52l1ftV/sb/d+S/hk1HMcY0CYf/A4Q/n23Yw2WPfs2Sg5Cyq8KhHFZce8xA1vzudF69cTq/P3dMk6D896Zj+Na43gxzSsgDnO+XNTSiVzJnjuuN19g0WGMMX2wo5qhBGURGCCLCuRNyOXNsHwAm90/jxeuP4g/njQXgpUX5zF2yg2OHZpES7yEnOZbc1LiAZVFWF/gsiJzkGE4ckY0nUprVz3Kf0G+bOYLeKbH87KVlfO2U0Wj0mlaDy8aifU2ZRG6cYfG2vUz7fx82W5Fx855KiivriImKaJqf4s/uihom9U8jzhPZJDCh4Ga1VdU1UuwIr2txZCfFsKu87Yl4jV5DoV9gPljw3qWmvpH/fdPaMvlkXRHffWoh20uqSYqNIiXe08zy8aesup6Z933Gw59u4qS/ftKhKgQuG5x4Wkcsw0CU1zRQ56Qs7y4PLLLuBNRvCsI/uVSFQzmsEBHioiMZ3SeFy6f1xyndz9i8FP5x2cRmPujc1Di++vmJ3HHWKKYNSmdEr2TOn5DLo59t5raXl7OjtJrpQzKaXf+UUbYU+5SB6Rw5IJ0jnBjB/R+ux+s13HjCkKa2xwzJ5PMNe/jnRxt4Z6XvKXr1znI8kcIFE/M4Y2xvYj2RjOqd3ExkCstriBDomxbHPRePp77RcNXj8ymrrudXr67gmLs+amaFzHO2s5NimoTjs3V72FVewzPzfItyPf7FFqIihAsn5bGrvKbZfAewg1ZeajzTBqXz6brQV9bcWeoTMnfehFv9eHzf1Hatl6KKWhq9hqkD05tdIxivLd3Bd55YyModzQP8/q7BpFgPqXEe9gYJju/YW01do5fnvt5GdX0jK3a0ThZoj/W795GbGseQ7ES+CSGL7sM11o3aEje+4YmUoDEOV5A7YgnuLyocitIGvVPsmiJRjqDcPnMEE/qlMnfJDmaO6cW5E3KbtZ/QN407zhrFFdNsllVqfDR/v3QCf7lwHB/8+LhmcZjjhmdRUdPAX95dyw+eX8yCLSXUN3qZv7mYodlJ/PXiI7jjrNGAdUkt2rqXDbsrKK+pZ1tJFVlJMURFRnDU4AweuHwiNfVe7n53LXMWbMdrDNc/s6hpVcVXFuczNDuRE4ZnN7mqVu20A+F/Fm7nhYXb2VpcyZwF27j4yL7MGGZXzfRPu230GvbsqyU7OYYZw7LYUlzVrCSMP8YYrnpsPt9/dhE7S6vZ6VdexrVwyqrriRDrPiwsr2218Jc/Ox2LZdogK9Qta5i1ZPMe+xlft3DhrfdLXU6KjSItPjqoq8q1gtwyMetDzF7zZ2PRPgZnJzKiV1JIEz5fWbyDJ7/a2qpMjuumGpKdRGF5TcA4hiuAgVyMnY1mVSlKB8hOjuU/3zsKY0yTteJPRIQ0LV7lctYRfQJea/rgTCIE0hOiiY+O4tKH55GTHMuO0mp+/a1RzdqePymPez5Yx+n3fUZ2UgwlVXV8a5zvumNzUxiek8TT87aSnhDNXy4cx7VPLuSVxflMHpDOkm2l/OrMkRhjhaKwvIbVBeUMz0misKKGn720nN4ptsDkD04cQoQIkRHCWysKGN83FYA3VxTgNfZ3cPRgO4B/sr6IKzL6t7q3JdtL+WRdESK2JMvE/qnEemyVZFdsyqptgHpUb2uVrSkoD7oGTIFjsUwblMH9H64PKlgurjgt2FzS5I6E5qnLybEe66oKIhwti1ZuLNpHo9c0xa/awxjD1j1VTOyXRu+UOF5dupOyqnpS4j1Bz3Hn5GwvqWpaeRN8Fseo3smsKSinrLq+1SRAV3j3J1W6o6jFoSj7QSDR6Cgp8R5uPW04d50/jtdunM7l0/ozLi+Ff1w2odlgB9ZtdvywLBJioiisqKWm3svsGb6JjiLCj08dxswxvXj1+9M5cUQ24/JSuOf9dVz04FckxkRx3oRcThyZTYTAve+vI39vNedOyGXJr0/hhOFZFJTV8O2p/eidEkdOciwzx/Ti+fnbqKxtYOn2Um5+fgljc1M4c2xvBmUmkJsa1+Suahk4fnXJDmKiIvj7pRNYW1jBCwvz6ZsWT3ZSDJsda6Gsup6UOA8je9sBsq0JkW6MZGTvJFLiPGwtadvicF1ZC7aUND2dN3pNs6fxWE8kqXHRVNQ2UB+g5EmBn3stQqC2wcv2kirufH0Vt7+8vN3qyXur6qmobaB/RgIjnHtsq4yNf+quf/aZMb56a0c5gu0/N6jp8xzh2FFa3WRphgu1OBSlC/n+8b6Yx51nj26z7T8um4jXGN5YXsDO0upmgXyA00b34rTRvZre33rqcO77YB39MxK4+aShZCTGkJEYw7njc5mzYDsAo/okIyL8/ryxPPDxBn5w4tCm8689ZiBvLC/gXx9vYMPufSTHRvH87GkkOmVXZgzL4r/LdnLRg1+yYMteZgzL4g/njiHWE8lrS3dy8qgcvjWuD4u3lvLYF5vpkxrHsF5JfPTNbmrqGymvscKRkRhDTnJMq8HQ6zXUe73EREWyvaSKOE8kKXEe+mfENxtYwVZXXrmjjFOd+99aXElSbBTFlXWs372PYTlJbC2upK7BS2q8zaSyT+326b+8up6MxJhm1ywoqyE+OpKqukamD8nks/V7eGtlQVMlgJr6Ru6bNSHo97XVEcj+6fFN83y+2VXOFCdOE6i9OzfH3xU3d8kOHvp0EyeOyObkkTaGtmR7KUe3sM5KquoQAWOsdTQuLzVo3w4UFQ5F6SG4dbIundIvpPYzhmU1xSr8uf2METR4Dfl7q5rSgnNT4/j9uWObtZvQL40LJubxr483Ygz84MQhTaIBcNywTJ6fv41FW/dyxbT+vLw4nxPu/pic5Fiq6xv54UlWhG6bOdxxQ2Uwsncyby4v4M3lBdb/71QEGJubwsKte5tcgNtLqrjxucVs3lPJ9ccN5u2VuzhqcAYiQr/0+KZZ9y8tyuf/3lhNQ6OXyrpG/jN7GiN6JVNe08C1xwzk359v5v3VhQzLSWpKFvjXtyfy4sJ8LpiYyyeOxbS3qrVw7CqvZnivJG4+aShDsxM55k8f8ehnmwGYMiCdrzYVB3VZgs/q6Z8RT6/kWFLiPG1mVvnHUPyD/59v2ENWUgyPXDmZyAhhcFYCS7a1zmjbW1nHuLxUlm0vZeWO8rAKh7qqFOUwIzsplr9dOoFXvj+d5Njg/naA33xrFOeNz+XWU4c1ywgDOHpIJkkxUdx0whD+79wx/O8nx/OdYwaSkRjN784e3WQRxURF8vzsacyeMZjpgzPpnxHPz+euYHtJdVOplpNG5rCtpIrVBeXU1DdyzRML2LynkvF9U/nLu2vZXVHLZY5gHpGXyvaSan796koe/2IzsZ4ITh6VQ2ZiNP/4aEPToHvkgHSO6JvaNO/jpUX5DM5K4KhBGdx7yXhS46Ob4gTF+1pnKhWU1dA7JZYThmeTlxbPeRNyKamsY3zfVM6dkEtheS2b9gR3mblWUd/0eESE0X2SeXtFQcCFyL7csIe//28DInYu0RY/i2r1znJG90luiq1M6JfGkm2lrQLkJZV1jM9LISXOw/I2ytl0BiociqIEJSXewz2XjOemE4e2Ko2SHOvh61+exI9OsfXBeqXE8oszRvL6TccwK4hVFBEhPHrlZPJS4zh1VE6T6+XUUXbxrDP/9jln/+NzNuzex7++PZEnrpnCqaNyGJKdyPHDrfX0nWMGct2xA3l63lZW7Szn+uMGc/+sCXz32EF8tt6mNwP0S4/ntNE5LMsvY/zv3mPh1r1cNLlvMwsh3RGOSx6e12xAN8awq6yGXslxTfvuOGsUQ7MTuXRK36Y07C/aWI1yS3ElvZJjm35vvz17NGkJ0dw8Z2mrmMr9H65nS3El50/IY3ivJLY5rqq6Bi8bi/YxsndyU9tJ/dMorqxrllpc3+ilvKaB9IQYxuWlsDxAnbHORF1ViqLsN/HRHR9ChuYk8eFPjsMYX5JBRqJN8f10XRFp8dH84bwxHDvUCsVDV0yivtE0pURHRgi/OGMkm/dU8fmGoqaste9MH8jbKwp4Z9UuxvdNZWhOIr1TYimrqqe8pp6dpTVc1KIU/Kg+yfzmW6P42//W89z8bRw9JJPd5TWsLaygqq6RPqm+Uu+p8dG8/+PjACssI3olcf8H6zlpZE5TwcS5S/Iprapncv90Fm/dS/8MX7n7oTlJ3H76CGY/vYhP1haxu6KWbSVVXHfsQBZu3cv3ZgziZ6eP4IGPN/Lm8gIWbikhLjqS+kbDKD/hOH10L+54bRUvLsxn9Nk2I81NKU5P8DAuL4UHPwleB60zCKtwiMjpwP1AJPCoMeauFsfFOX4GUAVcbYxZLCJ9gaeAXoAXeNgYc79zzp3AdYA7++gXxpi3wnkfiqJ0LiJCy9DAPy+bQG2Dl8wWsQYRITpKWu174PKJ7K6obWofHRXBA5dP4o3lO7li2gA8kRGkJUTz8zNGBu1HZITwnWMGsmnPPl5alM93nljA/76xJdAHZSZwXot5Ov6f/4/LJnLuP7/goge+JC0hmqjIiKbsJ4DoyAh+c1bztOoTRmSTmRjNz15e3pQ+++AnGwE4cYS1vq48qj9Pf7WFW19cxtSB1rLxtzjSEqI5ZXQOry7dwU9PG05CTFTTtdISoslOjqXRa/hiw56mZZA7m7C5qkQkEvgnMBMYBVwqIqNaNJsJDHV+ZgMPOPsbgJ8YY0YC04AbW5x7rzFmvPOjoqEohwBJsZ5WotEWnsiIpid9lz6pccyeMbhDVXsBzpuQR029l8Xb9nLzSUP5zbdGMWf2tFYBc3+GZCcyZ/Y0RASvsZldp43O4aNbj+fPF4zjpRuO4sQRzQduT2QEt88cyajeydx0whD+cuE4AJJiopoq/ibERPHXi8dTU+/lPwu3MyQ7kYEtFpr6zvQBlFfX88M5S9lbWcd9H6wDrOvtuGFZDMxM4DevreKXc1eEZSa5hKuSoogcBdxpjDnNef9zAGPMH/3aPAR8bIx53nm/FjjeGFPQ4lqvAf8wxrzvWBz7jDF3h9qXyZMnm4ULFx7oLSmKcgizdHspQ7ITm2WOhYLXa4iIkKZgdUfn+OyuqKG6rrFVqfvahkZb4iUtLuA1n/hiM3f+dzVxnkiq6xuJiYrgo1uPp09qHAu3lHDFv+cTFx3J32ZN4JihgSdWtoeILDLGTG65P5yuqlxgu9/7fGBqCG1ygSbhEJEBwATga792N4nIlcBCrGXSKjdNRGZjrRj69QstfVFRlMMXd4Z8R4lwsp32d1JodlLgJXNjoiLpmx58SeCrpw8kMjKCRz/bxP+dM4apg9KJibKW1uQB6az+3WmdMlE1EOHMqgrU45bmTZttRCQReBm4xRjjphA8AAwGxmMF5q+BPtwY87AxZrIxZnJWVutcdkVRlJ7OFdP688lPT2DGsKwm0XAJl2hAeIUjH+jr9z4P2BlqGxHxYEXjWWPMK24DY0yhMabRGOMFHgGmhKHviqIoShDCKRwLgKEiMlBEooFZwOst2rwOXCmWaUCZMabAybb6N7DGGHOP/wki0tvv7XlA6xrEiqIoStgIW4zDGNMgIjcB72LTcR8zxqwSkeud4w8Cb2FTcTdg03GvcU6fDlwBrBCRpc4+N+32zyIyHuvS2gJ8L1z3oCiKorQmbFlV3QnNqlIURek4wbKqDgvhEJEiYGu7DQOTCQSvK9Cz0Hvpnui9dE/0XqC/MaZVdtFhIRwHgogsDKS4PRG9l+6J3kv3RO8lOFrkUFEURekQKhyKoihKh1DhaJ+Hu7oDnYjeS/dE76V7ovcSBI1xKIqiKB1CLQ5FURSlQ6hwKIqiKB1ChaMNROR0EVkrIhtE5Pau7k9HEZEtIrJCRJaKyEJnX7qIvC8i653XtK7uZyBE5DER2S0iK/32Be27iPzc+Z7WishpXdPr1gS5jztFZIfzvSwVkTP8jnXL+wAQkb4i8pGIrBGRVSLyQ2d/T/xegt1Lj/tuRCRWROaLyDLnXn7r7A/f92KM0Z8AP9gyKRuBQUA0sAwY1dX96uA9bAEyW+z7M3C7s3078Keu7meQvs8AJgIr2+s7dqGwZUAMMND53iK7+h7auI87gVsDtO229+H0rzcw0dlOAtY5fe6J30uwe+lx3w22yniis+3BLkExLZzfi1ocwZkCbDDGbDLG1AFzgHO6uE+dwTnAk872k8C5XdeV4BhjPgVKWuwO1vdzgDnGmFpjzGZs7bNuUTU5yH0Eo9veB4AxpsAYs9jZrgDWYNfP6YnfS7B7CUZ3vhdjjHGX+fM4P4Ywfi8qHMEJtshUT8IA74nIImdhK4Ac46yw6Lxmd1nvOk6wvvfE7+omEVnuuLJcF0KPuY8WC6z16O8lwGJxPe67EZFIpyDsbuB9Y0xYvxcVjuCEshBVd2e6MWYidm33G0VkRld3KEz0tO8q2GJkPeI+giywFrBpgH3d6n4C3EuP/G6MXaNoPHZNoykiMqaN5gd8LyocwQllIapujTFmp/O6G5iLNUcL3TVNnNfdXdfDDhOs7z3quzLBFyPr9vcRZIG1Hvm9BLqXnvzdABhjSoGPgdMJ4/eiwhGcUBai6raISIKIJLnbwKnYRa9eB65yml0FvNY1PdwvgvX9dWCWiMSIyEBgKDC/C/oXEm0sRtat70Mk6AJrPe57CXYvPfG7EZEsEUl1tuOAk4FvCOf30tUZAd35B7vI1Dps1sEvu7o/Hez7IGzmxDJgldt/IAP4EFjvvKZ3dV+D9P95rKugHvuEdG1bfQd+6XxPa4GZXd3/du7jaWAFsNz5J+7d3e/D6dsxWJfGcmCp83NGD/1egt1Lj/tugHHAEqfPK4HfOPvD9r1oyRFFURSlQ6irSlEURekQKhyKoihKh1DhUBRFUTqECoeiKIrSIVQ4FEVRlA6hwqEo3RAROV5E3ujqfihKIFQ4FEVRlA6hwqEoB4CIXO6shbBURB5yis3tE5G/ishiEflQRLKctuNFZJ5TQG+uW0BPRIaIyAfOegqLRWSwc/lEEXlJRL4RkWed2c6IyF0istq5zt1ddOvKYYwKh6LsJyIyErgEW0xyPNAIfBtIABYbW2DyE+AO55SngNuMMeOws5Pd/c8C/zTGHAEcjZ1pDrZi6y3Y9RMGAdNFJB1bCmO0c53fh/MeFSUQKhyKsv+cBEwCFjglrU/CDvBe4D9Om2eAY0QkBUg1xnzi7H8SmOHUE8s1xswFMMbUGGOqnDbzjTH5xhbcWwoMAMqBGuBRETkfcNsqykFDhUNR9h8BnjTGjHd+hhtj7gzQrq26PoFKXLvU+m03AlHGmAZsxdaXsQvzvNOxLivKgaPCoSj7z4fAhSKSDU1rPPfH/l9d6LS5DPjcGFMG7BWRY539VwCfGLsGRL6InOtcI0ZE4oN9oLN+RIox5i2sG2t8p9+VorRDVFd3QFF6KsaY1SLyK+wqixHYCrg3ApXAaBFZBJRh4yBgS1s/6AjDJuAaZ/8VwEMi8jvnGhe18bFJwGsiEou1Vn7UybelKO2i1XEVpZMRkX3GmMSu7oeihAt1VSmKoigdQi0ORVEUpUOoxaEoiqJ0CBUORVEUpUOocCiKoigdQoVDURRF6RAqHIqiKEqH+P9zH3jpet3F9gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.ylim(0.02, 0.2)\n",
    "plt.title('Mean square error')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1f4930aa308>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['mean_absolute_error'], label='train')\n",
    "plt.plot(history.history['val_mean_absolute_error'], label='validation')\n",
    "plt.ylim(0.12, 0.26)\n",
    "plt.title('Mean absolute error')\n",
    "plt.ylabel('metrics')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "測試數據的誤差百分比：用測試數據預測房屋價格並與答案計算誤差百分比。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_1 Percentage Error: 13.60%\n"
     ]
    }
   ],
   "source": [
    "# 載入模型\n",
    "model = keras.models.load_model('lab2-logs/models/Best-model-1.h5')\n",
    "# 先將房屋價格取出\n",
    "y_test = np.array(test_data['price'])\n",
    "# 標準化數據\n",
    "test_data = (test_data - mean) / std\n",
    "# 將輸入數據存成Numpy 格式\n",
    "x_test = np.array(test_data.drop('price', axis='columns'))\n",
    "# 預測測試數據\n",
    "y_pred = model.predict(x_test)\n",
    "# 將預測結果轉換回來(因為訓練時的訓練目標也有經過標準化)\n",
    "y_pred = np.reshape(y_pred * std['price'] + mean['price'], y_test.shape)\n",
    "# 計算平均的誤差百分比\n",
    "percentage_error = np.mean(np.abs(y_test - y_pred)) / np.mean(y_test) * 100\n",
    "# 顯示誤差百分比\n",
    "print(\"Model_1 Percentage Error: {:.2f}%\".format(percentage_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorBoard 可視化工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 這行指令可以幫助我們直接在jupyter notebook上顯示TensorBoard\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 19740."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --port 9530 --logdir lab2-logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 實驗二：過擬合問題\n",
    "\n",
    "### 方法一、減少網路權重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "  2/203 [..............................] - ETA: 26s - loss: 0.9657 - mean_absolute_error: 0.6888WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.2584s). Check your callbacks.\n",
      "203/203 [==============================] - 1s 2ms/step - loss: 0.5598 - mean_absolute_error: 0.4676 - val_loss: 0.3080 - val_mean_absolute_error: 0.3683\n",
      "Epoch 2/300\n",
      "203/203 [==============================] - 0s 787us/step - loss: 0.2826 - mean_absolute_error: 0.3346 - val_loss: 0.2345 - val_mean_absolute_error: 0.3123\n",
      "Epoch 3/300\n",
      "203/203 [==============================] - 0s 760us/step - loss: 0.2331 - mean_absolute_error: 0.3044 - val_loss: 0.2192 - val_mean_absolute_error: 0.2968\n",
      "Epoch 4/300\n",
      "203/203 [==============================] - 0s 740us/step - loss: 0.2119 - mean_absolute_error: 0.2878 - val_loss: 0.1943 - val_mean_absolute_error: 0.2763\n",
      "Epoch 5/300\n",
      "203/203 [==============================] - 0s 749us/step - loss: 0.1987 - mean_absolute_error: 0.2785 - val_loss: 0.1813 - val_mean_absolute_error: 0.2637\n",
      "Epoch 6/300\n",
      "203/203 [==============================] - 0s 726us/step - loss: 0.1851 - mean_absolute_error: 0.2669 - val_loss: 0.1734 - val_mean_absolute_error: 0.2542\n",
      "Epoch 7/300\n",
      "203/203 [==============================] - 0s 681us/step - loss: 0.1739 - mean_absolute_error: 0.2575 - val_loss: 0.1770 - val_mean_absolute_error: 0.2598\n",
      "Epoch 8/300\n",
      "203/203 [==============================] - 0s 724us/step - loss: 0.1661 - mean_absolute_error: 0.2517 - val_loss: 0.1613 - val_mean_absolute_error: 0.2435\n",
      "Epoch 9/300\n",
      "203/203 [==============================] - 0s 674us/step - loss: 0.1597 - mean_absolute_error: 0.2455 - val_loss: 0.1592 - val_mean_absolute_error: 0.2447\n",
      "Epoch 10/300\n",
      "203/203 [==============================] - 0s 718us/step - loss: 0.1531 - mean_absolute_error: 0.2422 - val_loss: 0.1533 - val_mean_absolute_error: 0.2369\n",
      "Epoch 11/300\n",
      "203/203 [==============================] - 0s 724us/step - loss: 0.1486 - mean_absolute_error: 0.2374 - val_loss: 0.1495 - val_mean_absolute_error: 0.2321\n",
      "Epoch 12/300\n",
      "203/203 [==============================] - 0s 728us/step - loss: 0.1437 - mean_absolute_error: 0.2342 - val_loss: 0.1509 - val_mean_absolute_error: 0.2312\n",
      "Epoch 13/300\n",
      "203/203 [==============================] - 0s 719us/step - loss: 0.1408 - mean_absolute_error: 0.2302 - val_loss: 0.1460 - val_mean_absolute_error: 0.2285\n",
      "Epoch 14/300\n",
      "203/203 [==============================] - 0s 735us/step - loss: 0.1368 - mean_absolute_error: 0.2282 - val_loss: 0.1430 - val_mean_absolute_error: 0.2256\n",
      "Epoch 15/300\n",
      "203/203 [==============================] - 0s 735us/step - loss: 0.1329 - mean_absolute_error: 0.2249 - val_loss: 0.1404 - val_mean_absolute_error: 0.2232\n",
      "Epoch 16/300\n",
      "203/203 [==============================] - 0s 741us/step - loss: 0.1306 - mean_absolute_error: 0.2228 - val_loss: 0.1418 - val_mean_absolute_error: 0.2210\n",
      "Epoch 17/300\n",
      "203/203 [==============================] - 0s 728us/step - loss: 0.1288 - mean_absolute_error: 0.2217 - val_loss: 0.1365 - val_mean_absolute_error: 0.2190\n",
      "Epoch 18/300\n",
      "203/203 [==============================] - 0s 730us/step - loss: 0.1255 - mean_absolute_error: 0.2193 - val_loss: 0.1336 - val_mean_absolute_error: 0.2163\n",
      "Epoch 19/300\n",
      "203/203 [==============================] - 0s 722us/step - loss: 0.1248 - mean_absolute_error: 0.2183 - val_loss: 0.1324 - val_mean_absolute_error: 0.2156\n",
      "Epoch 20/300\n",
      "203/203 [==============================] - 0s 740us/step - loss: 0.1221 - mean_absolute_error: 0.2178 - val_loss: 0.1314 - val_mean_absolute_error: 0.2135\n",
      "Epoch 21/300\n",
      "203/203 [==============================] - 0s 702us/step - loss: 0.1194 - mean_absolute_error: 0.2137 - val_loss: 0.1316 - val_mean_absolute_error: 0.2148\n",
      "Epoch 22/300\n",
      "203/203 [==============================] - 0s 681us/step - loss: 0.1165 - mean_absolute_error: 0.2121 - val_loss: 0.1347 - val_mean_absolute_error: 0.2195\n",
      "Epoch 23/300\n",
      "203/203 [==============================] - 0s 800us/step - loss: 0.1169 - mean_absolute_error: 0.2118 - val_loss: 0.1318 - val_mean_absolute_error: 0.2124\n",
      "Epoch 24/300\n",
      "203/203 [==============================] - 0s 814us/step - loss: 0.1128 - mean_absolute_error: 0.2095 - val_loss: 0.1275 - val_mean_absolute_error: 0.2087\n",
      "Epoch 25/300\n",
      "203/203 [==============================] - 0s 708us/step - loss: 0.1125 - mean_absolute_error: 0.2084 - val_loss: 0.1331 - val_mean_absolute_error: 0.2133\n",
      "Epoch 26/300\n",
      "203/203 [==============================] - 0s 758us/step - loss: 0.1114 - mean_absolute_error: 0.2074 - val_loss: 0.1297 - val_mean_absolute_error: 0.2104\n",
      "Epoch 27/300\n",
      "203/203 [==============================] - 0s 753us/step - loss: 0.1076 - mean_absolute_error: 0.2054 - val_loss: 0.1253 - val_mean_absolute_error: 0.2082\n",
      "Epoch 28/300\n",
      "203/203 [==============================] - 0s 786us/step - loss: 0.1093 - mean_absolute_error: 0.2062 - val_loss: 0.1253 - val_mean_absolute_error: 0.2060\n",
      "Epoch 29/300\n",
      "203/203 [==============================] - 0s 797us/step - loss: 0.1081 - mean_absolute_error: 0.2049 - val_loss: 0.1254 - val_mean_absolute_error: 0.2055\n",
      "Epoch 30/300\n",
      "203/203 [==============================] - 0s 746us/step - loss: 0.1060 - mean_absolute_error: 0.2038 - val_loss: 0.1290 - val_mean_absolute_error: 0.2077\n",
      "Epoch 31/300\n",
      "203/203 [==============================] - 0s 816us/step - loss: 0.1050 - mean_absolute_error: 0.2026 - val_loss: 0.1249 - val_mean_absolute_error: 0.2050\n",
      "Epoch 32/300\n",
      "203/203 [==============================] - 0s 742us/step - loss: 0.1042 - mean_absolute_error: 0.2019 - val_loss: 0.1269 - val_mean_absolute_error: 0.2061\n",
      "Epoch 33/300\n",
      "203/203 [==============================] - 0s 870us/step - loss: 0.1042 - mean_absolute_error: 0.2021 - val_loss: 0.1201 - val_mean_absolute_error: 0.2042\n",
      "Epoch 34/300\n",
      "203/203 [==============================] - 0s 837us/step - loss: 0.1040 - mean_absolute_error: 0.2012 - val_loss: 0.1226 - val_mean_absolute_error: 0.2038\n",
      "Epoch 35/300\n",
      "203/203 [==============================] - 0s 689us/step - loss: 0.1017 - mean_absolute_error: 0.1998 - val_loss: 0.1278 - val_mean_absolute_error: 0.2059\n",
      "Epoch 36/300\n",
      "203/203 [==============================] - 0s 746us/step - loss: 0.1007 - mean_absolute_error: 0.1995 - val_loss: 0.1303 - val_mean_absolute_error: 0.2074\n",
      "Epoch 37/300\n",
      "203/203 [==============================] - 0s 705us/step - loss: 0.1007 - mean_absolute_error: 0.1995 - val_loss: 0.1370 - val_mean_absolute_error: 0.2093\n",
      "Epoch 38/300\n",
      "203/203 [==============================] - 0s 699us/step - loss: 0.1001 - mean_absolute_error: 0.1993 - val_loss: 0.1392 - val_mean_absolute_error: 0.2076\n",
      "Epoch 39/300\n",
      "203/203 [==============================] - 0s 765us/step - loss: 0.0997 - mean_absolute_error: 0.1989 - val_loss: 0.1198 - val_mean_absolute_error: 0.2005\n",
      "Epoch 40/300\n",
      "203/203 [==============================] - 0s 730us/step - loss: 0.0982 - mean_absolute_error: 0.1973 - val_loss: 0.1231 - val_mean_absolute_error: 0.2042\n",
      "Epoch 41/300\n",
      "203/203 [==============================] - 0s 755us/step - loss: 0.0991 - mean_absolute_error: 0.1985 - val_loss: 0.1214 - val_mean_absolute_error: 0.2026\n",
      "Epoch 42/300\n",
      "203/203 [==============================] - 0s 711us/step - loss: 0.0990 - mean_absolute_error: 0.1984 - val_loss: 0.1159 - val_mean_absolute_error: 0.2006\n",
      "Epoch 43/300\n",
      "203/203 [==============================] - 0s 739us/step - loss: 0.0979 - mean_absolute_error: 0.1972 - val_loss: 0.1252 - val_mean_absolute_error: 0.2046\n",
      "Epoch 44/300\n",
      "203/203 [==============================] - 0s 761us/step - loss: 0.0971 - mean_absolute_error: 0.1961 - val_loss: 0.1288 - val_mean_absolute_error: 0.2039\n",
      "Epoch 45/300\n",
      "203/203 [==============================] - 0s 808us/step - loss: 0.0954 - mean_absolute_error: 0.1957 - val_loss: 0.1183 - val_mean_absolute_error: 0.1996\n",
      "Epoch 46/300\n",
      "203/203 [==============================] - 0s 771us/step - loss: 0.0947 - mean_absolute_error: 0.1960 - val_loss: 0.1179 - val_mean_absolute_error: 0.1986\n",
      "Epoch 47/300\n",
      "203/203 [==============================] - 0s 752us/step - loss: 0.0947 - mean_absolute_error: 0.1946 - val_loss: 0.1179 - val_mean_absolute_error: 0.1995\n",
      "Epoch 48/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 0s 759us/step - loss: 0.0955 - mean_absolute_error: 0.1947 - val_loss: 0.1253 - val_mean_absolute_error: 0.2022\n",
      "Epoch 49/300\n",
      "203/203 [==============================] - 0s 740us/step - loss: 0.0964 - mean_absolute_error: 0.1955 - val_loss: 0.1327 - val_mean_absolute_error: 0.2040\n",
      "Epoch 50/300\n",
      "203/203 [==============================] - 0s 715us/step - loss: 0.0954 - mean_absolute_error: 0.1949 - val_loss: 0.1304 - val_mean_absolute_error: 0.2047\n",
      "Epoch 51/300\n",
      "203/203 [==============================] - 0s 833us/step - loss: 0.0931 - mean_absolute_error: 0.1940 - val_loss: 0.1173 - val_mean_absolute_error: 0.1981\n",
      "Epoch 52/300\n",
      "203/203 [==============================] - 0s 706us/step - loss: 0.0935 - mean_absolute_error: 0.1932 - val_loss: 0.1187 - val_mean_absolute_error: 0.1983\n",
      "Epoch 53/300\n",
      "203/203 [==============================] - 0s 854us/step - loss: 0.0916 - mean_absolute_error: 0.1921 - val_loss: 0.1164 - val_mean_absolute_error: 0.1973\n",
      "Epoch 54/300\n",
      "203/203 [==============================] - 0s 771us/step - loss: 0.0917 - mean_absolute_error: 0.1921 - val_loss: 0.1170 - val_mean_absolute_error: 0.1969\n",
      "Epoch 55/300\n",
      "203/203 [==============================] - 0s 762us/step - loss: 0.0916 - mean_absolute_error: 0.1924 - val_loss: 0.1170 - val_mean_absolute_error: 0.1983\n",
      "Epoch 56/300\n",
      "203/203 [==============================] - 0s 701us/step - loss: 0.0917 - mean_absolute_error: 0.1930 - val_loss: 0.1251 - val_mean_absolute_error: 0.1996\n",
      "Epoch 57/300\n",
      "203/203 [==============================] - 0s 763us/step - loss: 0.0911 - mean_absolute_error: 0.1924 - val_loss: 0.1267 - val_mean_absolute_error: 0.2002\n",
      "Epoch 58/300\n",
      "203/203 [==============================] - 0s 724us/step - loss: 0.0905 - mean_absolute_error: 0.1921 - val_loss: 0.1251 - val_mean_absolute_error: 0.1982\n",
      "Epoch 59/300\n",
      "203/203 [==============================] - 0s 700us/step - loss: 0.0912 - mean_absolute_error: 0.1921 - val_loss: 0.1196 - val_mean_absolute_error: 0.1989\n",
      "Epoch 60/300\n",
      "203/203 [==============================] - 0s 699us/step - loss: 0.0907 - mean_absolute_error: 0.1918 - val_loss: 0.1256 - val_mean_absolute_error: 0.1998\n",
      "Epoch 61/300\n",
      "203/203 [==============================] - 0s 720us/step - loss: 0.0896 - mean_absolute_error: 0.1903 - val_loss: 0.1206 - val_mean_absolute_error: 0.1977\n",
      "Epoch 62/300\n",
      "203/203 [==============================] - 0s 765us/step - loss: 0.0889 - mean_absolute_error: 0.1893 - val_loss: 0.1145 - val_mean_absolute_error: 0.2025\n",
      "Epoch 63/300\n",
      "203/203 [==============================] - 0s 764us/step - loss: 0.0889 - mean_absolute_error: 0.1907 - val_loss: 0.1182 - val_mean_absolute_error: 0.1967\n",
      "Epoch 64/300\n",
      "203/203 [==============================] - 0s 696us/step - loss: 0.0897 - mean_absolute_error: 0.1906 - val_loss: 0.1242 - val_mean_absolute_error: 0.1997\n",
      "Epoch 65/300\n",
      "203/203 [==============================] - 0s 667us/step - loss: 0.0892 - mean_absolute_error: 0.1903 - val_loss: 0.1195 - val_mean_absolute_error: 0.2004\n",
      "Epoch 66/300\n",
      "203/203 [==============================] - 0s 688us/step - loss: 0.0881 - mean_absolute_error: 0.1890 - val_loss: 0.1214 - val_mean_absolute_error: 0.2035\n",
      "Epoch 67/300\n",
      "203/203 [==============================] - 0s 762us/step - loss: 0.0873 - mean_absolute_error: 0.1895 - val_loss: 0.1181 - val_mean_absolute_error: 0.1966\n",
      "Epoch 68/300\n",
      "203/203 [==============================] - 0s 683us/step - loss: 0.0885 - mean_absolute_error: 0.1901 - val_loss: 0.1213 - val_mean_absolute_error: 0.2103\n",
      "Epoch 69/300\n",
      "203/203 [==============================] - 0s 683us/step - loss: 0.0883 - mean_absolute_error: 0.1894 - val_loss: 0.1203 - val_mean_absolute_error: 0.1999\n",
      "Epoch 70/300\n",
      "203/203 [==============================] - 0s 751us/step - loss: 0.0872 - mean_absolute_error: 0.1892 - val_loss: 0.1221 - val_mean_absolute_error: 0.1966\n",
      "Epoch 71/300\n",
      "203/203 [==============================] - 0s 793us/step - loss: 0.0871 - mean_absolute_error: 0.1891 - val_loss: 0.1128 - val_mean_absolute_error: 0.1945\n",
      "Epoch 72/300\n",
      "203/203 [==============================] - 0s 753us/step - loss: 0.0863 - mean_absolute_error: 0.1885 - val_loss: 0.1160 - val_mean_absolute_error: 0.1946\n",
      "Epoch 73/300\n",
      "203/203 [==============================] - 0s 717us/step - loss: 0.0872 - mean_absolute_error: 0.1891 - val_loss: 0.1224 - val_mean_absolute_error: 0.1995\n",
      "Epoch 74/300\n",
      "203/203 [==============================] - 0s 706us/step - loss: 0.0862 - mean_absolute_error: 0.1877 - val_loss: 0.1243 - val_mean_absolute_error: 0.2064\n",
      "Epoch 75/300\n",
      "203/203 [==============================] - 0s 720us/step - loss: 0.0876 - mean_absolute_error: 0.1900 - val_loss: 0.1171 - val_mean_absolute_error: 0.1947\n",
      "Epoch 76/300\n",
      "203/203 [==============================] - 0s 710us/step - loss: 0.0865 - mean_absolute_error: 0.1885 - val_loss: 0.1227 - val_mean_absolute_error: 0.1974\n",
      "Epoch 77/300\n",
      "203/203 [==============================] - 0s 738us/step - loss: 0.0868 - mean_absolute_error: 0.1894 - val_loss: 0.1127 - val_mean_absolute_error: 0.1924\n",
      "Epoch 78/300\n",
      "203/203 [==============================] - 0s 698us/step - loss: 0.0860 - mean_absolute_error: 0.1882 - val_loss: 0.1202 - val_mean_absolute_error: 0.1959\n",
      "Epoch 79/300\n",
      "203/203 [==============================] - 0s 700us/step - loss: 0.0857 - mean_absolute_error: 0.1881 - val_loss: 0.1165 - val_mean_absolute_error: 0.1948\n",
      "Epoch 80/300\n",
      "203/203 [==============================] - 0s 753us/step - loss: 0.0856 - mean_absolute_error: 0.1881 - val_loss: 0.1248 - val_mean_absolute_error: 0.1964\n",
      "Epoch 81/300\n",
      "203/203 [==============================] - 0s 760us/step - loss: 0.0873 - mean_absolute_error: 0.1888 - val_loss: 0.1154 - val_mean_absolute_error: 0.1939\n",
      "Epoch 82/300\n",
      "203/203 [==============================] - 0s 720us/step - loss: 0.0850 - mean_absolute_error: 0.1868 - val_loss: 0.1261 - val_mean_absolute_error: 0.1977\n",
      "Epoch 83/300\n",
      "203/203 [==============================] - 0s 747us/step - loss: 0.0853 - mean_absolute_error: 0.1876 - val_loss: 0.1152 - val_mean_absolute_error: 0.1940\n",
      "Epoch 84/300\n",
      "203/203 [==============================] - 0s 726us/step - loss: 0.0842 - mean_absolute_error: 0.1868 - val_loss: 0.1229 - val_mean_absolute_error: 0.1959\n",
      "Epoch 85/300\n",
      "203/203 [==============================] - 0s 705us/step - loss: 0.0841 - mean_absolute_error: 0.1863 - val_loss: 0.1145 - val_mean_absolute_error: 0.1968\n",
      "Epoch 86/300\n",
      "203/203 [==============================] - 0s 675us/step - loss: 0.0850 - mean_absolute_error: 0.1874 - val_loss: 0.1140 - val_mean_absolute_error: 0.1938\n",
      "Epoch 87/300\n",
      "203/203 [==============================] - 0s 686us/step - loss: 0.0847 - mean_absolute_error: 0.1866 - val_loss: 0.1155 - val_mean_absolute_error: 0.1952\n",
      "Epoch 88/300\n",
      "203/203 [==============================] - 0s 683us/step - loss: 0.0845 - mean_absolute_error: 0.1880 - val_loss: 0.1139 - val_mean_absolute_error: 0.1935\n",
      "Epoch 89/300\n",
      "203/203 [==============================] - 0s 674us/step - loss: 0.0835 - mean_absolute_error: 0.1871 - val_loss: 0.1168 - val_mean_absolute_error: 0.1946\n",
      "Epoch 90/300\n",
      "203/203 [==============================] - 0s 666us/step - loss: 0.0830 - mean_absolute_error: 0.1870 - val_loss: 0.1187 - val_mean_absolute_error: 0.1950\n",
      "Epoch 91/300\n",
      "203/203 [==============================] - 0s 695us/step - loss: 0.0826 - mean_absolute_error: 0.1855 - val_loss: 0.1348 - val_mean_absolute_error: 0.2020\n",
      "Epoch 92/300\n",
      "203/203 [==============================] - 0s 709us/step - loss: 0.0843 - mean_absolute_error: 0.1867 - val_loss: 0.1226 - val_mean_absolute_error: 0.1958\n",
      "Epoch 93/300\n",
      "203/203 [==============================] - 0s 732us/step - loss: 0.0840 - mean_absolute_error: 0.1871 - val_loss: 0.1316 - val_mean_absolute_error: 0.2008\n",
      "Epoch 94/300\n",
      "203/203 [==============================] - 0s 714us/step - loss: 0.0847 - mean_absolute_error: 0.1876 - val_loss: 0.1218 - val_mean_absolute_error: 0.1967\n",
      "Epoch 95/300\n",
      "203/203 [==============================] - 0s 713us/step - loss: 0.0832 - mean_absolute_error: 0.1864 - val_loss: 0.1188 - val_mean_absolute_error: 0.1951\n",
      "Epoch 96/300\n",
      "203/203 [==============================] - 0s 706us/step - loss: 0.0823 - mean_absolute_error: 0.1852 - val_loss: 0.1209 - val_mean_absolute_error: 0.1985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/300\n",
      "203/203 [==============================] - 0s 666us/step - loss: 0.0825 - mean_absolute_error: 0.1855 - val_loss: 0.1204 - val_mean_absolute_error: 0.1958\n",
      "Epoch 98/300\n",
      "203/203 [==============================] - 0s 694us/step - loss: 0.0829 - mean_absolute_error: 0.1858 - val_loss: 0.1183 - val_mean_absolute_error: 0.1950\n",
      "Epoch 99/300\n",
      "203/203 [==============================] - 0s 700us/step - loss: 0.0841 - mean_absolute_error: 0.1868 - val_loss: 0.1198 - val_mean_absolute_error: 0.1956\n",
      "Epoch 100/300\n",
      "203/203 [==============================] - 0s 681us/step - loss: 0.0819 - mean_absolute_error: 0.1854 - val_loss: 0.1272 - val_mean_absolute_error: 0.1973\n",
      "Epoch 101/300\n",
      "203/203 [==============================] - 0s 766us/step - loss: 0.0829 - mean_absolute_error: 0.1860 - val_loss: 0.1232 - val_mean_absolute_error: 0.1986\n",
      "Epoch 102/300\n",
      "203/203 [==============================] - 0s 715us/step - loss: 0.0821 - mean_absolute_error: 0.1860 - val_loss: 0.1257 - val_mean_absolute_error: 0.2000\n",
      "Epoch 103/300\n",
      "203/203 [==============================] - 0s 670us/step - loss: 0.0831 - mean_absolute_error: 0.1860 - val_loss: 0.1392 - val_mean_absolute_error: 0.2040\n",
      "Epoch 104/300\n",
      "203/203 [==============================] - 0s 679us/step - loss: 0.0818 - mean_absolute_error: 0.1842 - val_loss: 0.1296 - val_mean_absolute_error: 0.2016\n",
      "Epoch 105/300\n",
      "203/203 [==============================] - 0s 782us/step - loss: 0.0819 - mean_absolute_error: 0.1850 - val_loss: 0.1457 - val_mean_absolute_error: 0.2033\n",
      "Epoch 106/300\n",
      "203/203 [==============================] - 0s 721us/step - loss: 0.0834 - mean_absolute_error: 0.1860 - val_loss: 0.1209 - val_mean_absolute_error: 0.1972\n",
      "Epoch 107/300\n",
      "203/203 [==============================] - 0s 731us/step - loss: 0.0812 - mean_absolute_error: 0.1843 - val_loss: 0.1204 - val_mean_absolute_error: 0.1991\n",
      "Epoch 108/300\n",
      "203/203 [==============================] - 0s 784us/step - loss: 0.0816 - mean_absolute_error: 0.1844 - val_loss: 0.1293 - val_mean_absolute_error: 0.1983\n",
      "Epoch 109/300\n",
      "203/203 [==============================] - 0s 723us/step - loss: 0.0813 - mean_absolute_error: 0.1849 - val_loss: 0.1143 - val_mean_absolute_error: 0.1945\n",
      "Epoch 110/300\n",
      "203/203 [==============================] - 0s 708us/step - loss: 0.0817 - mean_absolute_error: 0.1843 - val_loss: 0.1243 - val_mean_absolute_error: 0.1955\n",
      "Epoch 111/300\n",
      "203/203 [==============================] - 0s 677us/step - loss: 0.0816 - mean_absolute_error: 0.1854 - val_loss: 0.1203 - val_mean_absolute_error: 0.1947\n",
      "Epoch 112/300\n",
      "203/203 [==============================] - 0s 727us/step - loss: 0.0812 - mean_absolute_error: 0.1851 - val_loss: 0.1176 - val_mean_absolute_error: 0.1936\n",
      "Epoch 113/300\n",
      "203/203 [==============================] - 0s 726us/step - loss: 0.0805 - mean_absolute_error: 0.1844 - val_loss: 0.1346 - val_mean_absolute_error: 0.2009\n",
      "Epoch 114/300\n",
      "203/203 [==============================] - 0s 734us/step - loss: 0.0814 - mean_absolute_error: 0.1848 - val_loss: 0.1242 - val_mean_absolute_error: 0.1996\n",
      "Epoch 115/300\n",
      "203/203 [==============================] - 0s 715us/step - loss: 0.0806 - mean_absolute_error: 0.1843 - val_loss: 0.1179 - val_mean_absolute_error: 0.1944\n",
      "Epoch 116/300\n",
      "203/203 [==============================] - 0s 690us/step - loss: 0.0808 - mean_absolute_error: 0.1845 - val_loss: 0.1255 - val_mean_absolute_error: 0.2003\n",
      "Epoch 117/300\n",
      "203/203 [==============================] - 0s 669us/step - loss: 0.0812 - mean_absolute_error: 0.1854 - val_loss: 0.1185 - val_mean_absolute_error: 0.1932\n",
      "Epoch 118/300\n",
      "203/203 [==============================] - 0s 693us/step - loss: 0.0804 - mean_absolute_error: 0.1835 - val_loss: 0.1239 - val_mean_absolute_error: 0.1975\n",
      "Epoch 119/300\n",
      "203/203 [==============================] - 0s 747us/step - loss: 0.0809 - mean_absolute_error: 0.1846 - val_loss: 0.1262 - val_mean_absolute_error: 0.2014\n",
      "Epoch 120/300\n",
      "203/203 [==============================] - 0s 732us/step - loss: 0.0809 - mean_absolute_error: 0.1850 - val_loss: 0.1221 - val_mean_absolute_error: 0.1975\n",
      "Epoch 121/300\n",
      "203/203 [==============================] - 0s 748us/step - loss: 0.0803 - mean_absolute_error: 0.1835 - val_loss: 0.1256 - val_mean_absolute_error: 0.2006\n",
      "Epoch 122/300\n",
      "203/203 [==============================] - 0s 759us/step - loss: 0.0799 - mean_absolute_error: 0.1836 - val_loss: 0.1351 - val_mean_absolute_error: 0.1974\n",
      "Epoch 123/300\n",
      "203/203 [==============================] - 0s 706us/step - loss: 0.0801 - mean_absolute_error: 0.1832 - val_loss: 0.1254 - val_mean_absolute_error: 0.1985\n",
      "Epoch 124/300\n",
      "203/203 [==============================] - 0s 753us/step - loss: 0.0794 - mean_absolute_error: 0.1832 - val_loss: 0.1314 - val_mean_absolute_error: 0.2005\n",
      "Epoch 125/300\n",
      "203/203 [==============================] - 0s 722us/step - loss: 0.0801 - mean_absolute_error: 0.1839 - val_loss: 0.1238 - val_mean_absolute_error: 0.1952\n",
      "Epoch 126/300\n",
      "203/203 [==============================] - 0s 773us/step - loss: 0.0790 - mean_absolute_error: 0.1832 - val_loss: 0.1368 - val_mean_absolute_error: 0.1999\n",
      "Epoch 127/300\n",
      "203/203 [==============================] - 0s 731us/step - loss: 0.0798 - mean_absolute_error: 0.1841 - val_loss: 0.1272 - val_mean_absolute_error: 0.1980\n",
      "Epoch 128/300\n",
      "203/203 [==============================] - 0s 775us/step - loss: 0.0795 - mean_absolute_error: 0.1839 - val_loss: 0.1200 - val_mean_absolute_error: 0.1938\n",
      "Epoch 129/300\n",
      "203/203 [==============================] - 0s 760us/step - loss: 0.0795 - mean_absolute_error: 0.1826 - val_loss: 0.1229 - val_mean_absolute_error: 0.1960\n",
      "Epoch 130/300\n",
      "203/203 [==============================] - 0s 723us/step - loss: 0.0804 - mean_absolute_error: 0.1835 - val_loss: 0.1321 - val_mean_absolute_error: 0.2043\n",
      "Epoch 131/300\n",
      "203/203 [==============================] - 0s 672us/step - loss: 0.0790 - mean_absolute_error: 0.1837 - val_loss: 0.1323 - val_mean_absolute_error: 0.1970\n",
      "Epoch 132/300\n",
      "203/203 [==============================] - 0s 708us/step - loss: 0.0792 - mean_absolute_error: 0.1833 - val_loss: 0.1231 - val_mean_absolute_error: 0.1965\n",
      "Epoch 133/300\n",
      "203/203 [==============================] - 0s 703us/step - loss: 0.0796 - mean_absolute_error: 0.1835 - val_loss: 0.1208 - val_mean_absolute_error: 0.1943\n",
      "Epoch 134/300\n",
      "203/203 [==============================] - 0s 672us/step - loss: 0.0804 - mean_absolute_error: 0.1842 - val_loss: 0.1234 - val_mean_absolute_error: 0.1965\n",
      "Epoch 135/300\n",
      "203/203 [==============================] - 0s 680us/step - loss: 0.0780 - mean_absolute_error: 0.1821 - val_loss: 0.1226 - val_mean_absolute_error: 0.1989\n",
      "Epoch 136/300\n",
      "203/203 [==============================] - 0s 689us/step - loss: 0.0800 - mean_absolute_error: 0.1839 - val_loss: 0.1290 - val_mean_absolute_error: 0.1987\n",
      "Epoch 137/300\n",
      "203/203 [==============================] - 0s 705us/step - loss: 0.0792 - mean_absolute_error: 0.1828 - val_loss: 0.1305 - val_mean_absolute_error: 0.1979\n",
      "Epoch 138/300\n",
      "203/203 [==============================] - 0s 670us/step - loss: 0.0786 - mean_absolute_error: 0.1830 - val_loss: 0.1305 - val_mean_absolute_error: 0.1972\n",
      "Epoch 139/300\n",
      "203/203 [==============================] - 0s 693us/step - loss: 0.0789 - mean_absolute_error: 0.1821 - val_loss: 0.1265 - val_mean_absolute_error: 0.1970\n",
      "Epoch 140/300\n",
      "203/203 [==============================] - 0s 693us/step - loss: 0.0778 - mean_absolute_error: 0.1824 - val_loss: 0.1226 - val_mean_absolute_error: 0.1970\n",
      "Epoch 141/300\n",
      "203/203 [==============================] - 0s 734us/step - loss: 0.0780 - mean_absolute_error: 0.1818 - val_loss: 0.1332 - val_mean_absolute_error: 0.1993\n",
      "Epoch 142/300\n",
      "203/203 [==============================] - 0s 723us/step - loss: 0.0787 - mean_absolute_error: 0.1831 - val_loss: 0.1201 - val_mean_absolute_error: 0.1939\n",
      "Epoch 143/300\n",
      "203/203 [==============================] - 0s 745us/step - loss: 0.0771 - mean_absolute_error: 0.1819 - val_loss: 0.1518 - val_mean_absolute_error: 0.2033\n",
      "Epoch 144/300\n",
      "203/203 [==============================] - 0s 721us/step - loss: 0.0795 - mean_absolute_error: 0.1834 - val_loss: 0.1298 - val_mean_absolute_error: 0.2009\n",
      "Epoch 145/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 0s 680us/step - loss: 0.0771 - mean_absolute_error: 0.1823 - val_loss: 0.1239 - val_mean_absolute_error: 0.1929\n",
      "Epoch 146/300\n",
      "203/203 [==============================] - 0s 699us/step - loss: 0.0786 - mean_absolute_error: 0.1825 - val_loss: 0.1282 - val_mean_absolute_error: 0.1974\n",
      "Epoch 147/300\n",
      "203/203 [==============================] - 0s 683us/step - loss: 0.0782 - mean_absolute_error: 0.1821 - val_loss: 0.1182 - val_mean_absolute_error: 0.1925\n",
      "Epoch 148/300\n",
      "203/203 [==============================] - 0s 706us/step - loss: 0.0791 - mean_absolute_error: 0.1834 - val_loss: 0.1248 - val_mean_absolute_error: 0.1973\n",
      "Epoch 149/300\n",
      "203/203 [==============================] - 0s 705us/step - loss: 0.0773 - mean_absolute_error: 0.1821 - val_loss: 0.1191 - val_mean_absolute_error: 0.1931\n",
      "Epoch 150/300\n",
      "203/203 [==============================] - 0s 695us/step - loss: 0.0772 - mean_absolute_error: 0.1813 - val_loss: 0.1203 - val_mean_absolute_error: 0.1930\n",
      "Epoch 151/300\n",
      "203/203 [==============================] - 0s 786us/step - loss: 0.0764 - mean_absolute_error: 0.1812 - val_loss: 0.1165 - val_mean_absolute_error: 0.1932\n",
      "Epoch 152/300\n",
      "203/203 [==============================] - 0s 749us/step - loss: 0.0772 - mean_absolute_error: 0.1826 - val_loss: 0.1324 - val_mean_absolute_error: 0.1963\n",
      "Epoch 153/300\n",
      "203/203 [==============================] - 0s 769us/step - loss: 0.0775 - mean_absolute_error: 0.1811 - val_loss: 0.1294 - val_mean_absolute_error: 0.1957\n",
      "Epoch 154/300\n",
      "203/203 [==============================] - 0s 780us/step - loss: 0.0766 - mean_absolute_error: 0.1821 - val_loss: 0.1164 - val_mean_absolute_error: 0.1917\n",
      "Epoch 155/300\n",
      "203/203 [==============================] - 0s 704us/step - loss: 0.0769 - mean_absolute_error: 0.1816 - val_loss: 0.1205 - val_mean_absolute_error: 0.1926\n",
      "Epoch 156/300\n",
      "203/203 [==============================] - 0s 728us/step - loss: 0.0762 - mean_absolute_error: 0.1814 - val_loss: 0.1287 - val_mean_absolute_error: 0.1990\n",
      "Epoch 157/300\n",
      "203/203 [==============================] - 0s 698us/step - loss: 0.0765 - mean_absolute_error: 0.1816 - val_loss: 0.1175 - val_mean_absolute_error: 0.1972\n",
      "Epoch 158/300\n",
      "203/203 [==============================] - 0s 665us/step - loss: 0.0776 - mean_absolute_error: 0.1823 - val_loss: 0.1218 - val_mean_absolute_error: 0.1933\n",
      "Epoch 159/300\n",
      "203/203 [==============================] - 0s 717us/step - loss: 0.0764 - mean_absolute_error: 0.1806 - val_loss: 0.1289 - val_mean_absolute_error: 0.1954\n",
      "Epoch 160/300\n",
      "203/203 [==============================] - 0s 757us/step - loss: 0.0772 - mean_absolute_error: 0.1814 - val_loss: 0.1304 - val_mean_absolute_error: 0.2014\n",
      "Epoch 161/300\n",
      "203/203 [==============================] - 0s 716us/step - loss: 0.0760 - mean_absolute_error: 0.1812 - val_loss: 0.1245 - val_mean_absolute_error: 0.1949\n",
      "Epoch 162/300\n",
      "203/203 [==============================] - 0s 691us/step - loss: 0.0763 - mean_absolute_error: 0.1809 - val_loss: 0.1177 - val_mean_absolute_error: 0.1921\n",
      "Epoch 163/300\n",
      "203/203 [==============================] - 0s 677us/step - loss: 0.0766 - mean_absolute_error: 0.1814 - val_loss: 0.1214 - val_mean_absolute_error: 0.1926\n",
      "Epoch 164/300\n",
      "203/203 [==============================] - 0s 748us/step - loss: 0.0761 - mean_absolute_error: 0.1810 - val_loss: 0.1261 - val_mean_absolute_error: 0.1944\n",
      "Epoch 165/300\n",
      "203/203 [==============================] - ETA: 0s - loss: 0.0769 - mean_absolute_error: 0.182 - 0s 716us/step - loss: 0.0768 - mean_absolute_error: 0.1819 - val_loss: 0.1234 - val_mean_absolute_error: 0.1958\n",
      "Epoch 166/300\n",
      "203/203 [==============================] - 0s 705us/step - loss: 0.0770 - mean_absolute_error: 0.1819 - val_loss: 0.1275 - val_mean_absolute_error: 0.2016\n",
      "Epoch 167/300\n",
      "203/203 [==============================] - 0s 762us/step - loss: 0.0806 - mean_absolute_error: 0.1836 - val_loss: 0.1204 - val_mean_absolute_error: 0.1924\n",
      "Epoch 168/300\n",
      "203/203 [==============================] - 0s 693us/step - loss: 0.0751 - mean_absolute_error: 0.1801 - val_loss: 0.1247 - val_mean_absolute_error: 0.1943\n",
      "Epoch 169/300\n",
      "203/203 [==============================] - 0s 766us/step - loss: 0.0760 - mean_absolute_error: 0.1813 - val_loss: 0.1246 - val_mean_absolute_error: 0.1944\n",
      "Epoch 170/300\n",
      "203/203 [==============================] - 0s 739us/step - loss: 0.0757 - mean_absolute_error: 0.1799 - val_loss: 0.1378 - val_mean_absolute_error: 0.2021\n",
      "Epoch 171/300\n",
      "203/203 [==============================] - 0s 764us/step - loss: 0.0765 - mean_absolute_error: 0.1809 - val_loss: 0.1221 - val_mean_absolute_error: 0.1928\n",
      "Epoch 172/300\n",
      "203/203 [==============================] - 0s 756us/step - loss: 0.0758 - mean_absolute_error: 0.1809 - val_loss: 0.1267 - val_mean_absolute_error: 0.1963\n",
      "Epoch 173/300\n",
      "203/203 [==============================] - 0s 777us/step - loss: 0.0759 - mean_absolute_error: 0.1802 - val_loss: 0.1209 - val_mean_absolute_error: 0.1950\n",
      "Epoch 174/300\n",
      "203/203 [==============================] - 0s 666us/step - loss: 0.0753 - mean_absolute_error: 0.1799 - val_loss: 0.1267 - val_mean_absolute_error: 0.1950\n",
      "Epoch 175/300\n",
      "203/203 [==============================] - 0s 684us/step - loss: 0.0754 - mean_absolute_error: 0.1807 - val_loss: 0.1245 - val_mean_absolute_error: 0.1959\n",
      "Epoch 176/300\n",
      "203/203 [==============================] - 0s 693us/step - loss: 0.0752 - mean_absolute_error: 0.1803 - val_loss: 0.1336 - val_mean_absolute_error: 0.1969\n",
      "Epoch 177/300\n",
      "203/203 [==============================] - 0s 716us/step - loss: 0.0755 - mean_absolute_error: 0.1800 - val_loss: 0.1241 - val_mean_absolute_error: 0.1942\n",
      "Epoch 178/300\n",
      "203/203 [==============================] - 0s 701us/step - loss: 0.0759 - mean_absolute_error: 0.1812 - val_loss: 0.1258 - val_mean_absolute_error: 0.1963\n",
      "Epoch 179/300\n",
      "203/203 [==============================] - 0s 668us/step - loss: 0.0750 - mean_absolute_error: 0.1801 - val_loss: 0.1268 - val_mean_absolute_error: 0.1927\n",
      "Epoch 180/300\n",
      "203/203 [==============================] - 0s 711us/step - loss: 0.0755 - mean_absolute_error: 0.1811 - val_loss: 0.1252 - val_mean_absolute_error: 0.1939\n",
      "Epoch 181/300\n",
      "203/203 [==============================] - 0s 675us/step - loss: 0.0753 - mean_absolute_error: 0.1797 - val_loss: 0.1328 - val_mean_absolute_error: 0.1948\n",
      "Epoch 182/300\n",
      "203/203 [==============================] - 0s 691us/step - loss: 0.0753 - mean_absolute_error: 0.1802 - val_loss: 0.1322 - val_mean_absolute_error: 0.1971\n",
      "Epoch 183/300\n",
      "203/203 [==============================] - 0s 725us/step - loss: 0.0743 - mean_absolute_error: 0.1794 - val_loss: 0.1230 - val_mean_absolute_error: 0.1930\n",
      "Epoch 184/300\n",
      "203/203 [==============================] - 0s 740us/step - loss: 0.0752 - mean_absolute_error: 0.1800 - val_loss: 0.1358 - val_mean_absolute_error: 0.1991\n",
      "Epoch 185/300\n",
      "203/203 [==============================] - 0s 705us/step - loss: 0.0747 - mean_absolute_error: 0.1799 - val_loss: 0.1279 - val_mean_absolute_error: 0.1972\n",
      "Epoch 186/300\n",
      "203/203 [==============================] - 0s 667us/step - loss: 0.0752 - mean_absolute_error: 0.1798 - val_loss: 0.1243 - val_mean_absolute_error: 0.1941\n",
      "Epoch 187/300\n",
      "203/203 [==============================] - 0s 693us/step - loss: 0.0744 - mean_absolute_error: 0.1785 - val_loss: 0.1309 - val_mean_absolute_error: 0.1968\n",
      "Epoch 188/300\n",
      "203/203 [==============================] - 0s 816us/step - loss: 0.0754 - mean_absolute_error: 0.1801 - val_loss: 0.1340 - val_mean_absolute_error: 0.1959\n",
      "Epoch 189/300\n",
      "203/203 [==============================] - 0s 706us/step - loss: 0.0754 - mean_absolute_error: 0.1805 - val_loss: 0.1390 - val_mean_absolute_error: 0.1998\n",
      "Epoch 190/300\n",
      "203/203 [==============================] - 0s 688us/step - loss: 0.0747 - mean_absolute_error: 0.1796 - val_loss: 0.1204 - val_mean_absolute_error: 0.1939\n",
      "Epoch 191/300\n",
      "203/203 [==============================] - 0s 704us/step - loss: 0.0750 - mean_absolute_error: 0.1798 - val_loss: 0.1309 - val_mean_absolute_error: 0.1957\n",
      "Epoch 192/300\n",
      "203/203 [==============================] - 0s 675us/step - loss: 0.0745 - mean_absolute_error: 0.1790 - val_loss: 0.1237 - val_mean_absolute_error: 0.1934\n",
      "Epoch 193/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 0s 668us/step - loss: 0.0752 - mean_absolute_error: 0.1808 - val_loss: 0.1198 - val_mean_absolute_error: 0.1925\n",
      "Epoch 194/300\n",
      "203/203 [==============================] - 0s 751us/step - loss: 0.0745 - mean_absolute_error: 0.1797 - val_loss: 0.1308 - val_mean_absolute_error: 0.1956\n",
      "Epoch 195/300\n",
      "203/203 [==============================] - 0s 725us/step - loss: 0.0750 - mean_absolute_error: 0.1801 - val_loss: 0.1273 - val_mean_absolute_error: 0.1943\n",
      "Epoch 196/300\n",
      "203/203 [==============================] - 0s 665us/step - loss: 0.0743 - mean_absolute_error: 0.1789 - val_loss: 0.1250 - val_mean_absolute_error: 0.1948\n",
      "Epoch 197/300\n",
      "203/203 [==============================] - 0s 751us/step - loss: 0.0747 - mean_absolute_error: 0.1800 - val_loss: 0.1268 - val_mean_absolute_error: 0.1956\n",
      "Epoch 198/300\n",
      "203/203 [==============================] - 0s 693us/step - loss: 0.0749 - mean_absolute_error: 0.1797 - val_loss: 0.1264 - val_mean_absolute_error: 0.1933\n",
      "Epoch 199/300\n",
      "203/203 [==============================] - 0s 670us/step - loss: 0.0733 - mean_absolute_error: 0.1779 - val_loss: 0.1286 - val_mean_absolute_error: 0.1941\n",
      "Epoch 200/300\n",
      "203/203 [==============================] - 0s 673us/step - loss: 0.0744 - mean_absolute_error: 0.1791 - val_loss: 0.1284 - val_mean_absolute_error: 0.1955\n",
      "Epoch 201/300\n",
      "203/203 [==============================] - 0s 666us/step - loss: 0.0741 - mean_absolute_error: 0.1788 - val_loss: 0.1323 - val_mean_absolute_error: 0.1983\n",
      "Epoch 202/300\n",
      "203/203 [==============================] - 0s 713us/step - loss: 0.0740 - mean_absolute_error: 0.1796 - val_loss: 0.1296 - val_mean_absolute_error: 0.1954\n",
      "Epoch 203/300\n",
      "203/203 [==============================] - 0s 753us/step - loss: 0.0746 - mean_absolute_error: 0.1792 - val_loss: 0.1348 - val_mean_absolute_error: 0.1967\n",
      "Epoch 204/300\n",
      "203/203 [==============================] - 0s 728us/step - loss: 0.0736 - mean_absolute_error: 0.1780 - val_loss: 0.1264 - val_mean_absolute_error: 0.1932\n",
      "Epoch 205/300\n",
      "203/203 [==============================] - 0s 767us/step - loss: 0.0738 - mean_absolute_error: 0.1780 - val_loss: 0.1245 - val_mean_absolute_error: 0.1923\n",
      "Epoch 206/300\n",
      "203/203 [==============================] - 0s 670us/step - loss: 0.0744 - mean_absolute_error: 0.1788 - val_loss: 0.1324 - val_mean_absolute_error: 0.1973\n",
      "Epoch 207/300\n",
      "203/203 [==============================] - 0s 701us/step - loss: 0.0749 - mean_absolute_error: 0.1797 - val_loss: 0.1292 - val_mean_absolute_error: 0.1996\n",
      "Epoch 208/300\n",
      "203/203 [==============================] - 0s 697us/step - loss: 0.0738 - mean_absolute_error: 0.1789 - val_loss: 0.1277 - val_mean_absolute_error: 0.1941\n",
      "Epoch 209/300\n",
      "203/203 [==============================] - 0s 730us/step - loss: 0.0735 - mean_absolute_error: 0.1784 - val_loss: 0.1235 - val_mean_absolute_error: 0.1961\n",
      "Epoch 210/300\n",
      "203/203 [==============================] - 0s 689us/step - loss: 0.0745 - mean_absolute_error: 0.1792 - val_loss: 0.1397 - val_mean_absolute_error: 0.1975\n",
      "Epoch 211/300\n",
      "203/203 [==============================] - 0s 815us/step - loss: 0.0747 - mean_absolute_error: 0.1793 - val_loss: 0.1400 - val_mean_absolute_error: 0.1997\n",
      "Epoch 212/300\n",
      "203/203 [==============================] - 0s 698us/step - loss: 0.0741 - mean_absolute_error: 0.1790 - val_loss: 0.1255 - val_mean_absolute_error: 0.1940\n",
      "Epoch 213/300\n",
      "203/203 [==============================] - 0s 673us/step - loss: 0.0742 - mean_absolute_error: 0.1795 - val_loss: 0.1232 - val_mean_absolute_error: 0.1935\n",
      "Epoch 214/300\n",
      "203/203 [==============================] - 0s 722us/step - loss: 0.0743 - mean_absolute_error: 0.1789 - val_loss: 0.1373 - val_mean_absolute_error: 0.1998\n",
      "Epoch 215/300\n",
      "203/203 [==============================] - 0s 741us/step - loss: 0.0737 - mean_absolute_error: 0.1783 - val_loss: 0.1383 - val_mean_absolute_error: 0.1987\n",
      "Epoch 216/300\n",
      "203/203 [==============================] - 0s 798us/step - loss: 0.0734 - mean_absolute_error: 0.1784 - val_loss: 0.1235 - val_mean_absolute_error: 0.1936\n",
      "Epoch 217/300\n",
      "203/203 [==============================] - 0s 670us/step - loss: 0.0741 - mean_absolute_error: 0.1781 - val_loss: 0.1322 - val_mean_absolute_error: 0.1954\n",
      "Epoch 218/300\n",
      "203/203 [==============================] - 0s 708us/step - loss: 0.0740 - mean_absolute_error: 0.1792 - val_loss: 0.1351 - val_mean_absolute_error: 0.1961\n",
      "Epoch 219/300\n",
      "203/203 [==============================] - 0s 670us/step - loss: 0.0741 - mean_absolute_error: 0.1794 - val_loss: 0.1346 - val_mean_absolute_error: 0.1947\n",
      "Epoch 220/300\n",
      "203/203 [==============================] - 0s 811us/step - loss: 0.0729 - mean_absolute_error: 0.1773 - val_loss: 0.1263 - val_mean_absolute_error: 0.1938\n",
      "Epoch 221/300\n",
      "203/203 [==============================] - 0s 723us/step - loss: 0.0734 - mean_absolute_error: 0.1785 - val_loss: 0.1261 - val_mean_absolute_error: 0.1933\n",
      "Epoch 222/300\n",
      "203/203 [==============================] - 0s 749us/step - loss: 0.0729 - mean_absolute_error: 0.1775 - val_loss: 0.1277 - val_mean_absolute_error: 0.1976\n",
      "Epoch 223/300\n",
      "203/203 [==============================] - 0s 720us/step - loss: 0.0741 - mean_absolute_error: 0.1784 - val_loss: 0.1422 - val_mean_absolute_error: 0.2012\n",
      "Epoch 224/300\n",
      "203/203 [==============================] - 0s 680us/step - loss: 0.0734 - mean_absolute_error: 0.1790 - val_loss: 0.1295 - val_mean_absolute_error: 0.1953\n",
      "Epoch 225/300\n",
      "203/203 [==============================] - 0s 689us/step - loss: 0.0722 - mean_absolute_error: 0.1773 - val_loss: 0.1538 - val_mean_absolute_error: 0.2016\n",
      "Epoch 226/300\n",
      "203/203 [==============================] - 0s 712us/step - loss: 0.0739 - mean_absolute_error: 0.1785 - val_loss: 0.1368 - val_mean_absolute_error: 0.1976\n",
      "Epoch 227/300\n",
      "203/203 [==============================] - 0s 723us/step - loss: 0.0728 - mean_absolute_error: 0.1780 - val_loss: 0.1367 - val_mean_absolute_error: 0.1987\n",
      "Epoch 228/300\n",
      "203/203 [==============================] - 0s 710us/step - loss: 0.0746 - mean_absolute_error: 0.1796 - val_loss: 0.1316 - val_mean_absolute_error: 0.1987\n",
      "Epoch 229/300\n",
      "203/203 [==============================] - 0s 685us/step - loss: 0.0740 - mean_absolute_error: 0.1792 - val_loss: 0.1303 - val_mean_absolute_error: 0.2022\n",
      "Epoch 230/300\n",
      "203/203 [==============================] - 0s 686us/step - loss: 0.0731 - mean_absolute_error: 0.1773 - val_loss: 0.1373 - val_mean_absolute_error: 0.1971\n",
      "Epoch 231/300\n",
      "203/203 [==============================] - 0s 690us/step - loss: 0.0739 - mean_absolute_error: 0.1783 - val_loss: 0.1245 - val_mean_absolute_error: 0.1938\n",
      "Epoch 232/300\n",
      "203/203 [==============================] - 0s 671us/step - loss: 0.0731 - mean_absolute_error: 0.1777 - val_loss: 0.1291 - val_mean_absolute_error: 0.1945\n",
      "Epoch 233/300\n",
      "203/203 [==============================] - 0s 688us/step - loss: 0.0741 - mean_absolute_error: 0.1795 - val_loss: 0.1278 - val_mean_absolute_error: 0.1942\n",
      "Epoch 234/300\n",
      "203/203 [==============================] - 0s 667us/step - loss: 0.0741 - mean_absolute_error: 0.1778 - val_loss: 0.1273 - val_mean_absolute_error: 0.1945\n",
      "Epoch 235/300\n",
      "203/203 [==============================] - 0s 670us/step - loss: 0.0730 - mean_absolute_error: 0.1781 - val_loss: 0.1380 - val_mean_absolute_error: 0.1981\n",
      "Epoch 236/300\n",
      "203/203 [==============================] - 0s 697us/step - loss: 0.0721 - mean_absolute_error: 0.1768 - val_loss: 0.1314 - val_mean_absolute_error: 0.1950\n",
      "Epoch 237/300\n",
      "203/203 [==============================] - 0s 667us/step - loss: 0.0728 - mean_absolute_error: 0.1778 - val_loss: 0.1294 - val_mean_absolute_error: 0.1934\n",
      "Epoch 238/300\n",
      "203/203 [==============================] - 0s 717us/step - loss: 0.0724 - mean_absolute_error: 0.1765 - val_loss: 0.1364 - val_mean_absolute_error: 0.1968\n",
      "Epoch 239/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.0734 - mean_absolute_error: 0.1785 - val_loss: 0.1490 - val_mean_absolute_error: 0.1982\n",
      "Epoch 240/300\n",
      "203/203 [==============================] - 0s 682us/step - loss: 0.0730 - mean_absolute_error: 0.1780 - val_loss: 0.1322 - val_mean_absolute_error: 0.1965\n",
      "Epoch 241/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 0s 701us/step - loss: 0.0732 - mean_absolute_error: 0.1783 - val_loss: 0.1376 - val_mean_absolute_error: 0.1982\n",
      "Epoch 242/300\n",
      "203/203 [==============================] - 0s 854us/step - loss: 0.0733 - mean_absolute_error: 0.1781 - val_loss: 0.1284 - val_mean_absolute_error: 0.1943\n",
      "Epoch 243/300\n",
      "203/203 [==============================] - 0s 727us/step - loss: 0.0730 - mean_absolute_error: 0.1780 - val_loss: 0.1283 - val_mean_absolute_error: 0.1949\n",
      "Epoch 244/300\n",
      "203/203 [==============================] - 0s 792us/step - loss: 0.0723 - mean_absolute_error: 0.1775 - val_loss: 0.1373 - val_mean_absolute_error: 0.2000\n",
      "Epoch 245/300\n",
      "203/203 [==============================] - 0s 680us/step - loss: 0.0729 - mean_absolute_error: 0.1777 - val_loss: 0.1281 - val_mean_absolute_error: 0.1943\n",
      "Epoch 246/300\n",
      "203/203 [==============================] - 0s 672us/step - loss: 0.0722 - mean_absolute_error: 0.1772 - val_loss: 0.1352 - val_mean_absolute_error: 0.1953\n",
      "Epoch 247/300\n",
      "203/203 [==============================] - 0s 715us/step - loss: 0.0723 - mean_absolute_error: 0.1774 - val_loss: 0.1270 - val_mean_absolute_error: 0.1943\n",
      "Epoch 248/300\n",
      "203/203 [==============================] - 0s 771us/step - loss: 0.0728 - mean_absolute_error: 0.1777 - val_loss: 0.1416 - val_mean_absolute_error: 0.1968\n",
      "Epoch 249/300\n",
      "203/203 [==============================] - 0s 721us/step - loss: 0.0728 - mean_absolute_error: 0.1776 - val_loss: 0.1259 - val_mean_absolute_error: 0.1955\n",
      "Epoch 250/300\n",
      "203/203 [==============================] - 0s 747us/step - loss: 0.0724 - mean_absolute_error: 0.1778 - val_loss: 0.1282 - val_mean_absolute_error: 0.1940\n",
      "Epoch 251/300\n",
      "203/203 [==============================] - 0s 784us/step - loss: 0.0727 - mean_absolute_error: 0.1769 - val_loss: 0.1331 - val_mean_absolute_error: 0.1998\n",
      "Epoch 252/300\n",
      "203/203 [==============================] - 0s 784us/step - loss: 0.0721 - mean_absolute_error: 0.1775 - val_loss: 0.1346 - val_mean_absolute_error: 0.1946\n",
      "Epoch 253/300\n",
      "203/203 [==============================] - 0s 737us/step - loss: 0.0731 - mean_absolute_error: 0.1782 - val_loss: 0.1328 - val_mean_absolute_error: 0.1954\n",
      "Epoch 254/300\n",
      "203/203 [==============================] - 0s 788us/step - loss: 0.0735 - mean_absolute_error: 0.1784 - val_loss: 0.1257 - val_mean_absolute_error: 0.1930\n",
      "Epoch 255/300\n",
      "203/203 [==============================] - 0s 691us/step - loss: 0.0723 - mean_absolute_error: 0.1777 - val_loss: 0.1245 - val_mean_absolute_error: 0.1944\n",
      "Epoch 256/300\n",
      "203/203 [==============================] - 0s 702us/step - loss: 0.0725 - mean_absolute_error: 0.1775 - val_loss: 0.1317 - val_mean_absolute_error: 0.1937\n",
      "Epoch 257/300\n",
      "203/203 [==============================] - 0s 835us/step - loss: 0.0738 - mean_absolute_error: 0.1783 - val_loss: 0.1247 - val_mean_absolute_error: 0.1944\n",
      "Epoch 258/300\n",
      "203/203 [==============================] - 0s 786us/step - loss: 0.0732 - mean_absolute_error: 0.1779 - val_loss: 0.1226 - val_mean_absolute_error: 0.1942\n",
      "Epoch 259/300\n",
      "203/203 [==============================] - 0s 658us/step - loss: 0.0723 - mean_absolute_error: 0.1775 - val_loss: 0.1385 - val_mean_absolute_error: 0.1970\n",
      "Epoch 260/300\n",
      "203/203 [==============================] - 0s 679us/step - loss: 0.0722 - mean_absolute_error: 0.1768 - val_loss: 0.1364 - val_mean_absolute_error: 0.1956\n",
      "Epoch 261/300\n",
      "203/203 [==============================] - 0s 767us/step - loss: 0.0724 - mean_absolute_error: 0.1773 - val_loss: 0.1286 - val_mean_absolute_error: 0.1950\n",
      "Epoch 262/300\n",
      "203/203 [==============================] - 0s 779us/step - loss: 0.0725 - mean_absolute_error: 0.1772 - val_loss: 0.1332 - val_mean_absolute_error: 0.1955\n",
      "Epoch 263/300\n",
      "203/203 [==============================] - 0s 750us/step - loss: 0.0732 - mean_absolute_error: 0.1790 - val_loss: 0.1371 - val_mean_absolute_error: 0.1954\n",
      "Epoch 264/300\n",
      "203/203 [==============================] - 0s 739us/step - loss: 0.0714 - mean_absolute_error: 0.1771 - val_loss: 0.1378 - val_mean_absolute_error: 0.1948\n",
      "Epoch 265/300\n",
      "203/203 [==============================] - 0s 691us/step - loss: 0.0721 - mean_absolute_error: 0.1767 - val_loss: 0.1340 - val_mean_absolute_error: 0.1945\n",
      "Epoch 266/300\n",
      "203/203 [==============================] - 0s 670us/step - loss: 0.0731 - mean_absolute_error: 0.1779 - val_loss: 0.1288 - val_mean_absolute_error: 0.1982\n",
      "Epoch 267/300\n",
      "203/203 [==============================] - 0s 665us/step - loss: 0.0725 - mean_absolute_error: 0.1774 - val_loss: 0.1345 - val_mean_absolute_error: 0.1942\n",
      "Epoch 268/300\n",
      "203/203 [==============================] - 0s 665us/step - loss: 0.0721 - mean_absolute_error: 0.1772 - val_loss: 0.1337 - val_mean_absolute_error: 0.1947\n",
      "Epoch 269/300\n",
      "203/203 [==============================] - 0s 673us/step - loss: 0.0712 - mean_absolute_error: 0.1761 - val_loss: 0.1279 - val_mean_absolute_error: 0.1929\n",
      "Epoch 270/300\n",
      "203/203 [==============================] - 0s 681us/step - loss: 0.0720 - mean_absolute_error: 0.1770 - val_loss: 0.1303 - val_mean_absolute_error: 0.1934\n",
      "Epoch 271/300\n",
      "203/203 [==============================] - 0s 701us/step - loss: 0.0725 - mean_absolute_error: 0.1772 - val_loss: 0.1385 - val_mean_absolute_error: 0.1961\n",
      "Epoch 272/300\n",
      "203/203 [==============================] - 0s 862us/step - loss: 0.0720 - mean_absolute_error: 0.1764 - val_loss: 0.1357 - val_mean_absolute_error: 0.1938\n",
      "Epoch 273/300\n",
      "203/203 [==============================] - 0s 752us/step - loss: 0.0715 - mean_absolute_error: 0.1762 - val_loss: 0.1425 - val_mean_absolute_error: 0.2004\n",
      "Epoch 274/300\n",
      "203/203 [==============================] - 0s 686us/step - loss: 0.0723 - mean_absolute_error: 0.1767 - val_loss: 0.1326 - val_mean_absolute_error: 0.1993\n",
      "Epoch 275/300\n",
      "203/203 [==============================] - 0s 683us/step - loss: 0.0720 - mean_absolute_error: 0.1772 - val_loss: 0.1355 - val_mean_absolute_error: 0.1945\n",
      "Epoch 276/300\n",
      "203/203 [==============================] - 0s 775us/step - loss: 0.0720 - mean_absolute_error: 0.1771 - val_loss: 0.1415 - val_mean_absolute_error: 0.1953\n",
      "Epoch 277/300\n",
      "203/203 [==============================] - 0s 742us/step - loss: 0.0722 - mean_absolute_error: 0.1771 - val_loss: 0.1305 - val_mean_absolute_error: 0.1937\n",
      "Epoch 278/300\n",
      "203/203 [==============================] - 0s 785us/step - loss: 0.0724 - mean_absolute_error: 0.1775 - val_loss: 0.1253 - val_mean_absolute_error: 0.1923\n",
      "Epoch 279/300\n",
      "203/203 [==============================] - 0s 709us/step - loss: 0.0716 - mean_absolute_error: 0.1762 - val_loss: 0.1427 - val_mean_absolute_error: 0.1974\n",
      "Epoch 280/300\n",
      "203/203 [==============================] - 0s 688us/step - loss: 0.0728 - mean_absolute_error: 0.1775 - val_loss: 0.1292 - val_mean_absolute_error: 0.1937\n",
      "Epoch 281/300\n",
      "203/203 [==============================] - 0s 661us/step - loss: 0.0711 - mean_absolute_error: 0.1759 - val_loss: 0.1331 - val_mean_absolute_error: 0.1940\n",
      "Epoch 282/300\n",
      "203/203 [==============================] - 0s 676us/step - loss: 0.0712 - mean_absolute_error: 0.1765 - val_loss: 0.1313 - val_mean_absolute_error: 0.1932\n",
      "Epoch 283/300\n",
      "203/203 [==============================] - 0s 736us/step - loss: 0.0727 - mean_absolute_error: 0.1781 - val_loss: 0.1337 - val_mean_absolute_error: 0.1960\n",
      "Epoch 284/300\n",
      "203/203 [==============================] - 0s 673us/step - loss: 0.0731 - mean_absolute_error: 0.1776 - val_loss: 0.1428 - val_mean_absolute_error: 0.1990\n",
      "Epoch 285/300\n",
      "203/203 [==============================] - 0s 667us/step - loss: 0.0719 - mean_absolute_error: 0.1774 - val_loss: 0.1241 - val_mean_absolute_error: 0.1930\n",
      "Epoch 286/300\n",
      "203/203 [==============================] - 0s 722us/step - loss: 0.0725 - mean_absolute_error: 0.1774 - val_loss: 0.1372 - val_mean_absolute_error: 0.1957\n",
      "Epoch 287/300\n",
      "203/203 [==============================] - 0s 669us/step - loss: 0.0724 - mean_absolute_error: 0.1768 - val_loss: 0.1297 - val_mean_absolute_error: 0.1938\n",
      "Epoch 288/300\n",
      "203/203 [==============================] - 0s 676us/step - loss: 0.0725 - mean_absolute_error: 0.1771 - val_loss: 0.1326 - val_mean_absolute_error: 0.1945\n",
      "Epoch 289/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 0s 670us/step - loss: 0.0727 - mean_absolute_error: 0.1771 - val_loss: 0.1300 - val_mean_absolute_error: 0.1930\n",
      "Epoch 290/300\n",
      "203/203 [==============================] - 0s 669us/step - loss: 0.0717 - mean_absolute_error: 0.1765 - val_loss: 0.1472 - val_mean_absolute_error: 0.1966\n",
      "Epoch 291/300\n",
      "203/203 [==============================] - 0s 725us/step - loss: 0.0719 - mean_absolute_error: 0.1763 - val_loss: 0.1279 - val_mean_absolute_error: 0.1914\n",
      "Epoch 292/300\n",
      "203/203 [==============================] - 0s 674us/step - loss: 0.0711 - mean_absolute_error: 0.1760 - val_loss: 0.1352 - val_mean_absolute_error: 0.1946\n",
      "Epoch 293/300\n",
      "203/203 [==============================] - 0s 741us/step - loss: 0.0718 - mean_absolute_error: 0.1763 - val_loss: 0.1428 - val_mean_absolute_error: 0.1959\n",
      "Epoch 294/300\n",
      "203/203 [==============================] - 0s 668us/step - loss: 0.0711 - mean_absolute_error: 0.1762 - val_loss: 0.1376 - val_mean_absolute_error: 0.1943\n",
      "Epoch 295/300\n",
      "203/203 [==============================] - 0s 669us/step - loss: 0.0717 - mean_absolute_error: 0.1762 - val_loss: 0.1403 - val_mean_absolute_error: 0.1967\n",
      "Epoch 296/300\n",
      "203/203 [==============================] - 0s 661us/step - loss: 0.0716 - mean_absolute_error: 0.1768 - val_loss: 0.1459 - val_mean_absolute_error: 0.1979\n",
      "Epoch 297/300\n",
      "203/203 [==============================] - 0s 678us/step - loss: 0.0724 - mean_absolute_error: 0.1775 - val_loss: 0.1370 - val_mean_absolute_error: 0.1942\n",
      "Epoch 298/300\n",
      "203/203 [==============================] - 0s 756us/step - loss: 0.0712 - mean_absolute_error: 0.1758 - val_loss: 0.1330 - val_mean_absolute_error: 0.1934\n",
      "Epoch 299/300\n",
      "203/203 [==============================] - 0s 660us/step - loss: 0.0714 - mean_absolute_error: 0.1770 - val_loss: 0.1441 - val_mean_absolute_error: 0.1998\n",
      "Epoch 300/300\n",
      "203/203 [==============================] - 0s 663us/step - loss: 0.0726 - mean_absolute_error: 0.1780 - val_loss: 0.1355 - val_mean_absolute_error: 0.1954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f4953f9d88>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2 = keras.Sequential(name='model-2')\n",
    "model_2.add(layers.Dense(16, activation='relu', input_shape=(21,)))\n",
    "model_2.add(layers.Dense(16, activation='relu'))\n",
    "model_2.add(layers.Dense(1))\n",
    "\n",
    "model_2.compile(keras.optimizers.Adam(0.001),\n",
    "                loss=keras.losses.MeanSquaredError(),\n",
    "                metrics=[keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "log_dir = os.path.join('lab2-logs', 'model-2')\n",
    "model_cbk = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "model_mckp = keras.callbacks.ModelCheckpoint(model_dir + '/Best-model-2.h5', \n",
    "                                             monitor='val_mean_absolute_error', \n",
    "                                             save_best_only=True, \n",
    "                                             mode='min')\n",
    "model_2.fit(x_train, y_train, \n",
    "            batch_size=64 ,\n",
    "            epochs=300, \n",
    "            validation_data=(x_val, y_val), \n",
    "            callbacks=[model_cbk, model_mckp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加入L1或L2 正則化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "  2/203 [..............................] - ETA: 36s - loss: 0.9490 - mean_absolute_error: 0.7139WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.3662s). Check your callbacks.\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.4342 - mean_absolute_error: 0.3552 - val_loss: 0.2977 - val_mean_absolute_error: 0.2860\n",
      "Epoch 2/300\n",
      "203/203 [==============================] - 0s 795us/step - loss: 0.2996 - mean_absolute_error: 0.2851 - val_loss: 0.2654 - val_mean_absolute_error: 0.2685\n",
      "Epoch 3/300\n",
      "203/203 [==============================] - 0s 809us/step - loss: 0.2621 - mean_absolute_error: 0.2663 - val_loss: 0.2481 - val_mean_absolute_error: 0.2509\n",
      "Epoch 4/300\n",
      "203/203 [==============================] - 0s 852us/step - loss: 0.2377 - mean_absolute_error: 0.2526 - val_loss: 0.2296 - val_mean_absolute_error: 0.2417\n",
      "Epoch 5/300\n",
      "203/203 [==============================] - 0s 799us/step - loss: 0.2260 - mean_absolute_error: 0.2445 - val_loss: 0.2250 - val_mean_absolute_error: 0.2366\n",
      "Epoch 6/300\n",
      "203/203 [==============================] - 0s 797us/step - loss: 0.2105 - mean_absolute_error: 0.2339 - val_loss: 0.2072 - val_mean_absolute_error: 0.2301\n",
      "Epoch 7/300\n",
      "203/203 [==============================] - 0s 789us/step - loss: 0.1978 - mean_absolute_error: 0.2270 - val_loss: 0.2039 - val_mean_absolute_error: 0.2244\n",
      "Epoch 8/300\n",
      "203/203 [==============================] - 0s 810us/step - loss: 0.1907 - mean_absolute_error: 0.2248 - val_loss: 0.1999 - val_mean_absolute_error: 0.2244\n",
      "Epoch 9/300\n",
      "203/203 [==============================] - 0s 798us/step - loss: 0.1817 - mean_absolute_error: 0.2186 - val_loss: 0.1951 - val_mean_absolute_error: 0.2218\n",
      "Epoch 10/300\n",
      "203/203 [==============================] - 0s 804us/step - loss: 0.1821 - mean_absolute_error: 0.2209 - val_loss: 0.1866 - val_mean_absolute_error: 0.2123\n",
      "Epoch 11/300\n",
      "203/203 [==============================] - 0s 793us/step - loss: 0.1731 - mean_absolute_error: 0.2149 - val_loss: 0.1852 - val_mean_absolute_error: 0.2100\n",
      "Epoch 12/300\n",
      "203/203 [==============================] - 0s 794us/step - loss: 0.1685 - mean_absolute_error: 0.2110 - val_loss: 0.1759 - val_mean_absolute_error: 0.2048\n",
      "Epoch 13/300\n",
      "203/203 [==============================] - 0s 747us/step - loss: 0.1607 - mean_absolute_error: 0.2064 - val_loss: 0.1780 - val_mean_absolute_error: 0.2088\n",
      "Epoch 14/300\n",
      "203/203 [==============================] - 0s 798us/step - loss: 0.1582 - mean_absolute_error: 0.2051 - val_loss: 0.1751 - val_mean_absolute_error: 0.2045\n",
      "Epoch 15/300\n",
      "203/203 [==============================] - 0s 728us/step - loss: 0.1533 - mean_absolute_error: 0.2021 - val_loss: 0.1807 - val_mean_absolute_error: 0.2242\n",
      "Epoch 16/300\n",
      "203/203 [==============================] - 0s 852us/step - loss: 0.1534 - mean_absolute_error: 0.2029 - val_loss: 0.1634 - val_mean_absolute_error: 0.1970\n",
      "Epoch 17/300\n",
      "203/203 [==============================] - 0s 749us/step - loss: 0.1519 - mean_absolute_error: 0.2027 - val_loss: 0.1908 - val_mean_absolute_error: 0.2250\n",
      "Epoch 18/300\n",
      "203/203 [==============================] - 0s 781us/step - loss: 0.1462 - mean_absolute_error: 0.1995 - val_loss: 0.1783 - val_mean_absolute_error: 0.2088\n",
      "Epoch 19/300\n",
      "203/203 [==============================] - 0s 840us/step - loss: 0.1466 - mean_absolute_error: 0.2021 - val_loss: 0.1660 - val_mean_absolute_error: 0.2076\n",
      "Epoch 20/300\n",
      "203/203 [==============================] - 0s 825us/step - loss: 0.1404 - mean_absolute_error: 0.1954 - val_loss: 0.1621 - val_mean_absolute_error: 0.2000\n",
      "Epoch 21/300\n",
      "203/203 [==============================] - 0s 885us/step - loss: 0.1393 - mean_absolute_error: 0.1964 - val_loss: 0.1545 - val_mean_absolute_error: 0.1937\n",
      "Epoch 22/300\n",
      "203/203 [==============================] - 0s 853us/step - loss: 0.1340 - mean_absolute_error: 0.1917 - val_loss: 0.1650 - val_mean_absolute_error: 0.2030\n",
      "Epoch 23/300\n",
      "203/203 [==============================] - 0s 940us/step - loss: 0.1367 - mean_absolute_error: 0.1952 - val_loss: 0.1656 - val_mean_absolute_error: 0.1992\n",
      "Epoch 24/300\n",
      "203/203 [==============================] - 0s 901us/step - loss: 0.1326 - mean_absolute_error: 0.1921 - val_loss: 0.1561 - val_mean_absolute_error: 0.1954\n",
      "Epoch 25/300\n",
      "203/203 [==============================] - 0s 797us/step - loss: 0.1323 - mean_absolute_error: 0.1938 - val_loss: 0.1525 - val_mean_absolute_error: 0.1953\n",
      "Epoch 26/300\n",
      "203/203 [==============================] - 0s 766us/step - loss: 0.1302 - mean_absolute_error: 0.1909 - val_loss: 0.1529 - val_mean_absolute_error: 0.1941\n",
      "Epoch 27/300\n",
      "203/203 [==============================] - 0s 977us/step - loss: 0.1293 - mean_absolute_error: 0.1930 - val_loss: 0.1525 - val_mean_absolute_error: 0.1935\n",
      "Epoch 28/300\n",
      "203/203 [==============================] - 0s 815us/step - loss: 0.1270 - mean_absolute_error: 0.1895 - val_loss: 0.1500 - val_mean_absolute_error: 0.1973\n",
      "Epoch 29/300\n",
      "203/203 [==============================] - 0s 821us/step - loss: 0.1258 - mean_absolute_error: 0.1900 - val_loss: 0.1714 - val_mean_absolute_error: 0.2093\n",
      "Epoch 30/300\n",
      "203/203 [==============================] - 0s 896us/step - loss: 0.1261 - mean_absolute_error: 0.1902 - val_loss: 0.1546 - val_mean_absolute_error: 0.2025\n",
      "Epoch 31/300\n",
      "203/203 [==============================] - 0s 817us/step - loss: 0.1237 - mean_absolute_error: 0.1883 - val_loss: 0.1550 - val_mean_absolute_error: 0.1948\n",
      "Epoch 32/300\n",
      "203/203 [==============================] - 0s 904us/step - loss: 0.1206 - mean_absolute_error: 0.1868 - val_loss: 0.1496 - val_mean_absolute_error: 0.1962\n",
      "Epoch 33/300\n",
      "203/203 [==============================] - 0s 895us/step - loss: 0.1213 - mean_absolute_error: 0.1878 - val_loss: 0.1461 - val_mean_absolute_error: 0.1925\n",
      "Epoch 34/300\n",
      "203/203 [==============================] - 0s 837us/step - loss: 0.1199 - mean_absolute_error: 0.1871 - val_loss: 0.1440 - val_mean_absolute_error: 0.1936\n",
      "Epoch 35/300\n",
      "203/203 [==============================] - 0s 851us/step - loss: 0.1202 - mean_absolute_error: 0.1880 - val_loss: 0.1512 - val_mean_absolute_error: 0.1946\n",
      "Epoch 36/300\n",
      "203/203 [==============================] - 0s 845us/step - loss: 0.1170 - mean_absolute_error: 0.1858 - val_loss: 0.1480 - val_mean_absolute_error: 0.1936\n",
      "Epoch 37/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1244 - mean_absolute_error: 0.1906 - val_loss: 0.1465 - val_mean_absolute_error: 0.1923\n",
      "Epoch 38/300\n",
      "203/203 [==============================] - 0s 929us/step - loss: 0.1168 - mean_absolute_error: 0.1841 - val_loss: 0.1443 - val_mean_absolute_error: 0.1907\n",
      "Epoch 39/300\n",
      "203/203 [==============================] - 0s 744us/step - loss: 0.1155 - mean_absolute_error: 0.1851 - val_loss: 0.1451 - val_mean_absolute_error: 0.1922\n",
      "Epoch 40/300\n",
      "203/203 [==============================] - 0s 723us/step - loss: 0.1173 - mean_absolute_error: 0.1854 - val_loss: 0.1609 - val_mean_absolute_error: 0.2038\n",
      "Epoch 41/300\n",
      "203/203 [==============================] - 0s 724us/step - loss: 0.1126 - mean_absolute_error: 0.1855 - val_loss: 0.1434 - val_mean_absolute_error: 0.1910\n",
      "Epoch 42/300\n",
      "203/203 [==============================] - 0s 806us/step - loss: 0.1155 - mean_absolute_error: 0.1862 - val_loss: 0.1385 - val_mean_absolute_error: 0.1894\n",
      "Epoch 43/300\n",
      "203/203 [==============================] - 0s 725us/step - loss: 0.1164 - mean_absolute_error: 0.1863 - val_loss: 0.1608 - val_mean_absolute_error: 0.2320\n",
      "Epoch 44/300\n",
      "203/203 [==============================] - 0s 725us/step - loss: 0.1146 - mean_absolute_error: 0.1865 - val_loss: 0.1525 - val_mean_absolute_error: 0.1940\n",
      "Epoch 45/300\n",
      "203/203 [==============================] - 0s 780us/step - loss: 0.1117 - mean_absolute_error: 0.1831 - val_loss: 0.1462 - val_mean_absolute_error: 0.1926\n",
      "Epoch 46/300\n",
      "203/203 [==============================] - 0s 742us/step - loss: 0.1102 - mean_absolute_error: 0.1814 - val_loss: 0.1761 - val_mean_absolute_error: 0.2026\n",
      "Epoch 47/300\n",
      "203/203 [==============================] - 0s 825us/step - loss: 0.1102 - mean_absolute_error: 0.1835 - val_loss: 0.1359 - val_mean_absolute_error: 0.1883\n",
      "Epoch 48/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 0s 777us/step - loss: 0.1108 - mean_absolute_error: 0.1828 - val_loss: 0.1402 - val_mean_absolute_error: 0.1899\n",
      "Epoch 49/300\n",
      "203/203 [==============================] - 0s 758us/step - loss: 0.1085 - mean_absolute_error: 0.1824 - val_loss: 0.1491 - val_mean_absolute_error: 0.1954\n",
      "Epoch 50/300\n",
      "203/203 [==============================] - 0s 849us/step - loss: 0.1085 - mean_absolute_error: 0.1813 - val_loss: 0.1413 - val_mean_absolute_error: 0.1914\n",
      "Epoch 51/300\n",
      "203/203 [==============================] - 0s 800us/step - loss: 0.1111 - mean_absolute_error: 0.1833 - val_loss: 0.1430 - val_mean_absolute_error: 0.1922\n",
      "Epoch 52/300\n",
      "203/203 [==============================] - 0s 796us/step - loss: 0.1072 - mean_absolute_error: 0.1801 - val_loss: 0.1456 - val_mean_absolute_error: 0.1922\n",
      "Epoch 53/300\n",
      "203/203 [==============================] - 0s 754us/step - loss: 0.1053 - mean_absolute_error: 0.1791 - val_loss: 0.1437 - val_mean_absolute_error: 0.1923\n",
      "Epoch 54/300\n",
      "203/203 [==============================] - 0s 748us/step - loss: 0.1055 - mean_absolute_error: 0.1802 - val_loss: 0.1394 - val_mean_absolute_error: 0.1885\n",
      "Epoch 55/300\n",
      "203/203 [==============================] - 0s 728us/step - loss: 0.1058 - mean_absolute_error: 0.1793 - val_loss: 0.1301 - val_mean_absolute_error: 0.1884\n",
      "Epoch 56/300\n",
      "203/203 [==============================] - 0s 787us/step - loss: 0.1044 - mean_absolute_error: 0.1794 - val_loss: 0.1381 - val_mean_absolute_error: 0.1866\n",
      "Epoch 57/300\n",
      "203/203 [==============================] - 0s 731us/step - loss: 0.1033 - mean_absolute_error: 0.1775 - val_loss: 0.1380 - val_mean_absolute_error: 0.1884\n",
      "Epoch 58/300\n",
      "203/203 [==============================] - 0s 797us/step - loss: 0.1024 - mean_absolute_error: 0.1777 - val_loss: 0.1395 - val_mean_absolute_error: 0.1948\n",
      "Epoch 59/300\n",
      "203/203 [==============================] - 0s 833us/step - loss: 0.1056 - mean_absolute_error: 0.1821 - val_loss: 0.1352 - val_mean_absolute_error: 0.1890\n",
      "Epoch 60/300\n",
      "203/203 [==============================] - 0s 860us/step - loss: 0.1025 - mean_absolute_error: 0.1772 - val_loss: 0.1363 - val_mean_absolute_error: 0.1870\n",
      "Epoch 61/300\n",
      "203/203 [==============================] - 0s 872us/step - loss: 0.0997 - mean_absolute_error: 0.1763 - val_loss: 0.1428 - val_mean_absolute_error: 0.1897\n",
      "Epoch 62/300\n",
      "203/203 [==============================] - 0s 797us/step - loss: 0.1051 - mean_absolute_error: 0.1808 - val_loss: 0.1398 - val_mean_absolute_error: 0.1956\n",
      "Epoch 63/300\n",
      "203/203 [==============================] - 0s 782us/step - loss: 0.1018 - mean_absolute_error: 0.1779 - val_loss: 0.1475 - val_mean_absolute_error: 0.1934\n",
      "Epoch 64/300\n",
      "203/203 [==============================] - 0s 744us/step - loss: 0.1043 - mean_absolute_error: 0.1811 - val_loss: 0.1394 - val_mean_absolute_error: 0.1896\n",
      "Epoch 65/300\n",
      "203/203 [==============================] - 0s 831us/step - loss: 0.0995 - mean_absolute_error: 0.1768 - val_loss: 0.1390 - val_mean_absolute_error: 0.1899\n",
      "Epoch 66/300\n",
      "203/203 [==============================] - 0s 793us/step - loss: 0.0985 - mean_absolute_error: 0.1771 - val_loss: 0.1337 - val_mean_absolute_error: 0.1867\n",
      "Epoch 67/300\n",
      "203/203 [==============================] - 0s 950us/step - loss: 0.0997 - mean_absolute_error: 0.1773 - val_loss: 0.1346 - val_mean_absolute_error: 0.1873\n",
      "Epoch 68/300\n",
      "203/203 [==============================] - 0s 994us/step - loss: 0.1058 - mean_absolute_error: 0.1805 - val_loss: 0.1304 - val_mean_absolute_error: 0.1835\n",
      "Epoch 69/300\n",
      "203/203 [==============================] - 0s 865us/step - loss: 0.1012 - mean_absolute_error: 0.1774 - val_loss: 0.1385 - val_mean_absolute_error: 0.1891\n",
      "Epoch 70/300\n",
      "203/203 [==============================] - 0s 797us/step - loss: 0.1061 - mean_absolute_error: 0.1815 - val_loss: 0.1478 - val_mean_absolute_error: 0.1882\n",
      "Epoch 71/300\n",
      "203/203 [==============================] - 0s 903us/step - loss: 0.1002 - mean_absolute_error: 0.1769 - val_loss: 0.1668 - val_mean_absolute_error: 0.2004\n",
      "Epoch 72/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1070 - mean_absolute_error: 0.1828 - val_loss: 0.1308 - val_mean_absolute_error: 0.1832\n",
      "Epoch 73/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.0982 - mean_absolute_error: 0.1760 - val_loss: 0.1301 - val_mean_absolute_error: 0.1905\n",
      "Epoch 74/300\n",
      "203/203 [==============================] - 0s 858us/step - loss: 0.0957 - mean_absolute_error: 0.1744 - val_loss: 0.1299 - val_mean_absolute_error: 0.1846\n",
      "Epoch 75/300\n",
      "203/203 [==============================] - 0s 823us/step - loss: 0.0948 - mean_absolute_error: 0.1736 - val_loss: 0.1331 - val_mean_absolute_error: 0.1874\n",
      "Epoch 76/300\n",
      "203/203 [==============================] - 0s 728us/step - loss: 0.0993 - mean_absolute_error: 0.1765 - val_loss: 0.1352 - val_mean_absolute_error: 0.1904\n",
      "Epoch 77/300\n",
      "203/203 [==============================] - 0s 816us/step - loss: 0.1015 - mean_absolute_error: 0.1783 - val_loss: 0.1394 - val_mean_absolute_error: 0.1908\n",
      "Epoch 78/300\n",
      "203/203 [==============================] - 0s 846us/step - loss: 0.0952 - mean_absolute_error: 0.1740 - val_loss: 0.1307 - val_mean_absolute_error: 0.1861\n",
      "Epoch 79/300\n",
      "203/203 [==============================] - 0s 819us/step - loss: 0.0952 - mean_absolute_error: 0.1728 - val_loss: 0.1312 - val_mean_absolute_error: 0.1885\n",
      "Epoch 80/300\n",
      "203/203 [==============================] - 0s 813us/step - loss: 0.1002 - mean_absolute_error: 0.1788 - val_loss: 0.1356 - val_mean_absolute_error: 0.1887\n",
      "Epoch 81/300\n",
      "203/203 [==============================] - 0s 839us/step - loss: 0.0965 - mean_absolute_error: 0.1750 - val_loss: 0.1348 - val_mean_absolute_error: 0.1879\n",
      "Epoch 82/300\n",
      "203/203 [==============================] - 0s 804us/step - loss: 0.0929 - mean_absolute_error: 0.1723 - val_loss: 0.1340 - val_mean_absolute_error: 0.1899\n",
      "Epoch 83/300\n",
      "203/203 [==============================] - 0s 813us/step - loss: 0.0933 - mean_absolute_error: 0.1732 - val_loss: 0.1543 - val_mean_absolute_error: 0.2005\n",
      "Epoch 84/300\n",
      "203/203 [==============================] - 0s 900us/step - loss: 0.0967 - mean_absolute_error: 0.1756 - val_loss: 0.1351 - val_mean_absolute_error: 0.1904\n",
      "Epoch 85/300\n",
      "203/203 [==============================] - 0s 953us/step - loss: 0.0973 - mean_absolute_error: 0.1751 - val_loss: 0.1253 - val_mean_absolute_error: 0.1824\n",
      "Epoch 86/300\n",
      "203/203 [==============================] - 0s 929us/step - loss: 0.0913 - mean_absolute_error: 0.1712 - val_loss: 0.1349 - val_mean_absolute_error: 0.1866\n",
      "Epoch 87/300\n",
      "203/203 [==============================] - 0s 948us/step - loss: 0.0932 - mean_absolute_error: 0.1723 - val_loss: 0.1348 - val_mean_absolute_error: 0.1879\n",
      "Epoch 88/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.0930 - mean_absolute_error: 0.1735 - val_loss: 0.1292 - val_mean_absolute_error: 0.1861\n",
      "Epoch 89/300\n",
      "203/203 [==============================] - 0s 884us/step - loss: 0.0934 - mean_absolute_error: 0.1740 - val_loss: 0.1375 - val_mean_absolute_error: 0.1857\n",
      "Epoch 90/300\n",
      "203/203 [==============================] - 0s 894us/step - loss: 0.0970 - mean_absolute_error: 0.1754 - val_loss: 0.1452 - val_mean_absolute_error: 0.1940\n",
      "Epoch 91/300\n",
      "203/203 [==============================] - 0s 816us/step - loss: 0.0944 - mean_absolute_error: 0.1749 - val_loss: 0.1307 - val_mean_absolute_error: 0.1894\n",
      "Epoch 92/300\n",
      "203/203 [==============================] - 0s 729us/step - loss: 0.0932 - mean_absolute_error: 0.1727 - val_loss: 0.1494 - val_mean_absolute_error: 0.1973\n",
      "Epoch 93/300\n",
      "203/203 [==============================] - 0s 725us/step - loss: 0.0920 - mean_absolute_error: 0.1714 - val_loss: 0.1353 - val_mean_absolute_error: 0.2017\n",
      "Epoch 94/300\n",
      "203/203 [==============================] - 0s 743us/step - loss: 0.1007 - mean_absolute_error: 0.1793 - val_loss: 0.1278 - val_mean_absolute_error: 0.1836\n",
      "Epoch 95/300\n",
      "203/203 [==============================] - 0s 720us/step - loss: 0.0931 - mean_absolute_error: 0.1724 - val_loss: 0.1360 - val_mean_absolute_error: 0.1836\n",
      "Epoch 96/300\n",
      "203/203 [==============================] - 0s 727us/step - loss: 0.0903 - mean_absolute_error: 0.1700 - val_loss: 0.1309 - val_mean_absolute_error: 0.1865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/300\n",
      "203/203 [==============================] - 0s 793us/step - loss: 0.0916 - mean_absolute_error: 0.1723 - val_loss: 0.1334 - val_mean_absolute_error: 0.1920\n",
      "Epoch 98/300\n",
      "203/203 [==============================] - 0s 751us/step - loss: 0.0891 - mean_absolute_error: 0.1706 - val_loss: 0.1353 - val_mean_absolute_error: 0.1840\n",
      "Epoch 99/300\n",
      "203/203 [==============================] - 0s 760us/step - loss: 0.0887 - mean_absolute_error: 0.1688 - val_loss: 0.1254 - val_mean_absolute_error: 0.1824\n",
      "Epoch 100/300\n",
      "203/203 [==============================] - 0s 747us/step - loss: 0.0898 - mean_absolute_error: 0.1706 - val_loss: 0.1294 - val_mean_absolute_error: 0.1840\n",
      "Epoch 101/300\n",
      "203/203 [==============================] - 0s 715us/step - loss: 0.0889 - mean_absolute_error: 0.1695 - val_loss: 0.1620 - val_mean_absolute_error: 0.1975\n",
      "Epoch 102/300\n",
      "203/203 [==============================] - 0s 742us/step - loss: 0.0926 - mean_absolute_error: 0.1740 - val_loss: 0.1336 - val_mean_absolute_error: 0.1867\n",
      "Epoch 103/300\n",
      "203/203 [==============================] - 0s 724us/step - loss: 0.0900 - mean_absolute_error: 0.1718 - val_loss: 0.1342 - val_mean_absolute_error: 0.1842\n",
      "Epoch 104/300\n",
      "203/203 [==============================] - 0s 753us/step - loss: 0.0918 - mean_absolute_error: 0.1737 - val_loss: 0.1399 - val_mean_absolute_error: 0.1832\n",
      "Epoch 105/300\n",
      "203/203 [==============================] - 0s 797us/step - loss: 0.0891 - mean_absolute_error: 0.1690 - val_loss: 0.1323 - val_mean_absolute_error: 0.1817\n",
      "Epoch 106/300\n",
      "203/203 [==============================] - 0s 719us/step - loss: 0.0881 - mean_absolute_error: 0.1696 - val_loss: 0.1268 - val_mean_absolute_error: 0.1854\n",
      "Epoch 107/300\n",
      "203/203 [==============================] - 0s 725us/step - loss: 0.0943 - mean_absolute_error: 0.1748 - val_loss: 0.1534 - val_mean_absolute_error: 0.1893\n",
      "Epoch 108/300\n",
      "203/203 [==============================] - 0s 787us/step - loss: 0.0916 - mean_absolute_error: 0.1714 - val_loss: 0.1275 - val_mean_absolute_error: 0.1816\n",
      "Epoch 109/300\n",
      "203/203 [==============================] - 0s 718us/step - loss: 0.0884 - mean_absolute_error: 0.1688 - val_loss: 0.1399 - val_mean_absolute_error: 0.1884\n",
      "Epoch 110/300\n",
      "203/203 [==============================] - 0s 716us/step - loss: 0.0877 - mean_absolute_error: 0.1705 - val_loss: 0.1387 - val_mean_absolute_error: 0.1866\n",
      "Epoch 111/300\n",
      "203/203 [==============================] - 0s 719us/step - loss: 0.0860 - mean_absolute_error: 0.1678 - val_loss: 0.1347 - val_mean_absolute_error: 0.1860\n",
      "Epoch 112/300\n",
      "203/203 [==============================] - 0s 768us/step - loss: 0.0870 - mean_absolute_error: 0.1700 - val_loss: 0.1273 - val_mean_absolute_error: 0.1841\n",
      "Epoch 113/300\n",
      "203/203 [==============================] - 0s 733us/step - loss: 0.0891 - mean_absolute_error: 0.1698 - val_loss: 0.1379 - val_mean_absolute_error: 0.1865\n",
      "Epoch 114/300\n",
      "203/203 [==============================] - 0s 809us/step - loss: 0.0881 - mean_absolute_error: 0.1689 - val_loss: 0.1416 - val_mean_absolute_error: 0.1883\n",
      "Epoch 115/300\n",
      "203/203 [==============================] - 0s 738us/step - loss: 0.0939 - mean_absolute_error: 0.1754 - val_loss: 0.1376 - val_mean_absolute_error: 0.1881\n",
      "Epoch 116/300\n",
      "203/203 [==============================] - 0s 815us/step - loss: 0.0895 - mean_absolute_error: 0.1703 - val_loss: 0.1427 - val_mean_absolute_error: 0.1901\n",
      "Epoch 117/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.0866 - mean_absolute_error: 0.1688 - val_loss: 0.1412 - val_mean_absolute_error: 0.1958\n",
      "Epoch 118/300\n",
      "203/203 [==============================] - 0s 909us/step - loss: 0.0855 - mean_absolute_error: 0.1677 - val_loss: 0.1390 - val_mean_absolute_error: 0.1946\n",
      "Epoch 119/300\n",
      "203/203 [==============================] - 0s 781us/step - loss: 0.0877 - mean_absolute_error: 0.1696 - val_loss: 0.1263 - val_mean_absolute_error: 0.1847\n",
      "Epoch 120/300\n",
      "203/203 [==============================] - 0s 771us/step - loss: 0.0925 - mean_absolute_error: 0.1741 - val_loss: 0.1362 - val_mean_absolute_error: 0.1861\n",
      "Epoch 121/300\n",
      "203/203 [==============================] - 0s 792us/step - loss: 0.0873 - mean_absolute_error: 0.1694 - val_loss: 0.1258 - val_mean_absolute_error: 0.1829\n",
      "Epoch 122/300\n",
      "203/203 [==============================] - 0s 824us/step - loss: 0.0868 - mean_absolute_error: 0.1691 - val_loss: 0.1326 - val_mean_absolute_error: 0.1847\n",
      "Epoch 123/300\n",
      "203/203 [==============================] - 0s 795us/step - loss: 0.0871 - mean_absolute_error: 0.1700 - val_loss: 0.1386 - val_mean_absolute_error: 0.1890\n",
      "Epoch 124/300\n",
      "203/203 [==============================] - 0s 765us/step - loss: 0.0866 - mean_absolute_error: 0.1698 - val_loss: 0.1409 - val_mean_absolute_error: 0.1996\n",
      "Epoch 125/300\n",
      "203/203 [==============================] - 0s 860us/step - loss: 0.0843 - mean_absolute_error: 0.1685 - val_loss: 0.1419 - val_mean_absolute_error: 0.1876\n",
      "Epoch 126/300\n",
      "203/203 [==============================] - 0s 880us/step - loss: 0.0886 - mean_absolute_error: 0.1710 - val_loss: 0.1419 - val_mean_absolute_error: 0.1875\n",
      "Epoch 127/300\n",
      "203/203 [==============================] - 0s 770us/step - loss: 0.0856 - mean_absolute_error: 0.1680 - val_loss: 0.1340 - val_mean_absolute_error: 0.1864\n",
      "Epoch 128/300\n",
      "203/203 [==============================] - 0s 746us/step - loss: 0.0883 - mean_absolute_error: 0.1707 - val_loss: 0.1291 - val_mean_absolute_error: 0.1840\n",
      "Epoch 129/300\n",
      "203/203 [==============================] - 0s 768us/step - loss: 0.0839 - mean_absolute_error: 0.1663 - val_loss: 0.1282 - val_mean_absolute_error: 0.1820\n",
      "Epoch 130/300\n",
      "203/203 [==============================] - 0s 739us/step - loss: 0.0841 - mean_absolute_error: 0.1669 - val_loss: 0.1249 - val_mean_absolute_error: 0.1822\n",
      "Epoch 131/300\n",
      "203/203 [==============================] - 0s 757us/step - loss: 0.0850 - mean_absolute_error: 0.1678 - val_loss: 0.1325 - val_mean_absolute_error: 0.1902\n",
      "Epoch 132/300\n",
      "203/203 [==============================] - 0s 762us/step - loss: 0.0846 - mean_absolute_error: 0.1675 - val_loss: 0.1382 - val_mean_absolute_error: 0.1882\n",
      "Epoch 133/300\n",
      "203/203 [==============================] - 0s 756us/step - loss: 0.0890 - mean_absolute_error: 0.1706 - val_loss: 0.1306 - val_mean_absolute_error: 0.1829\n",
      "Epoch 134/300\n",
      "203/203 [==============================] - 0s 762us/step - loss: 0.0832 - mean_absolute_error: 0.1660 - val_loss: 0.1301 - val_mean_absolute_error: 0.1862\n",
      "Epoch 135/300\n",
      "203/203 [==============================] - 0s 762us/step - loss: 0.0852 - mean_absolute_error: 0.1673 - val_loss: 0.1337 - val_mean_absolute_error: 0.1901\n",
      "Epoch 136/300\n",
      "203/203 [==============================] - 0s 835us/step - loss: 0.0827 - mean_absolute_error: 0.1663 - val_loss: 0.1276 - val_mean_absolute_error: 0.1804\n",
      "Epoch 137/300\n",
      "203/203 [==============================] - 0s 776us/step - loss: 0.0824 - mean_absolute_error: 0.1651 - val_loss: 0.1283 - val_mean_absolute_error: 0.1865\n",
      "Epoch 138/300\n",
      "203/203 [==============================] - 0s 801us/step - loss: 0.0899 - mean_absolute_error: 0.1723 - val_loss: 0.1454 - val_mean_absolute_error: 0.1962\n",
      "Epoch 139/300\n",
      "203/203 [==============================] - 0s 989us/step - loss: 0.0831 - mean_absolute_error: 0.1666 - val_loss: 0.1302 - val_mean_absolute_error: 0.1846\n",
      "Epoch 140/300\n",
      "203/203 [==============================] - 0s 978us/step - loss: 0.0808 - mean_absolute_error: 0.1644 - val_loss: 0.1290 - val_mean_absolute_error: 0.1813\n",
      "Epoch 141/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.0839 - mean_absolute_error: 0.1660 - val_loss: 0.1342 - val_mean_absolute_error: 0.1884\n",
      "Epoch 142/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.0878 - mean_absolute_error: 0.1708 - val_loss: 0.1340 - val_mean_absolute_error: 0.1822\n",
      "Epoch 143/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.0819 - mean_absolute_error: 0.1661 - val_loss: 0.1375 - val_mean_absolute_error: 0.1882\n",
      "Epoch 144/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.0875 - mean_absolute_error: 0.1695 - val_loss: 0.1380 - val_mean_absolute_error: 0.1881\n",
      "Epoch 145/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 0s 973us/step - loss: 0.0825 - mean_absolute_error: 0.1658 - val_loss: 0.1303 - val_mean_absolute_error: 0.1824\n",
      "Epoch 146/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.0816 - mean_absolute_error: 0.1654 - val_loss: 0.1362 - val_mean_absolute_error: 0.1859\n",
      "Epoch 147/300\n",
      "203/203 [==============================] - 0s 943us/step - loss: 0.0854 - mean_absolute_error: 0.1689 - val_loss: 0.1344 - val_mean_absolute_error: 0.1824\n",
      "Epoch 148/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.0873 - mean_absolute_error: 0.1700 - val_loss: 0.1327 - val_mean_absolute_error: 0.1831\n",
      "Epoch 149/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.0827 - mean_absolute_error: 0.1673 - val_loss: 0.1373 - val_mean_absolute_error: 0.1843\n",
      "Epoch 150/300\n",
      "203/203 [==============================] - 0s 938us/step - loss: 0.0869 - mean_absolute_error: 0.1697 - val_loss: 0.1398 - val_mean_absolute_error: 0.1895\n",
      "Epoch 151/300\n",
      "203/203 [==============================] - 0s 936us/step - loss: 0.0836 - mean_absolute_error: 0.1663 - val_loss: 0.1491 - val_mean_absolute_error: 0.1906\n",
      "Epoch 152/300\n",
      "203/203 [==============================] - 0s 802us/step - loss: 0.0865 - mean_absolute_error: 0.1691 - val_loss: 0.1381 - val_mean_absolute_error: 0.1874\n",
      "Epoch 153/300\n",
      "203/203 [==============================] - 0s 988us/step - loss: 0.0814 - mean_absolute_error: 0.1646 - val_loss: 0.1542 - val_mean_absolute_error: 0.1878\n",
      "Epoch 154/300\n",
      "203/203 [==============================] - 0s 881us/step - loss: 0.0859 - mean_absolute_error: 0.1676 - val_loss: 0.1404 - val_mean_absolute_error: 0.1874\n",
      "Epoch 155/300\n",
      "203/203 [==============================] - 0s 887us/step - loss: 0.0814 - mean_absolute_error: 0.1644 - val_loss: 0.1397 - val_mean_absolute_error: 0.1853\n",
      "Epoch 156/300\n",
      "203/203 [==============================] - 0s 958us/step - loss: 0.0823 - mean_absolute_error: 0.1652 - val_loss: 0.1366 - val_mean_absolute_error: 0.1820\n",
      "Epoch 157/300\n",
      "203/203 [==============================] - 0s 803us/step - loss: 0.0802 - mean_absolute_error: 0.1639 - val_loss: 0.1384 - val_mean_absolute_error: 0.1881\n",
      "Epoch 158/300\n",
      "203/203 [==============================] - 0s 886us/step - loss: 0.0856 - mean_absolute_error: 0.1684 - val_loss: 0.1324 - val_mean_absolute_error: 0.1921\n",
      "Epoch 159/300\n",
      "203/203 [==============================] - 0s 978us/step - loss: 0.0811 - mean_absolute_error: 0.1642 - val_loss: 0.1354 - val_mean_absolute_error: 0.1917\n",
      "Epoch 160/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.0838 - mean_absolute_error: 0.1679 - val_loss: 0.1298 - val_mean_absolute_error: 0.1835\n",
      "Epoch 161/300\n",
      "203/203 [==============================] - 0s 951us/step - loss: 0.0850 - mean_absolute_error: 0.1668 - val_loss: 0.1388 - val_mean_absolute_error: 0.1876\n",
      "Epoch 162/300\n",
      "203/203 [==============================] - 0s 928us/step - loss: 0.0812 - mean_absolute_error: 0.1658 - val_loss: 0.1312 - val_mean_absolute_error: 0.1845\n",
      "Epoch 163/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.0812 - mean_absolute_error: 0.1652 - val_loss: 0.1321 - val_mean_absolute_error: 0.1856\n",
      "Epoch 164/300\n",
      "203/203 [==============================] - 0s 953us/step - loss: 0.0825 - mean_absolute_error: 0.1656 - val_loss: 0.1338 - val_mean_absolute_error: 0.1847\n",
      "Epoch 165/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.0798 - mean_absolute_error: 0.1642 - val_loss: 0.1292 - val_mean_absolute_error: 0.1865\n",
      "Epoch 166/300\n",
      "203/203 [==============================] - 0s 904us/step - loss: 0.0795 - mean_absolute_error: 0.1638 - val_loss: 0.1353 - val_mean_absolute_error: 0.1816\n",
      "Epoch 167/300\n",
      "203/203 [==============================] - 0s 762us/step - loss: 0.0787 - mean_absolute_error: 0.1628 - val_loss: 0.1398 - val_mean_absolute_error: 0.1853\n",
      "Epoch 168/300\n",
      "203/203 [==============================] - 0s 741us/step - loss: 0.0794 - mean_absolute_error: 0.1643 - val_loss: 0.1435 - val_mean_absolute_error: 0.1868\n",
      "Epoch 169/300\n",
      "203/203 [==============================] - 0s 745us/step - loss: 0.0789 - mean_absolute_error: 0.1629 - val_loss: 0.1327 - val_mean_absolute_error: 0.1835\n",
      "Epoch 170/300\n",
      "203/203 [==============================] - 0s 731us/step - loss: 0.0790 - mean_absolute_error: 0.1639 - val_loss: 0.1380 - val_mean_absolute_error: 0.1886\n",
      "Epoch 171/300\n",
      "203/203 [==============================] - 0s 756us/step - loss: 0.0808 - mean_absolute_error: 0.1655 - val_loss: 0.1514 - val_mean_absolute_error: 0.1878\n",
      "Epoch 172/300\n",
      "203/203 [==============================] - 0s 803us/step - loss: 0.0800 - mean_absolute_error: 0.1645 - val_loss: 0.1455 - val_mean_absolute_error: 0.1884\n",
      "Epoch 173/300\n",
      "203/203 [==============================] - 0s 912us/step - loss: 0.0823 - mean_absolute_error: 0.1647 - val_loss: 0.1493 - val_mean_absolute_error: 0.1932\n",
      "Epoch 174/300\n",
      "203/203 [==============================] - 0s 850us/step - loss: 0.0891 - mean_absolute_error: 0.1703 - val_loss: 0.1518 - val_mean_absolute_error: 0.1860\n",
      "Epoch 175/300\n",
      "203/203 [==============================] - 0s 741us/step - loss: 0.0797 - mean_absolute_error: 0.1651 - val_loss: 0.1489 - val_mean_absolute_error: 0.1933\n",
      "Epoch 176/300\n",
      "203/203 [==============================] - 0s 853us/step - loss: 0.0787 - mean_absolute_error: 0.1636 - val_loss: 0.1349 - val_mean_absolute_error: 0.1853\n",
      "Epoch 177/300\n",
      "203/203 [==============================] - 0s 807us/step - loss: 0.0784 - mean_absolute_error: 0.1633 - val_loss: 0.1331 - val_mean_absolute_error: 0.1826\n",
      "Epoch 178/300\n",
      "203/203 [==============================] - 0s 771us/step - loss: 0.0805 - mean_absolute_error: 0.1649 - val_loss: 0.1294 - val_mean_absolute_error: 0.1862\n",
      "Epoch 179/300\n",
      "203/203 [==============================] - 0s 763us/step - loss: 0.0784 - mean_absolute_error: 0.1635 - val_loss: 0.1612 - val_mean_absolute_error: 0.1967\n",
      "Epoch 180/300\n",
      "203/203 [==============================] - 0s 749us/step - loss: 0.0909 - mean_absolute_error: 0.1746 - val_loss: 0.1495 - val_mean_absolute_error: 0.2129\n",
      "Epoch 181/300\n",
      "203/203 [==============================] - 0s 746us/step - loss: 0.0875 - mean_absolute_error: 0.1713 - val_loss: 0.1409 - val_mean_absolute_error: 0.1947\n",
      "Epoch 182/300\n",
      "203/203 [==============================] - 0s 753us/step - loss: 0.0839 - mean_absolute_error: 0.1676 - val_loss: 0.1430 - val_mean_absolute_error: 0.1842\n",
      "Epoch 183/300\n",
      "203/203 [==============================] - 0s 765us/step - loss: 0.0787 - mean_absolute_error: 0.1622 - val_loss: 0.1401 - val_mean_absolute_error: 0.1833\n",
      "Epoch 184/300\n",
      "203/203 [==============================] - 0s 750us/step - loss: 0.0786 - mean_absolute_error: 0.1639 - val_loss: 0.1374 - val_mean_absolute_error: 0.1834\n",
      "Epoch 185/300\n",
      "203/203 [==============================] - 0s 787us/step - loss: 0.0785 - mean_absolute_error: 0.1632 - val_loss: 0.1410 - val_mean_absolute_error: 0.1905\n",
      "Epoch 186/300\n",
      "203/203 [==============================] - 0s 740us/step - loss: 0.0788 - mean_absolute_error: 0.1634 - val_loss: 0.1321 - val_mean_absolute_error: 0.1848\n",
      "Epoch 187/300\n",
      "203/203 [==============================] - 0s 737us/step - loss: 0.0794 - mean_absolute_error: 0.1646 - val_loss: 0.1341 - val_mean_absolute_error: 0.1851\n",
      "Epoch 188/300\n",
      "203/203 [==============================] - 0s 769us/step - loss: 0.0805 - mean_absolute_error: 0.1644 - val_loss: 0.1437 - val_mean_absolute_error: 0.1879\n",
      "Epoch 189/300\n",
      "203/203 [==============================] - 0s 774us/step - loss: 0.0828 - mean_absolute_error: 0.1670 - val_loss: 0.1372 - val_mean_absolute_error: 0.1848\n",
      "Epoch 190/300\n",
      "203/203 [==============================] - 0s 787us/step - loss: 0.0824 - mean_absolute_error: 0.1658 - val_loss: 0.1531 - val_mean_absolute_error: 0.1922\n",
      "Epoch 191/300\n",
      "203/203 [==============================] - 0s 790us/step - loss: 0.0791 - mean_absolute_error: 0.1625 - val_loss: 0.1365 - val_mean_absolute_error: 0.1834\n",
      "Epoch 192/300\n",
      "203/203 [==============================] - 0s 818us/step - loss: 0.0787 - mean_absolute_error: 0.1629 - val_loss: 0.1317 - val_mean_absolute_error: 0.1830\n",
      "Epoch 193/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 0s 794us/step - loss: 0.0809 - mean_absolute_error: 0.1645 - val_loss: 0.1357 - val_mean_absolute_error: 0.1874\n",
      "Epoch 194/300\n",
      "203/203 [==============================] - 0s 774us/step - loss: 0.0774 - mean_absolute_error: 0.1622 - val_loss: 0.1450 - val_mean_absolute_error: 0.1870\n",
      "Epoch 195/300\n",
      "203/203 [==============================] - 0s 750us/step - loss: 0.0800 - mean_absolute_error: 0.1654 - val_loss: 0.1476 - val_mean_absolute_error: 0.1866\n",
      "Epoch 196/300\n",
      "203/203 [==============================] - 0s 875us/step - loss: 0.0775 - mean_absolute_error: 0.1633 - val_loss: 0.1636 - val_mean_absolute_error: 0.1906\n",
      "Epoch 197/300\n",
      "203/203 [==============================] - 0s 763us/step - loss: 0.0845 - mean_absolute_error: 0.1671 - val_loss: 0.1398 - val_mean_absolute_error: 0.1924\n",
      "Epoch 198/300\n",
      "203/203 [==============================] - 0s 746us/step - loss: 0.0782 - mean_absolute_error: 0.1621 - val_loss: 0.1325 - val_mean_absolute_error: 0.1826\n",
      "Epoch 199/300\n",
      "203/203 [==============================] - 0s 760us/step - loss: 0.0835 - mean_absolute_error: 0.1654 - val_loss: 0.1447 - val_mean_absolute_error: 0.1876\n",
      "Epoch 200/300\n",
      "203/203 [==============================] - 0s 748us/step - loss: 0.0792 - mean_absolute_error: 0.1633 - val_loss: 0.1414 - val_mean_absolute_error: 0.1930\n",
      "Epoch 201/300\n",
      "203/203 [==============================] - 0s 754us/step - loss: 0.0773 - mean_absolute_error: 0.1616 - val_loss: 0.1542 - val_mean_absolute_error: 0.1947\n",
      "Epoch 202/300\n",
      "203/203 [==============================] - 0s 777us/step - loss: 0.0814 - mean_absolute_error: 0.1660 - val_loss: 0.1322 - val_mean_absolute_error: 0.1846\n",
      "Epoch 203/300\n",
      "203/203 [==============================] - 0s 745us/step - loss: 0.0775 - mean_absolute_error: 0.1612 - val_loss: 0.1529 - val_mean_absolute_error: 0.1991\n",
      "Epoch 204/300\n",
      "203/203 [==============================] - 0s 767us/step - loss: 0.0821 - mean_absolute_error: 0.1666 - val_loss: 0.1403 - val_mean_absolute_error: 0.1841\n",
      "Epoch 205/300\n",
      "203/203 [==============================] - 0s 746us/step - loss: 0.0778 - mean_absolute_error: 0.1630 - val_loss: 0.1283 - val_mean_absolute_error: 0.1810\n",
      "Epoch 206/300\n",
      "203/203 [==============================] - 0s 829us/step - loss: 0.0781 - mean_absolute_error: 0.1635 - val_loss: 0.1316 - val_mean_absolute_error: 0.1892\n",
      "Epoch 207/300\n",
      "203/203 [==============================] - 0s 758us/step - loss: 0.0774 - mean_absolute_error: 0.1630 - val_loss: 0.1299 - val_mean_absolute_error: 0.1838\n",
      "Epoch 208/300\n",
      "203/203 [==============================] - 0s 768us/step - loss: 0.0765 - mean_absolute_error: 0.1615 - val_loss: 0.1386 - val_mean_absolute_error: 0.1870\n",
      "Epoch 209/300\n",
      "203/203 [==============================] - 0s 756us/step - loss: 0.0802 - mean_absolute_error: 0.1634 - val_loss: 0.1937 - val_mean_absolute_error: 0.1969\n",
      "Epoch 210/300\n",
      "203/203 [==============================] - 0s 797us/step - loss: 0.0812 - mean_absolute_error: 0.1661 - val_loss: 0.1331 - val_mean_absolute_error: 0.1870\n",
      "Epoch 211/300\n",
      "203/203 [==============================] - 0s 830us/step - loss: 0.0775 - mean_absolute_error: 0.1627 - val_loss: 0.1585 - val_mean_absolute_error: 0.1904\n",
      "Epoch 212/300\n",
      "203/203 [==============================] - 0s 809us/step - loss: 0.0764 - mean_absolute_error: 0.1613 - val_loss: 0.1327 - val_mean_absolute_error: 0.1833\n",
      "Epoch 213/300\n",
      "203/203 [==============================] - 0s 753us/step - loss: 0.0804 - mean_absolute_error: 0.1649 - val_loss: 0.1376 - val_mean_absolute_error: 0.1859\n",
      "Epoch 214/300\n",
      "203/203 [==============================] - 0s 767us/step - loss: 0.0752 - mean_absolute_error: 0.1593 - val_loss: 0.1528 - val_mean_absolute_error: 0.1869\n",
      "Epoch 215/300\n",
      "203/203 [==============================] - 0s 776us/step - loss: 0.0753 - mean_absolute_error: 0.1597 - val_loss: 0.1366 - val_mean_absolute_error: 0.1877\n",
      "Epoch 216/300\n",
      "203/203 [==============================] - 0s 939us/step - loss: 0.0781 - mean_absolute_error: 0.1628 - val_loss: 0.1366 - val_mean_absolute_error: 0.1898\n",
      "Epoch 217/300\n",
      "203/203 [==============================] - 0s 785us/step - loss: 0.0792 - mean_absolute_error: 0.1637 - val_loss: 0.1428 - val_mean_absolute_error: 0.1845\n",
      "Epoch 218/300\n",
      "203/203 [==============================] - 0s 766us/step - loss: 0.0828 - mean_absolute_error: 0.1649 - val_loss: 0.1568 - val_mean_absolute_error: 0.1948\n",
      "Epoch 219/300\n",
      "203/203 [==============================] - 0s 773us/step - loss: 0.0789 - mean_absolute_error: 0.1628 - val_loss: 0.1584 - val_mean_absolute_error: 0.1864\n",
      "Epoch 220/300\n",
      "203/203 [==============================] - 0s 755us/step - loss: 0.0768 - mean_absolute_error: 0.1623 - val_loss: 0.1389 - val_mean_absolute_error: 0.1867\n",
      "Epoch 221/300\n",
      "203/203 [==============================] - 0s 792us/step - loss: 0.0758 - mean_absolute_error: 0.1613 - val_loss: 0.1484 - val_mean_absolute_error: 0.1870\n",
      "Epoch 222/300\n",
      "203/203 [==============================] - 0s 762us/step - loss: 0.0786 - mean_absolute_error: 0.1619 - val_loss: 0.1580 - val_mean_absolute_error: 0.1995\n",
      "Epoch 223/300\n",
      "203/203 [==============================] - 0s 757us/step - loss: 0.0760 - mean_absolute_error: 0.1600 - val_loss: 0.1461 - val_mean_absolute_error: 0.1888\n",
      "Epoch 224/300\n",
      "203/203 [==============================] - 0s 805us/step - loss: 0.0763 - mean_absolute_error: 0.1613 - val_loss: 0.1428 - val_mean_absolute_error: 0.1843\n",
      "Epoch 225/300\n",
      "203/203 [==============================] - 0s 782us/step - loss: 0.0813 - mean_absolute_error: 0.1657 - val_loss: 0.1521 - val_mean_absolute_error: 0.2015\n",
      "Epoch 226/300\n",
      "203/203 [==============================] - 0s 817us/step - loss: 0.0794 - mean_absolute_error: 0.1627 - val_loss: 0.1553 - val_mean_absolute_error: 0.1868\n",
      "Epoch 227/300\n",
      "203/203 [==============================] - 0s 776us/step - loss: 0.0765 - mean_absolute_error: 0.1611 - val_loss: 0.1388 - val_mean_absolute_error: 0.1859\n",
      "Epoch 228/300\n",
      "203/203 [==============================] - 0s 738us/step - loss: 0.0744 - mean_absolute_error: 0.1597 - val_loss: 0.1561 - val_mean_absolute_error: 0.1889\n",
      "Epoch 229/300\n",
      "203/203 [==============================] - 0s 752us/step - loss: 0.0755 - mean_absolute_error: 0.1597 - val_loss: 0.1393 - val_mean_absolute_error: 0.1877\n",
      "Epoch 230/300\n",
      "203/203 [==============================] - 0s 848us/step - loss: 0.0879 - mean_absolute_error: 0.1692 - val_loss: 0.1460 - val_mean_absolute_error: 0.1954\n",
      "Epoch 231/300\n",
      "203/203 [==============================] - 0s 955us/step - loss: 0.0769 - mean_absolute_error: 0.1607 - val_loss: 0.1521 - val_mean_absolute_error: 0.1910\n",
      "Epoch 232/300\n",
      "203/203 [==============================] - 0s 900us/step - loss: 0.0748 - mean_absolute_error: 0.1600 - val_loss: 0.1390 - val_mean_absolute_error: 0.1852\n",
      "Epoch 233/300\n",
      "203/203 [==============================] - 0s 831us/step - loss: 0.0758 - mean_absolute_error: 0.1612 - val_loss: 0.1451 - val_mean_absolute_error: 0.1855\n",
      "Epoch 234/300\n",
      "203/203 [==============================] - 0s 887us/step - loss: 0.0745 - mean_absolute_error: 0.1595 - val_loss: 0.1450 - val_mean_absolute_error: 0.1897\n",
      "Epoch 235/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.0735 - mean_absolute_error: 0.1587 - val_loss: 0.1347 - val_mean_absolute_error: 0.1867\n",
      "Epoch 236/300\n",
      "203/203 [==============================] - 0s 981us/step - loss: 0.0775 - mean_absolute_error: 0.1618 - val_loss: 0.1465 - val_mean_absolute_error: 0.1909\n",
      "Epoch 237/300\n",
      "203/203 [==============================] - 0s 790us/step - loss: 0.0750 - mean_absolute_error: 0.1601 - val_loss: 0.1440 - val_mean_absolute_error: 0.1861\n",
      "Epoch 238/300\n",
      "203/203 [==============================] - 0s 806us/step - loss: 0.0739 - mean_absolute_error: 0.1592 - val_loss: 0.1398 - val_mean_absolute_error: 0.1877\n",
      "Epoch 239/300\n",
      "203/203 [==============================] - 0s 903us/step - loss: 0.0758 - mean_absolute_error: 0.1607 - val_loss: 0.1461 - val_mean_absolute_error: 0.1903\n",
      "Epoch 240/300\n",
      "203/203 [==============================] - 0s 941us/step - loss: 0.0808 - mean_absolute_error: 0.1660 - val_loss: 0.1495 - val_mean_absolute_error: 0.1934\n",
      "Epoch 241/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 0s 784us/step - loss: 0.0760 - mean_absolute_error: 0.1620 - val_loss: 0.1442 - val_mean_absolute_error: 0.1882\n",
      "Epoch 242/300\n",
      "203/203 [==============================] - 0s 754us/step - loss: 0.0735 - mean_absolute_error: 0.1600 - val_loss: 0.1559 - val_mean_absolute_error: 0.1895\n",
      "Epoch 243/300\n",
      "203/203 [==============================] - 0s 814us/step - loss: 0.0791 - mean_absolute_error: 0.1643 - val_loss: 0.1461 - val_mean_absolute_error: 0.1931\n",
      "Epoch 244/300\n",
      "203/203 [==============================] - 0s 902us/step - loss: 0.0761 - mean_absolute_error: 0.1608 - val_loss: 0.1438 - val_mean_absolute_error: 0.1897\n",
      "Epoch 245/300\n",
      "203/203 [==============================] - 0s 981us/step - loss: 0.0764 - mean_absolute_error: 0.1613 - val_loss: 0.1454 - val_mean_absolute_error: 0.1901\n",
      "Epoch 246/300\n",
      "203/203 [==============================] - 0s 786us/step - loss: 0.0785 - mean_absolute_error: 0.1632 - val_loss: 0.1449 - val_mean_absolute_error: 0.1881\n",
      "Epoch 247/300\n",
      "203/203 [==============================] - 0s 764us/step - loss: 0.0759 - mean_absolute_error: 0.1611 - val_loss: 0.1437 - val_mean_absolute_error: 0.1882\n",
      "Epoch 248/300\n",
      "203/203 [==============================] - 0s 727us/step - loss: 0.0755 - mean_absolute_error: 0.1603 - val_loss: 0.1637 - val_mean_absolute_error: 0.1915\n",
      "Epoch 249/300\n",
      "203/203 [==============================] - 0s 759us/step - loss: 0.0791 - mean_absolute_error: 0.1631 - val_loss: 0.1421 - val_mean_absolute_error: 0.1882\n",
      "Epoch 250/300\n",
      "203/203 [==============================] - 0s 788us/step - loss: 0.0740 - mean_absolute_error: 0.1590 - val_loss: 0.1347 - val_mean_absolute_error: 0.1868\n",
      "Epoch 251/300\n",
      "203/203 [==============================] - 0s 735us/step - loss: 0.0765 - mean_absolute_error: 0.1608 - val_loss: 0.1483 - val_mean_absolute_error: 0.1852\n",
      "Epoch 252/300\n",
      "203/203 [==============================] - 0s 880us/step - loss: 0.0812 - mean_absolute_error: 0.1656 - val_loss: 0.1363 - val_mean_absolute_error: 0.1997\n",
      "Epoch 253/300\n",
      "203/203 [==============================] - 0s 905us/step - loss: 0.0784 - mean_absolute_error: 0.1632 - val_loss: 0.1459 - val_mean_absolute_error: 0.1894\n",
      "Epoch 254/300\n",
      "203/203 [==============================] - 0s 854us/step - loss: 0.0762 - mean_absolute_error: 0.1603 - val_loss: 0.1470 - val_mean_absolute_error: 0.1898\n",
      "Epoch 255/300\n",
      "203/203 [==============================] - 0s 853us/step - loss: 0.0822 - mean_absolute_error: 0.1657 - val_loss: 0.1439 - val_mean_absolute_error: 0.2009\n",
      "Epoch 256/300\n",
      "203/203 [==============================] - 0s 857us/step - loss: 0.0748 - mean_absolute_error: 0.1601 - val_loss: 0.1427 - val_mean_absolute_error: 0.1883\n",
      "Epoch 257/300\n",
      "203/203 [==============================] - 0s 758us/step - loss: 0.0730 - mean_absolute_error: 0.1583 - val_loss: 0.1440 - val_mean_absolute_error: 0.1874\n",
      "Epoch 258/300\n",
      "203/203 [==============================] - 0s 748us/step - loss: 0.0749 - mean_absolute_error: 0.1602 - val_loss: 0.1499 - val_mean_absolute_error: 0.1868\n",
      "Epoch 259/300\n",
      "203/203 [==============================] - 0s 772us/step - loss: 0.0740 - mean_absolute_error: 0.1597 - val_loss: 0.1377 - val_mean_absolute_error: 0.1878\n",
      "Epoch 260/300\n",
      "203/203 [==============================] - 0s 740us/step - loss: 0.0713 - mean_absolute_error: 0.1575 - val_loss: 0.1441 - val_mean_absolute_error: 0.1857\n",
      "Epoch 261/300\n",
      "203/203 [==============================] - 0s 746us/step - loss: 0.0757 - mean_absolute_error: 0.1599 - val_loss: 0.1419 - val_mean_absolute_error: 0.1918\n",
      "Epoch 262/300\n",
      "203/203 [==============================] - 0s 751us/step - loss: 0.0762 - mean_absolute_error: 0.1627 - val_loss: 0.1462 - val_mean_absolute_error: 0.1923\n",
      "Epoch 263/300\n",
      "203/203 [==============================] - 0s 736us/step - loss: 0.0750 - mean_absolute_error: 0.1612 - val_loss: 0.1448 - val_mean_absolute_error: 0.1920\n",
      "Epoch 264/300\n",
      "203/203 [==============================] - 0s 755us/step - loss: 0.0781 - mean_absolute_error: 0.1613 - val_loss: 0.1323 - val_mean_absolute_error: 0.1867\n",
      "Epoch 265/300\n",
      "203/203 [==============================] - 0s 745us/step - loss: 0.0830 - mean_absolute_error: 0.1637 - val_loss: 0.1406 - val_mean_absolute_error: 0.1916\n",
      "Epoch 266/300\n",
      "203/203 [==============================] - 0s 746us/step - loss: 0.0788 - mean_absolute_error: 0.1628 - val_loss: 0.1370 - val_mean_absolute_error: 0.1929\n",
      "Epoch 267/300\n",
      "203/203 [==============================] - 0s 870us/step - loss: 0.0756 - mean_absolute_error: 0.1604 - val_loss: 0.1266 - val_mean_absolute_error: 0.1811\n",
      "Epoch 268/300\n",
      "203/203 [==============================] - 0s 760us/step - loss: 0.0720 - mean_absolute_error: 0.1573 - val_loss: 0.1368 - val_mean_absolute_error: 0.1828\n",
      "Epoch 269/300\n",
      "203/203 [==============================] - 0s 752us/step - loss: 0.0748 - mean_absolute_error: 0.1596 - val_loss: 0.1475 - val_mean_absolute_error: 0.1883\n",
      "Epoch 270/300\n",
      "203/203 [==============================] - 0s 953us/step - loss: 0.0724 - mean_absolute_error: 0.1578 - val_loss: 0.1470 - val_mean_absolute_error: 0.1934\n",
      "Epoch 271/300\n",
      "203/203 [==============================] - 0s 970us/step - loss: 0.0740 - mean_absolute_error: 0.1598 - val_loss: 0.1457 - val_mean_absolute_error: 0.1876\n",
      "Epoch 272/300\n",
      "203/203 [==============================] - 0s 939us/step - loss: 0.0726 - mean_absolute_error: 0.1579 - val_loss: 0.1511 - val_mean_absolute_error: 0.1963\n",
      "Epoch 273/300\n",
      "203/203 [==============================] - 0s 869us/step - loss: 0.0750 - mean_absolute_error: 0.1602 - val_loss: 0.1423 - val_mean_absolute_error: 0.1929\n",
      "Epoch 274/300\n",
      "203/203 [==============================] - 0s 765us/step - loss: 0.0744 - mean_absolute_error: 0.1592 - val_loss: 0.1359 - val_mean_absolute_error: 0.1827\n",
      "Epoch 275/300\n",
      "203/203 [==============================] - 0s 744us/step - loss: 0.0742 - mean_absolute_error: 0.1596 - val_loss: 0.1353 - val_mean_absolute_error: 0.1869\n",
      "Epoch 276/300\n",
      "203/203 [==============================] - 0s 954us/step - loss: 0.0746 - mean_absolute_error: 0.1593 - val_loss: 0.1476 - val_mean_absolute_error: 0.1921\n",
      "Epoch 277/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.0727 - mean_absolute_error: 0.1585 - val_loss: 0.1375 - val_mean_absolute_error: 0.1846\n",
      "Epoch 278/300\n",
      "203/203 [==============================] - 0s 913us/step - loss: 0.0717 - mean_absolute_error: 0.1585 - val_loss: 0.1392 - val_mean_absolute_error: 0.1880\n",
      "Epoch 279/300\n",
      "203/203 [==============================] - 0s 862us/step - loss: 0.0781 - mean_absolute_error: 0.1633 - val_loss: 0.1474 - val_mean_absolute_error: 0.1896\n",
      "Epoch 280/300\n",
      "203/203 [==============================] - 0s 880us/step - loss: 0.0759 - mean_absolute_error: 0.1621 - val_loss: 0.1279 - val_mean_absolute_error: 0.1888\n",
      "Epoch 281/300\n",
      "203/203 [==============================] - 0s 819us/step - loss: 0.0730 - mean_absolute_error: 0.1588 - val_loss: 0.1511 - val_mean_absolute_error: 0.1891\n",
      "Epoch 282/300\n",
      "203/203 [==============================] - 0s 869us/step - loss: 0.0708 - mean_absolute_error: 0.1565 - val_loss: 0.1512 - val_mean_absolute_error: 0.1879\n",
      "Epoch 283/300\n",
      "203/203 [==============================] - 0s 845us/step - loss: 0.0731 - mean_absolute_error: 0.1583 - val_loss: 0.1388 - val_mean_absolute_error: 0.1845\n",
      "Epoch 284/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.0726 - mean_absolute_error: 0.1579 - val_loss: 0.1472 - val_mean_absolute_error: 0.1909\n",
      "Epoch 285/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.0784 - mean_absolute_error: 0.1627 - val_loss: 0.1380 - val_mean_absolute_error: 0.1967\n",
      "Epoch 286/300\n",
      "203/203 [==============================] - 0s 957us/step - loss: 0.0779 - mean_absolute_error: 0.1608 - val_loss: 0.1576 - val_mean_absolute_error: 0.1926\n",
      "Epoch 287/300\n",
      "203/203 [==============================] - 0s 940us/step - loss: 0.0794 - mean_absolute_error: 0.1641 - val_loss: 0.1353 - val_mean_absolute_error: 0.1835\n",
      "Epoch 288/300\n",
      "203/203 [==============================] - 0s 934us/step - loss: 0.0713 - mean_absolute_error: 0.1578 - val_loss: 0.1587 - val_mean_absolute_error: 0.1947\n",
      "Epoch 289/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 0s 899us/step - loss: 0.0719 - mean_absolute_error: 0.1577 - val_loss: 0.1393 - val_mean_absolute_error: 0.1873\n",
      "Epoch 290/300\n",
      "203/203 [==============================] - 0s 785us/step - loss: 0.0702 - mean_absolute_error: 0.1561 - val_loss: 0.1344 - val_mean_absolute_error: 0.1850\n",
      "Epoch 291/300\n",
      "203/203 [==============================] - 0s 874us/step - loss: 0.0726 - mean_absolute_error: 0.1576 - val_loss: 0.1555 - val_mean_absolute_error: 0.1914\n",
      "Epoch 292/300\n",
      "203/203 [==============================] - 0s 861us/step - loss: 0.0764 - mean_absolute_error: 0.1612 - val_loss: 0.1438 - val_mean_absolute_error: 0.1896\n",
      "Epoch 293/300\n",
      "203/203 [==============================] - 0s 861us/step - loss: 0.0748 - mean_absolute_error: 0.1602 - val_loss: 0.1465 - val_mean_absolute_error: 0.1905\n",
      "Epoch 294/300\n",
      "203/203 [==============================] - 0s 816us/step - loss: 0.0782 - mean_absolute_error: 0.1622 - val_loss: 0.1401 - val_mean_absolute_error: 0.1934\n",
      "Epoch 295/300\n",
      "203/203 [==============================] - 0s 926us/step - loss: 0.0754 - mean_absolute_error: 0.1601 - val_loss: 0.1457 - val_mean_absolute_error: 0.1882\n",
      "Epoch 296/300\n",
      "203/203 [==============================] - 0s 865us/step - loss: 0.0710 - mean_absolute_error: 0.1562 - val_loss: 0.1505 - val_mean_absolute_error: 0.1894\n",
      "Epoch 297/300\n",
      "203/203 [==============================] - 0s 933us/step - loss: 0.0714 - mean_absolute_error: 0.1581 - val_loss: 0.1341 - val_mean_absolute_error: 0.1861\n",
      "Epoch 298/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.0712 - mean_absolute_error: 0.1568 - val_loss: 0.1454 - val_mean_absolute_error: 0.1943\n",
      "Epoch 299/300\n",
      "203/203 [==============================] - 0s 953us/step - loss: 0.0707 - mean_absolute_error: 0.1566 - val_loss: 0.1398 - val_mean_absolute_error: 0.1865\n",
      "Epoch 300/300\n",
      "203/203 [==============================] - 0s 949us/step - loss: 0.0734 - mean_absolute_error: 0.1592 - val_loss: 0.1436 - val_mean_absolute_error: 0.1910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f495d58e88>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3 = keras.Sequential(name='model-3')\n",
    "model_3.add(layers.Dense(64, \n",
    "                         kernel_regularizer=keras.regularizers.l2(0.001), \n",
    "                         activation='relu', input_shape=(21,)))\n",
    "model_3.add(layers.Dense(64, kernel_regularizer=keras.regularizers.l2(0.001), activation='relu'))\n",
    "model_3.add(layers.Dense(1))\n",
    "\n",
    "model_3.compile(keras.optimizers.Adam(0.001),\n",
    "                loss=keras.losses.MeanSquaredError(),\n",
    "                metrics=[keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "log_dir = os.path.join('lab2-logs', 'model-3')\n",
    "model_cbk = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "model_mckp = keras.callbacks.ModelCheckpoint(model_dir + '/Best-model-3.h5', \n",
    "                                             monitor='val_mean_absolute_error', \n",
    "                                             save_best_only=True, \n",
    "                                             mode='min')\n",
    "model_3.fit(x_train, y_train, \n",
    "            batch_size=64 ,\n",
    "            epochs=300, \n",
    "            validation_data=(x_val, y_val), \n",
    "            callbacks=[model_cbk, model_mckp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加入 Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "  2/203 [..............................] - ETA: 42s - loss: 6.0565 - mean_absolute_error: 1.0708WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.4209s). Check your callbacks.\n",
      "203/203 [==============================] - 1s 4ms/step - loss: 0.6047 - mean_absolute_error: 0.4804 - val_loss: 0.2399 - val_mean_absolute_error: 0.3009\n",
      "Epoch 2/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.3597 - mean_absolute_error: 0.3696 - val_loss: 0.2132 - val_mean_absolute_error: 0.2881\n",
      "Epoch 3/300\n",
      "203/203 [==============================] - ETA: 0s - loss: 0.3092 - mean_absolute_error: 0.340 - 0s 1ms/step - loss: 0.3002 - mean_absolute_error: 0.3405 - val_loss: 0.2016 - val_mean_absolute_error: 0.2784\n",
      "Epoch 4/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.2757 - mean_absolute_error: 0.3260 - val_loss: 0.1850 - val_mean_absolute_error: 0.2657\n",
      "Epoch 5/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.2780 - mean_absolute_error: 0.3191 - val_loss: 0.1871 - val_mean_absolute_error: 0.2673\n",
      "Epoch 6/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.2348 - mean_absolute_error: 0.3039 - val_loss: 0.1728 - val_mean_absolute_error: 0.2608\n",
      "Epoch 7/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.2413 - mean_absolute_error: 0.2993 - val_loss: 0.1886 - val_mean_absolute_error: 0.2710\n",
      "Epoch 8/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.2363 - mean_absolute_error: 0.2953 - val_loss: 0.2077 - val_mean_absolute_error: 0.2726\n",
      "Epoch 9/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.2132 - mean_absolute_error: 0.2860 - val_loss: 0.1596 - val_mean_absolute_error: 0.2555\n",
      "Epoch 10/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.2018 - mean_absolute_error: 0.2807 - val_loss: 0.1510 - val_mean_absolute_error: 0.2464\n",
      "Epoch 11/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1990 - mean_absolute_error: 0.2797 - val_loss: 0.1623 - val_mean_absolute_error: 0.2495\n",
      "Epoch 12/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.2026 - mean_absolute_error: 0.2781 - val_loss: 0.1617 - val_mean_absolute_error: 0.2491\n",
      "Epoch 13/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1959 - mean_absolute_error: 0.2756 - val_loss: 0.1496 - val_mean_absolute_error: 0.2350\n",
      "Epoch 14/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1799 - mean_absolute_error: 0.2703 - val_loss: 0.1458 - val_mean_absolute_error: 0.2378\n",
      "Epoch 15/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1850 - mean_absolute_error: 0.2690 - val_loss: 0.1445 - val_mean_absolute_error: 0.2343\n",
      "Epoch 16/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1790 - mean_absolute_error: 0.2677 - val_loss: 0.1427 - val_mean_absolute_error: 0.2332\n",
      "Epoch 17/300\n",
      "203/203 [==============================] - 0s 967us/step - loss: 0.1802 - mean_absolute_error: 0.2662 - val_loss: 0.1483 - val_mean_absolute_error: 0.2337\n",
      "Epoch 18/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1809 - mean_absolute_error: 0.2631 - val_loss: 0.1432 - val_mean_absolute_error: 0.2353\n",
      "Epoch 19/300\n",
      "203/203 [==============================] - 0s 999us/step - loss: 0.1842 - mean_absolute_error: 0.2644 - val_loss: 0.1813 - val_mean_absolute_error: 0.2558\n",
      "Epoch 20/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1795 - mean_absolute_error: 0.2627 - val_loss: 0.1404 - val_mean_absolute_error: 0.2303\n",
      "Epoch 21/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1828 - mean_absolute_error: 0.2628 - val_loss: 0.1462 - val_mean_absolute_error: 0.2381\n",
      "Epoch 22/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1743 - mean_absolute_error: 0.2596 - val_loss: 0.1558 - val_mean_absolute_error: 0.2415\n",
      "Epoch 23/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1797 - mean_absolute_error: 0.2593 - val_loss: 0.1345 - val_mean_absolute_error: 0.2277\n",
      "Epoch 24/300\n",
      "203/203 [==============================] - 0s 984us/step - loss: 0.1769 - mean_absolute_error: 0.2569 - val_loss: 0.1391 - val_mean_absolute_error: 0.2339\n",
      "Epoch 25/300\n",
      "203/203 [==============================] - 0s 958us/step - loss: 0.1796 - mean_absolute_error: 0.2583 - val_loss: 0.1356 - val_mean_absolute_error: 0.2347\n",
      "Epoch 26/300\n",
      "203/203 [==============================] - 0s 960us/step - loss: 0.1674 - mean_absolute_error: 0.2535 - val_loss: 0.1398 - val_mean_absolute_error: 0.2360\n",
      "Epoch 27/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1651 - mean_absolute_error: 0.2532 - val_loss: 0.1287 - val_mean_absolute_error: 0.2187\n",
      "Epoch 28/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1660 - mean_absolute_error: 0.2525 - val_loss: 0.1255 - val_mean_absolute_error: 0.2152\n",
      "Epoch 29/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1555 - mean_absolute_error: 0.2510 - val_loss: 0.1419 - val_mean_absolute_error: 0.2229\n",
      "Epoch 30/300\n",
      "203/203 [==============================] - 0s 958us/step - loss: 0.1598 - mean_absolute_error: 0.2485 - val_loss: 0.1227 - val_mean_absolute_error: 0.2163\n",
      "Epoch 31/300\n",
      "203/203 [==============================] - 0s 960us/step - loss: 0.1604 - mean_absolute_error: 0.2503 - val_loss: 0.1289 - val_mean_absolute_error: 0.2190\n",
      "Epoch 32/300\n",
      "203/203 [==============================] - 0s 962us/step - loss: 0.1594 - mean_absolute_error: 0.2483 - val_loss: 0.1416 - val_mean_absolute_error: 0.2199\n",
      "Epoch 33/300\n",
      "203/203 [==============================] - 0s 974us/step - loss: 0.1509 - mean_absolute_error: 0.2460 - val_loss: 0.1269 - val_mean_absolute_error: 0.2191\n",
      "Epoch 34/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1493 - mean_absolute_error: 0.2435 - val_loss: 0.1260 - val_mean_absolute_error: 0.2106\n",
      "Epoch 35/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1520 - mean_absolute_error: 0.2462 - val_loss: 0.1281 - val_mean_absolute_error: 0.2110\n",
      "Epoch 36/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1567 - mean_absolute_error: 0.2449 - val_loss: 0.1211 - val_mean_absolute_error: 0.2128\n",
      "Epoch 37/300\n",
      "203/203 [==============================] - 0s 988us/step - loss: 0.1706 - mean_absolute_error: 0.2481 - val_loss: 0.1388 - val_mean_absolute_error: 0.2259\n",
      "Epoch 38/300\n",
      "203/203 [==============================] - 0s 940us/step - loss: 0.1463 - mean_absolute_error: 0.2413 - val_loss: 0.1214 - val_mean_absolute_error: 0.2181\n",
      "Epoch 39/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1420 - mean_absolute_error: 0.2402 - val_loss: 0.1219 - val_mean_absolute_error: 0.2061\n",
      "Epoch 40/300\n",
      "203/203 [==============================] - 0s 991us/step - loss: 0.1438 - mean_absolute_error: 0.2412 - val_loss: 0.1181 - val_mean_absolute_error: 0.2132\n",
      "Epoch 41/300\n",
      "203/203 [==============================] - 0s 971us/step - loss: 0.1440 - mean_absolute_error: 0.2385 - val_loss: 0.1212 - val_mean_absolute_error: 0.2070\n",
      "Epoch 42/300\n",
      "203/203 [==============================] - 0s 993us/step - loss: 0.1428 - mean_absolute_error: 0.2400 - val_loss: 0.1191 - val_mean_absolute_error: 0.2130\n",
      "Epoch 43/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1356 - mean_absolute_error: 0.2375 - val_loss: 0.1215 - val_mean_absolute_error: 0.2100\n",
      "Epoch 44/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1478 - mean_absolute_error: 0.2387 - val_loss: 0.1416 - val_mean_absolute_error: 0.2186\n",
      "Epoch 45/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1415 - mean_absolute_error: 0.2365 - val_loss: 0.1160 - val_mean_absolute_error: 0.2062\n",
      "Epoch 46/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1358 - mean_absolute_error: 0.2361 - val_loss: 0.1184 - val_mean_absolute_error: 0.2174\n",
      "Epoch 47/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1358 - mean_absolute_error: 0.2350 - val_loss: 0.1302 - val_mean_absolute_error: 0.2109\n",
      "Epoch 48/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1386 - mean_absolute_error: 0.2361 - val_loss: 0.1202 - val_mean_absolute_error: 0.2095\n",
      "Epoch 49/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1448 - mean_absolute_error: 0.2378 - val_loss: 0.1310 - val_mean_absolute_error: 0.2258\n",
      "Epoch 50/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1455 - mean_absolute_error: 0.2368 - val_loss: 0.1268 - val_mean_absolute_error: 0.2162\n",
      "Epoch 51/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1408 - mean_absolute_error: 0.2353 - val_loss: 0.1347 - val_mean_absolute_error: 0.2081\n",
      "Epoch 52/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1454 - mean_absolute_error: 0.2362 - val_loss: 0.1272 - val_mean_absolute_error: 0.2100\n",
      "Epoch 53/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1365 - mean_absolute_error: 0.2351 - val_loss: 0.1153 - val_mean_absolute_error: 0.2021\n",
      "Epoch 54/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1482 - mean_absolute_error: 0.2354 - val_loss: 0.1192 - val_mean_absolute_error: 0.2154\n",
      "Epoch 55/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1414 - mean_absolute_error: 0.2340 - val_loss: 0.1202 - val_mean_absolute_error: 0.2085\n",
      "Epoch 56/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1338 - mean_absolute_error: 0.2335 - val_loss: 0.1182 - val_mean_absolute_error: 0.2169\n",
      "Epoch 57/300\n",
      "203/203 [==============================] - ETA: 0s - loss: 0.1428 - mean_absolute_error: 0.233 - 0s 1ms/step - loss: 0.1424 - mean_absolute_error: 0.2335 - val_loss: 0.1139 - val_mean_absolute_error: 0.2049\n",
      "Epoch 58/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1314 - mean_absolute_error: 0.2319 - val_loss: 0.1363 - val_mean_absolute_error: 0.2243\n",
      "Epoch 59/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1427 - mean_absolute_error: 0.2355 - val_loss: 0.1147 - val_mean_absolute_error: 0.2002\n",
      "Epoch 60/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1319 - mean_absolute_error: 0.2327 - val_loss: 0.1225 - val_mean_absolute_error: 0.2236\n",
      "Epoch 61/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1286 - mean_absolute_error: 0.2313 - val_loss: 0.1180 - val_mean_absolute_error: 0.2052\n",
      "Epoch 62/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1346 - mean_absolute_error: 0.2332 - val_loss: 0.1368 - val_mean_absolute_error: 0.2360\n",
      "Epoch 63/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1359 - mean_absolute_error: 0.2324 - val_loss: 0.1177 - val_mean_absolute_error: 0.2081\n",
      "Epoch 64/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1263 - mean_absolute_error: 0.2295 - val_loss: 0.1180 - val_mean_absolute_error: 0.2198\n",
      "Epoch 65/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1382 - mean_absolute_error: 0.2304 - val_loss: 0.1141 - val_mean_absolute_error: 0.2037\n",
      "Epoch 66/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1284 - mean_absolute_error: 0.2274 - val_loss: 0.1210 - val_mean_absolute_error: 0.2116\n",
      "Epoch 67/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1301 - mean_absolute_error: 0.2298 - val_loss: 0.1329 - val_mean_absolute_error: 0.2125\n",
      "Epoch 68/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1395 - mean_absolute_error: 0.2337 - val_loss: 0.1188 - val_mean_absolute_error: 0.2180\n",
      "Epoch 69/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1320 - mean_absolute_error: 0.2287 - val_loss: 0.1236 - val_mean_absolute_error: 0.2211\n",
      "Epoch 70/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1311 - mean_absolute_error: 0.2290 - val_loss: 0.1169 - val_mean_absolute_error: 0.2165\n",
      "Epoch 71/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1303 - mean_absolute_error: 0.2292 - val_loss: 0.1140 - val_mean_absolute_error: 0.2082\n",
      "Epoch 72/300\n",
      "203/203 [==============================] - ETA: 0s - loss: 0.1566 - mean_absolute_error: 0.234 - 0s 1ms/step - loss: 0.1464 - mean_absolute_error: 0.2319 - val_loss: 0.1152 - val_mean_absolute_error: 0.2081\n",
      "Epoch 73/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1329 - mean_absolute_error: 0.2301 - val_loss: 0.1146 - val_mean_absolute_error: 0.2150\n",
      "Epoch 74/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1451 - mean_absolute_error: 0.2334 - val_loss: 0.1112 - val_mean_absolute_error: 0.1988\n",
      "Epoch 75/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.1314 - mean_absolute_error: 0.2300 - val_loss: 0.1207 - val_mean_absolute_error: 0.2250\n",
      "Epoch 76/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.1296 - mean_absolute_error: 0.2298 - val_loss: 0.1117 - val_mean_absolute_error: 0.2028\n",
      "Epoch 77/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.1254 - mean_absolute_error: 0.2283 - val_loss: 0.1167 - val_mean_absolute_error: 0.2095\n",
      "Epoch 78/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1259 - mean_absolute_error: 0.2289 - val_loss: 0.1172 - val_mean_absolute_error: 0.2115\n",
      "Epoch 79/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1267 - mean_absolute_error: 0.2268 - val_loss: 0.1147 - val_mean_absolute_error: 0.2061\n",
      "Epoch 80/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1282 - mean_absolute_error: 0.2259 - val_loss: 0.1111 - val_mean_absolute_error: 0.2001\n",
      "Epoch 81/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1335 - mean_absolute_error: 0.2277 - val_loss: 0.1115 - val_mean_absolute_error: 0.2079\n",
      "Epoch 82/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1261 - mean_absolute_error: 0.2272 - val_loss: 0.1074 - val_mean_absolute_error: 0.2005\n",
      "Epoch 83/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1255 - mean_absolute_error: 0.2256 - val_loss: 0.1173 - val_mean_absolute_error: 0.2142\n",
      "Epoch 84/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.1250 - mean_absolute_error: 0.2256 - val_loss: 0.1207 - val_mean_absolute_error: 0.2109\n",
      "Epoch 85/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.1336 - mean_absolute_error: 0.2264 - val_loss: 0.1119 - val_mean_absolute_error: 0.2078\n",
      "Epoch 86/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1225 - mean_absolute_error: 0.2248 - val_loss: 0.1253 - val_mean_absolute_error: 0.2121\n",
      "Epoch 87/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1260 - mean_absolute_error: 0.2259 - val_loss: 0.1228 - val_mean_absolute_error: 0.2149\n",
      "Epoch 88/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1436 - mean_absolute_error: 0.2300 - val_loss: 0.1112 - val_mean_absolute_error: 0.2109\n",
      "Epoch 89/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1329 - mean_absolute_error: 0.2288 - val_loss: 0.1213 - val_mean_absolute_error: 0.2130\n",
      "Epoch 90/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1209 - mean_absolute_error: 0.2249 - val_loss: 0.1123 - val_mean_absolute_error: 0.2027\n",
      "Epoch 91/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1308 - mean_absolute_error: 0.2294 - val_loss: 0.1143 - val_mean_absolute_error: 0.2111\n",
      "Epoch 92/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1215 - mean_absolute_error: 0.2253 - val_loss: 0.1089 - val_mean_absolute_error: 0.1981\n",
      "Epoch 93/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1227 - mean_absolute_error: 0.2265 - val_loss: 0.1144 - val_mean_absolute_error: 0.2083\n",
      "Epoch 94/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1264 - mean_absolute_error: 0.2231 - val_loss: 0.1161 - val_mean_absolute_error: 0.2075\n",
      "Epoch 95/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1205 - mean_absolute_error: 0.2243 - val_loss: 0.1130 - val_mean_absolute_error: 0.2030\n",
      "Epoch 96/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1236 - mean_absolute_error: 0.2246 - val_loss: 0.1170 - val_mean_absolute_error: 0.2164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1273 - mean_absolute_error: 0.2282 - val_loss: 0.1236 - val_mean_absolute_error: 0.2206\n",
      "Epoch 98/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1282 - mean_absolute_error: 0.2269 - val_loss: 0.1122 - val_mean_absolute_error: 0.2063\n",
      "Epoch 99/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1173 - mean_absolute_error: 0.2232 - val_loss: 0.1135 - val_mean_absolute_error: 0.2021\n",
      "Epoch 100/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1140 - mean_absolute_error: 0.2209 - val_loss: 0.1211 - val_mean_absolute_error: 0.2139\n",
      "Epoch 101/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1247 - mean_absolute_error: 0.2225 - val_loss: 0.1171 - val_mean_absolute_error: 0.2051\n",
      "Epoch 102/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1200 - mean_absolute_error: 0.2234 - val_loss: 0.1252 - val_mean_absolute_error: 0.2147\n",
      "Epoch 103/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1241 - mean_absolute_error: 0.2243 - val_loss: 0.1221 - val_mean_absolute_error: 0.2139\n",
      "Epoch 104/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1240 - mean_absolute_error: 0.2243 - val_loss: 0.1212 - val_mean_absolute_error: 0.2042\n",
      "Epoch 105/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1188 - mean_absolute_error: 0.2212 - val_loss: 0.1179 - val_mean_absolute_error: 0.2111\n",
      "Epoch 106/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1203 - mean_absolute_error: 0.2222 - val_loss: 0.1152 - val_mean_absolute_error: 0.2063\n",
      "Epoch 107/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1206 - mean_absolute_error: 0.2247 - val_loss: 0.1169 - val_mean_absolute_error: 0.2154\n",
      "Epoch 108/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1161 - mean_absolute_error: 0.2218 - val_loss: 0.1132 - val_mean_absolute_error: 0.2028\n",
      "Epoch 109/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1221 - mean_absolute_error: 0.2235 - val_loss: 0.1159 - val_mean_absolute_error: 0.2102\n",
      "Epoch 110/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1216 - mean_absolute_error: 0.2223 - val_loss: 0.1210 - val_mean_absolute_error: 0.2145\n",
      "Epoch 111/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1256 - mean_absolute_error: 0.2246 - val_loss: 0.1131 - val_mean_absolute_error: 0.2030\n",
      "Epoch 112/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1305 - mean_absolute_error: 0.2239 - val_loss: 0.1226 - val_mean_absolute_error: 0.2152\n",
      "Epoch 113/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1258 - mean_absolute_error: 0.2238 - val_loss: 0.1211 - val_mean_absolute_error: 0.2130\n",
      "Epoch 114/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1195 - mean_absolute_error: 0.2236 - val_loss: 0.1102 - val_mean_absolute_error: 0.1937\n",
      "Epoch 115/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1203 - mean_absolute_error: 0.2238 - val_loss: 0.1203 - val_mean_absolute_error: 0.2135\n",
      "Epoch 116/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1193 - mean_absolute_error: 0.2217 - val_loss: 0.1241 - val_mean_absolute_error: 0.2228\n",
      "Epoch 117/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1224 - mean_absolute_error: 0.2226 - val_loss: 0.1199 - val_mean_absolute_error: 0.2142\n",
      "Epoch 118/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1232 - mean_absolute_error: 0.2224 - val_loss: 0.1177 - val_mean_absolute_error: 0.2105\n",
      "Epoch 119/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1265 - mean_absolute_error: 0.2240 - val_loss: 0.1181 - val_mean_absolute_error: 0.2104\n",
      "Epoch 120/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1185 - mean_absolute_error: 0.2200 - val_loss: 0.1206 - val_mean_absolute_error: 0.2187\n",
      "Epoch 121/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1146 - mean_absolute_error: 0.2198 - val_loss: 0.1253 - val_mean_absolute_error: 0.2083\n",
      "Epoch 122/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1272 - mean_absolute_error: 0.2236 - val_loss: 0.1280 - val_mean_absolute_error: 0.2198\n",
      "Epoch 123/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1199 - mean_absolute_error: 0.2191 - val_loss: 0.1229 - val_mean_absolute_error: 0.2081\n",
      "Epoch 124/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1242 - mean_absolute_error: 0.2239 - val_loss: 0.1161 - val_mean_absolute_error: 0.2042\n",
      "Epoch 125/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1176 - mean_absolute_error: 0.2205 - val_loss: 0.1169 - val_mean_absolute_error: 0.2064\n",
      "Epoch 126/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1239 - mean_absolute_error: 0.2219 - val_loss: 0.1317 - val_mean_absolute_error: 0.2106\n",
      "Epoch 127/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1214 - mean_absolute_error: 0.2229 - val_loss: 0.1177 - val_mean_absolute_error: 0.2048\n",
      "Epoch 128/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1130 - mean_absolute_error: 0.2196 - val_loss: 0.1178 - val_mean_absolute_error: 0.2159\n",
      "Epoch 129/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1210 - mean_absolute_error: 0.2249 - val_loss: 0.1151 - val_mean_absolute_error: 0.2082\n",
      "Epoch 130/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1253 - mean_absolute_error: 0.2250 - val_loss: 0.1223 - val_mean_absolute_error: 0.2136\n",
      "Epoch 131/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1207 - mean_absolute_error: 0.2214 - val_loss: 0.1178 - val_mean_absolute_error: 0.2056\n",
      "Epoch 132/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1161 - mean_absolute_error: 0.2208 - val_loss: 0.1244 - val_mean_absolute_error: 0.2144\n",
      "Epoch 133/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1238 - mean_absolute_error: 0.2238 - val_loss: 0.1225 - val_mean_absolute_error: 0.2074\n",
      "Epoch 134/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1180 - mean_absolute_error: 0.2218 - val_loss: 0.1218 - val_mean_absolute_error: 0.2123\n",
      "Epoch 135/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1137 - mean_absolute_error: 0.2205 - val_loss: 0.1236 - val_mean_absolute_error: 0.2152\n",
      "Epoch 136/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1115 - mean_absolute_error: 0.2190 - val_loss: 0.1111 - val_mean_absolute_error: 0.1971\n",
      "Epoch 137/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1154 - mean_absolute_error: 0.2185 - val_loss: 0.1146 - val_mean_absolute_error: 0.2001\n",
      "Epoch 138/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.1207 - mean_absolute_error: 0.2210 - val_loss: 0.1278 - val_mean_absolute_error: 0.2197\n",
      "Epoch 139/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1166 - mean_absolute_error: 0.2200 - val_loss: 0.1144 - val_mean_absolute_error: 0.2047\n",
      "Epoch 140/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1127 - mean_absolute_error: 0.2174 - val_loss: 0.1230 - val_mean_absolute_error: 0.2098\n",
      "Epoch 141/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1123 - mean_absolute_error: 0.2197 - val_loss: 0.1212 - val_mean_absolute_error: 0.2183\n",
      "Epoch 142/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1165 - mean_absolute_error: 0.2196 - val_loss: 0.1231 - val_mean_absolute_error: 0.2132\n",
      "Epoch 143/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1156 - mean_absolute_error: 0.2218 - val_loss: 0.1197 - val_mean_absolute_error: 0.2126\n",
      "Epoch 144/300\n",
      "203/203 [==============================] - 0s 995us/step - loss: 0.1248 - mean_absolute_error: 0.2236 - val_loss: 0.1276 - val_mean_absolute_error: 0.2217\n",
      "Epoch 145/300\n",
      "203/203 [==============================] - 0s 973us/step - loss: 0.1232 - mean_absolute_error: 0.2238 - val_loss: 0.1190 - val_mean_absolute_error: 0.2050\n",
      "Epoch 146/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 0s 969us/step - loss: 0.1234 - mean_absolute_error: 0.2194 - val_loss: 0.1191 - val_mean_absolute_error: 0.2059\n",
      "Epoch 147/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1199 - mean_absolute_error: 0.2219 - val_loss: 0.1250 - val_mean_absolute_error: 0.2126\n",
      "Epoch 148/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1164 - mean_absolute_error: 0.2213 - val_loss: 0.1182 - val_mean_absolute_error: 0.2121\n",
      "Epoch 149/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1101 - mean_absolute_error: 0.2178 - val_loss: 0.1196 - val_mean_absolute_error: 0.2190\n",
      "Epoch 150/300\n",
      "203/203 [==============================] - 0s 983us/step - loss: 0.1214 - mean_absolute_error: 0.2203 - val_loss: 0.1152 - val_mean_absolute_error: 0.2182\n",
      "Epoch 151/300\n",
      "203/203 [==============================] - 0s 960us/step - loss: 0.1297 - mean_absolute_error: 0.2220 - val_loss: 0.1273 - val_mean_absolute_error: 0.2065\n",
      "Epoch 152/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1206 - mean_absolute_error: 0.2211 - val_loss: 0.1175 - val_mean_absolute_error: 0.2006\n",
      "Epoch 153/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1264 - mean_absolute_error: 0.2223 - val_loss: 0.1164 - val_mean_absolute_error: 0.2027\n",
      "Epoch 154/300\n",
      "203/203 [==============================] - 0s 986us/step - loss: 0.1248 - mean_absolute_error: 0.2214 - val_loss: 0.1197 - val_mean_absolute_error: 0.2046\n",
      "Epoch 155/300\n",
      "203/203 [==============================] - 0s 971us/step - loss: 0.1194 - mean_absolute_error: 0.2201 - val_loss: 0.1222 - val_mean_absolute_error: 0.2161\n",
      "Epoch 156/300\n",
      "203/203 [==============================] - 0s 979us/step - loss: 0.1158 - mean_absolute_error: 0.2189 - val_loss: 0.1151 - val_mean_absolute_error: 0.2049\n",
      "Epoch 157/300\n",
      "203/203 [==============================] - 0s 970us/step - loss: 0.1187 - mean_absolute_error: 0.2197 - val_loss: 0.1095 - val_mean_absolute_error: 0.2087\n",
      "Epoch 158/300\n",
      "203/203 [==============================] - 0s 995us/step - loss: 0.1217 - mean_absolute_error: 0.2196 - val_loss: 0.1145 - val_mean_absolute_error: 0.2087\n",
      "Epoch 159/300\n",
      "203/203 [==============================] - 0s 971us/step - loss: 0.1174 - mean_absolute_error: 0.2184 - val_loss: 0.1398 - val_mean_absolute_error: 0.2189\n",
      "Epoch 160/300\n",
      "203/203 [==============================] - 0s 956us/step - loss: 0.1232 - mean_absolute_error: 0.2220 - val_loss: 0.1182 - val_mean_absolute_error: 0.2081\n",
      "Epoch 161/300\n",
      "203/203 [==============================] - 0s 979us/step - loss: 0.1165 - mean_absolute_error: 0.2186 - val_loss: 0.1253 - val_mean_absolute_error: 0.2160\n",
      "Epoch 162/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1151 - mean_absolute_error: 0.2189 - val_loss: 0.1319 - val_mean_absolute_error: 0.2182\n",
      "Epoch 163/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1136 - mean_absolute_error: 0.2188 - val_loss: 0.1244 - val_mean_absolute_error: 0.2234\n",
      "Epoch 164/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1127 - mean_absolute_error: 0.2157 - val_loss: 0.1236 - val_mean_absolute_error: 0.2262\n",
      "Epoch 165/300\n",
      "203/203 [==============================] - 0s 989us/step - loss: 0.1131 - mean_absolute_error: 0.2191 - val_loss: 0.1164 - val_mean_absolute_error: 0.2050\n",
      "Epoch 166/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1141 - mean_absolute_error: 0.2186 - val_loss: 0.1161 - val_mean_absolute_error: 0.2102\n",
      "Epoch 167/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1148 - mean_absolute_error: 0.2177 - val_loss: 0.1202 - val_mean_absolute_error: 0.2214\n",
      "Epoch 168/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1092 - mean_absolute_error: 0.2169 - val_loss: 0.1183 - val_mean_absolute_error: 0.2021\n",
      "Epoch 169/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1186 - mean_absolute_error: 0.2201 - val_loss: 0.1216 - val_mean_absolute_error: 0.2187\n",
      "Epoch 170/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1206 - mean_absolute_error: 0.2185 - val_loss: 0.1240 - val_mean_absolute_error: 0.2138\n",
      "Epoch 171/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1129 - mean_absolute_error: 0.2190 - val_loss: 0.1174 - val_mean_absolute_error: 0.2136\n",
      "Epoch 172/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1186 - mean_absolute_error: 0.2200 - val_loss: 0.1173 - val_mean_absolute_error: 0.2095\n",
      "Epoch 173/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1114 - mean_absolute_error: 0.2169 - val_loss: 0.1136 - val_mean_absolute_error: 0.1998\n",
      "Epoch 174/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1107 - mean_absolute_error: 0.2161 - val_loss: 0.1250 - val_mean_absolute_error: 0.2148\n",
      "Epoch 175/300\n",
      "203/203 [==============================] - 0s 993us/step - loss: 0.1162 - mean_absolute_error: 0.2186 - val_loss: 0.1234 - val_mean_absolute_error: 0.2193\n",
      "Epoch 176/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1180 - mean_absolute_error: 0.2175 - val_loss: 0.1408 - val_mean_absolute_error: 0.2250\n",
      "Epoch 177/300\n",
      "203/203 [==============================] - 0s 998us/step - loss: 0.1231 - mean_absolute_error: 0.2207 - val_loss: 0.1237 - val_mean_absolute_error: 0.2104\n",
      "Epoch 178/300\n",
      "203/203 [==============================] - 0s 969us/step - loss: 0.1089 - mean_absolute_error: 0.2157 - val_loss: 0.1278 - val_mean_absolute_error: 0.2179\n",
      "Epoch 179/300\n",
      "203/203 [==============================] - 0s 995us/step - loss: 0.1171 - mean_absolute_error: 0.2186 - val_loss: 0.1145 - val_mean_absolute_error: 0.2036\n",
      "Epoch 180/300\n",
      "203/203 [==============================] - 0s 964us/step - loss: 0.1081 - mean_absolute_error: 0.2157 - val_loss: 0.1155 - val_mean_absolute_error: 0.2118\n",
      "Epoch 181/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1117 - mean_absolute_error: 0.2162 - val_loss: 0.1165 - val_mean_absolute_error: 0.1937\n",
      "Epoch 182/300\n",
      "203/203 [==============================] - 0s 994us/step - loss: 0.1181 - mean_absolute_error: 0.2179 - val_loss: 0.1172 - val_mean_absolute_error: 0.2132\n",
      "Epoch 183/300\n",
      "203/203 [==============================] - 0s 989us/step - loss: 0.1224 - mean_absolute_error: 0.2223 - val_loss: 0.1148 - val_mean_absolute_error: 0.2108\n",
      "Epoch 184/300\n",
      "203/203 [==============================] - 0s 976us/step - loss: 0.1136 - mean_absolute_error: 0.2145 - val_loss: 0.1237 - val_mean_absolute_error: 0.2192\n",
      "Epoch 185/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1282 - mean_absolute_error: 0.2229 - val_loss: 0.1199 - val_mean_absolute_error: 0.2144\n",
      "Epoch 186/300\n",
      "203/203 [==============================] - 0s 987us/step - loss: 0.1151 - mean_absolute_error: 0.2181 - val_loss: 0.1168 - val_mean_absolute_error: 0.2047\n",
      "Epoch 187/300\n",
      "203/203 [==============================] - 0s 957us/step - loss: 0.1185 - mean_absolute_error: 0.2175 - val_loss: 0.1210 - val_mean_absolute_error: 0.2170\n",
      "Epoch 188/300\n",
      "203/203 [==============================] - 0s 981us/step - loss: 0.1097 - mean_absolute_error: 0.2154 - val_loss: 0.1176 - val_mean_absolute_error: 0.2022\n",
      "Epoch 189/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1169 - mean_absolute_error: 0.2177 - val_loss: 0.1316 - val_mean_absolute_error: 0.2188\n",
      "Epoch 190/300\n",
      "203/203 [==============================] - 0s 953us/step - loss: 0.1167 - mean_absolute_error: 0.2196 - val_loss: 0.1255 - val_mean_absolute_error: 0.2155\n",
      "Epoch 191/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1160 - mean_absolute_error: 0.2191 - val_loss: 0.1195 - val_mean_absolute_error: 0.2180\n",
      "Epoch 192/300\n",
      "203/203 [==============================] - 0s 971us/step - loss: 0.1144 - mean_absolute_error: 0.2176 - val_loss: 0.1220 - val_mean_absolute_error: 0.2166\n",
      "Epoch 193/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1166 - mean_absolute_error: 0.2176 - val_loss: 0.1156 - val_mean_absolute_error: 0.2051\n",
      "Epoch 194/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1191 - mean_absolute_error: 0.2190 - val_loss: 0.1163 - val_mean_absolute_error: 0.2058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 195/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1144 - mean_absolute_error: 0.2152 - val_loss: 0.1263 - val_mean_absolute_error: 0.2183\n",
      "Epoch 196/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1141 - mean_absolute_error: 0.2166 - val_loss: 0.1208 - val_mean_absolute_error: 0.2152\n",
      "Epoch 197/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1098 - mean_absolute_error: 0.2189 - val_loss: 0.1304 - val_mean_absolute_error: 0.2205\n",
      "Epoch 198/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1106 - mean_absolute_error: 0.2168 - val_loss: 0.1276 - val_mean_absolute_error: 0.2192\n",
      "Epoch 199/300\n",
      "203/203 [==============================] - 0s 973us/step - loss: 0.1093 - mean_absolute_error: 0.2160 - val_loss: 0.1152 - val_mean_absolute_error: 0.2126\n",
      "Epoch 200/300\n",
      "203/203 [==============================] - 0s 968us/step - loss: 0.1117 - mean_absolute_error: 0.2161 - val_loss: 0.1168 - val_mean_absolute_error: 0.2155\n",
      "Epoch 201/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1094 - mean_absolute_error: 0.2159 - val_loss: 0.1206 - val_mean_absolute_error: 0.2043\n",
      "Epoch 202/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1131 - mean_absolute_error: 0.2172 - val_loss: 0.1218 - val_mean_absolute_error: 0.2284\n",
      "Epoch 203/300\n",
      "203/203 [==============================] - 0s 968us/step - loss: 0.1109 - mean_absolute_error: 0.2162 - val_loss: 0.1186 - val_mean_absolute_error: 0.2060\n",
      "Epoch 204/300\n",
      "203/203 [==============================] - 0s 964us/step - loss: 0.1169 - mean_absolute_error: 0.2154 - val_loss: 0.1169 - val_mean_absolute_error: 0.2179\n",
      "Epoch 205/300\n",
      "203/203 [==============================] - 0s 984us/step - loss: 0.1150 - mean_absolute_error: 0.2181 - val_loss: 0.1099 - val_mean_absolute_error: 0.2097\n",
      "Epoch 206/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1127 - mean_absolute_error: 0.2163 - val_loss: 0.1190 - val_mean_absolute_error: 0.2143\n",
      "Epoch 207/300\n",
      "203/203 [==============================] - 0s 963us/step - loss: 0.1085 - mean_absolute_error: 0.2158 - val_loss: 0.1171 - val_mean_absolute_error: 0.2102\n",
      "Epoch 208/300\n",
      "203/203 [==============================] - 0s 965us/step - loss: 0.1092 - mean_absolute_error: 0.2148 - val_loss: 0.1213 - val_mean_absolute_error: 0.2236\n",
      "Epoch 209/300\n",
      "203/203 [==============================] - 0s 955us/step - loss: 0.1114 - mean_absolute_error: 0.2170 - val_loss: 0.1203 - val_mean_absolute_error: 0.2074\n",
      "Epoch 210/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1134 - mean_absolute_error: 0.2164 - val_loss: 0.1173 - val_mean_absolute_error: 0.2153\n",
      "Epoch 211/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1169 - mean_absolute_error: 0.2177 - val_loss: 0.1159 - val_mean_absolute_error: 0.2138\n",
      "Epoch 212/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1115 - mean_absolute_error: 0.2159 - val_loss: 0.1150 - val_mean_absolute_error: 0.2061\n",
      "Epoch 213/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1071 - mean_absolute_error: 0.2170 - val_loss: 0.1134 - val_mean_absolute_error: 0.2022\n",
      "Epoch 214/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1128 - mean_absolute_error: 0.2160 - val_loss: 0.1273 - val_mean_absolute_error: 0.2167\n",
      "Epoch 215/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1124 - mean_absolute_error: 0.2159 - val_loss: 0.1189 - val_mean_absolute_error: 0.2087\n",
      "Epoch 216/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1185 - mean_absolute_error: 0.2178 - val_loss: 0.1158 - val_mean_absolute_error: 0.2159\n",
      "Epoch 217/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1146 - mean_absolute_error: 0.2162 - val_loss: 0.1149 - val_mean_absolute_error: 0.2078\n",
      "Epoch 218/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1091 - mean_absolute_error: 0.2148 - val_loss: 0.1215 - val_mean_absolute_error: 0.2233\n",
      "Epoch 219/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1125 - mean_absolute_error: 0.2161 - val_loss: 0.1170 - val_mean_absolute_error: 0.2159\n",
      "Epoch 220/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1114 - mean_absolute_error: 0.2161 - val_loss: 0.1219 - val_mean_absolute_error: 0.2178\n",
      "Epoch 221/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1105 - mean_absolute_error: 0.2148 - val_loss: 0.1178 - val_mean_absolute_error: 0.2161\n",
      "Epoch 222/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1158 - mean_absolute_error: 0.2176 - val_loss: 0.1181 - val_mean_absolute_error: 0.2256\n",
      "Epoch 223/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1189 - mean_absolute_error: 0.2168 - val_loss: 0.1179 - val_mean_absolute_error: 0.2094\n",
      "Epoch 224/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1117 - mean_absolute_error: 0.2155 - val_loss: 0.1200 - val_mean_absolute_error: 0.2155\n",
      "Epoch 225/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1126 - mean_absolute_error: 0.2180 - val_loss: 0.1253 - val_mean_absolute_error: 0.2192\n",
      "Epoch 226/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1123 - mean_absolute_error: 0.2153 - val_loss: 0.1175 - val_mean_absolute_error: 0.2080\n",
      "Epoch 227/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1128 - mean_absolute_error: 0.2176 - val_loss: 0.1199 - val_mean_absolute_error: 0.2215\n",
      "Epoch 228/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1259 - mean_absolute_error: 0.2163 - val_loss: 0.1198 - val_mean_absolute_error: 0.2100\n",
      "Epoch 229/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1154 - mean_absolute_error: 0.2158 - val_loss: 0.1228 - val_mean_absolute_error: 0.2129\n",
      "Epoch 230/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1096 - mean_absolute_error: 0.2147 - val_loss: 0.1182 - val_mean_absolute_error: 0.2073\n",
      "Epoch 231/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1123 - mean_absolute_error: 0.2153 - val_loss: 0.1190 - val_mean_absolute_error: 0.2153\n",
      "Epoch 232/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1194 - mean_absolute_error: 0.2165 - val_loss: 0.1161 - val_mean_absolute_error: 0.2000\n",
      "Epoch 233/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1139 - mean_absolute_error: 0.2145 - val_loss: 0.1251 - val_mean_absolute_error: 0.2169\n",
      "Epoch 234/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1130 - mean_absolute_error: 0.2174 - val_loss: 0.1134 - val_mean_absolute_error: 0.2045\n",
      "Epoch 235/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1075 - mean_absolute_error: 0.2145 - val_loss: 0.1150 - val_mean_absolute_error: 0.1999\n",
      "Epoch 236/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1067 - mean_absolute_error: 0.2135 - val_loss: 0.1110 - val_mean_absolute_error: 0.2007\n",
      "Epoch 237/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1115 - mean_absolute_error: 0.2155 - val_loss: 0.1190 - val_mean_absolute_error: 0.2166\n",
      "Epoch 238/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1161 - mean_absolute_error: 0.2174 - val_loss: 0.1143 - val_mean_absolute_error: 0.2087\n",
      "Epoch 239/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1130 - mean_absolute_error: 0.2163 - val_loss: 0.1110 - val_mean_absolute_error: 0.2034\n",
      "Epoch 240/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1044 - mean_absolute_error: 0.2122 - val_loss: 0.1202 - val_mean_absolute_error: 0.2145\n",
      "Epoch 241/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1071 - mean_absolute_error: 0.2147 - val_loss: 0.1225 - val_mean_absolute_error: 0.2195\n",
      "Epoch 242/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1046 - mean_absolute_error: 0.2107 - val_loss: 0.1288 - val_mean_absolute_error: 0.2061\n",
      "Epoch 243/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1062 - mean_absolute_error: 0.2120 - val_loss: 0.1175 - val_mean_absolute_error: 0.2087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 244/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1126 - mean_absolute_error: 0.2135 - val_loss: 0.1154 - val_mean_absolute_error: 0.2097\n",
      "Epoch 245/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1064 - mean_absolute_error: 0.2133 - val_loss: 0.1175 - val_mean_absolute_error: 0.2087\n",
      "Epoch 246/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1114 - mean_absolute_error: 0.2138 - val_loss: 0.1185 - val_mean_absolute_error: 0.2174\n",
      "Epoch 247/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1100 - mean_absolute_error: 0.2125 - val_loss: 0.1167 - val_mean_absolute_error: 0.2175\n",
      "Epoch 248/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1084 - mean_absolute_error: 0.2132 - val_loss: 0.1132 - val_mean_absolute_error: 0.2057\n",
      "Epoch 249/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1188 - mean_absolute_error: 0.2187 - val_loss: 0.1206 - val_mean_absolute_error: 0.2163\n",
      "Epoch 250/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1062 - mean_absolute_error: 0.2141 - val_loss: 0.1198 - val_mean_absolute_error: 0.2194\n",
      "Epoch 251/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1106 - mean_absolute_error: 0.2150 - val_loss: 0.1185 - val_mean_absolute_error: 0.2224\n",
      "Epoch 252/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1168 - mean_absolute_error: 0.2176 - val_loss: 0.1248 - val_mean_absolute_error: 0.2227\n",
      "Epoch 253/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1152 - mean_absolute_error: 0.2154 - val_loss: 0.1166 - val_mean_absolute_error: 0.2133\n",
      "Epoch 254/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1110 - mean_absolute_error: 0.2175 - val_loss: 0.1130 - val_mean_absolute_error: 0.1977\n",
      "Epoch 255/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1133 - mean_absolute_error: 0.2166 - val_loss: 0.1134 - val_mean_absolute_error: 0.2049\n",
      "Epoch 256/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1134 - mean_absolute_error: 0.2146 - val_loss: 0.1149 - val_mean_absolute_error: 0.2121\n",
      "Epoch 257/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1103 - mean_absolute_error: 0.2136 - val_loss: 0.1168 - val_mean_absolute_error: 0.2157\n",
      "Epoch 258/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1060 - mean_absolute_error: 0.2138 - val_loss: 0.1211 - val_mean_absolute_error: 0.2164\n",
      "Epoch 259/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1101 - mean_absolute_error: 0.2126 - val_loss: 0.1229 - val_mean_absolute_error: 0.2169\n",
      "Epoch 260/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1090 - mean_absolute_error: 0.2150 - val_loss: 0.1276 - val_mean_absolute_error: 0.2191\n",
      "Epoch 261/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1092 - mean_absolute_error: 0.2136 - val_loss: 0.1213 - val_mean_absolute_error: 0.2081\n",
      "Epoch 262/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1108 - mean_absolute_error: 0.2152 - val_loss: 0.1251 - val_mean_absolute_error: 0.2243\n",
      "Epoch 263/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1069 - mean_absolute_error: 0.2142 - val_loss: 0.1111 - val_mean_absolute_error: 0.2004\n",
      "Epoch 264/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1059 - mean_absolute_error: 0.2137 - val_loss: 0.1201 - val_mean_absolute_error: 0.2135\n",
      "Epoch 265/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1021 - mean_absolute_error: 0.2120 - val_loss: 0.1204 - val_mean_absolute_error: 0.2159\n",
      "Epoch 266/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1095 - mean_absolute_error: 0.2143 - val_loss: 0.1266 - val_mean_absolute_error: 0.2200\n",
      "Epoch 267/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1045 - mean_absolute_error: 0.2118 - val_loss: 0.1168 - val_mean_absolute_error: 0.2105\n",
      "Epoch 268/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1019 - mean_absolute_error: 0.2120 - val_loss: 0.1141 - val_mean_absolute_error: 0.2064\n",
      "Epoch 269/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1078 - mean_absolute_error: 0.2132 - val_loss: 0.1176 - val_mean_absolute_error: 0.2135\n",
      "Epoch 270/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1066 - mean_absolute_error: 0.2125 - val_loss: 0.1084 - val_mean_absolute_error: 0.2039\n",
      "Epoch 271/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1132 - mean_absolute_error: 0.2146 - val_loss: 0.1179 - val_mean_absolute_error: 0.2200\n",
      "Epoch 272/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1024 - mean_absolute_error: 0.2106 - val_loss: 0.1240 - val_mean_absolute_error: 0.2078\n",
      "Epoch 273/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1132 - mean_absolute_error: 0.2130 - val_loss: 0.1140 - val_mean_absolute_error: 0.2133\n",
      "Epoch 274/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1036 - mean_absolute_error: 0.2111 - val_loss: 0.1152 - val_mean_absolute_error: 0.2113\n",
      "Epoch 275/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1029 - mean_absolute_error: 0.2129 - val_loss: 0.1116 - val_mean_absolute_error: 0.2065\n",
      "Epoch 276/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1106 - mean_absolute_error: 0.2130 - val_loss: 0.1130 - val_mean_absolute_error: 0.2070\n",
      "Epoch 277/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1218 - mean_absolute_error: 0.2152 - val_loss: 0.1180 - val_mean_absolute_error: 0.2257\n",
      "Epoch 278/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1083 - mean_absolute_error: 0.2140 - val_loss: 0.1103 - val_mean_absolute_error: 0.1976\n",
      "Epoch 279/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1135 - mean_absolute_error: 0.2141 - val_loss: 0.1202 - val_mean_absolute_error: 0.2207\n",
      "Epoch 280/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1131 - mean_absolute_error: 0.2158 - val_loss: 0.1116 - val_mean_absolute_error: 0.2164\n",
      "Epoch 281/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1054 - mean_absolute_error: 0.2125 - val_loss: 0.1188 - val_mean_absolute_error: 0.2137\n",
      "Epoch 282/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.1147 - mean_absolute_error: 0.2157 - val_loss: 0.1156 - val_mean_absolute_error: 0.2129\n",
      "Epoch 283/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1075 - mean_absolute_error: 0.2118 - val_loss: 0.1084 - val_mean_absolute_error: 0.2080\n",
      "Epoch 284/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1077 - mean_absolute_error: 0.2134 - val_loss: 0.1125 - val_mean_absolute_error: 0.2050\n",
      "Epoch 285/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1073 - mean_absolute_error: 0.2142 - val_loss: 0.1189 - val_mean_absolute_error: 0.2191\n",
      "Epoch 286/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1132 - mean_absolute_error: 0.2147 - val_loss: 0.1208 - val_mean_absolute_error: 0.2235\n",
      "Epoch 287/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1070 - mean_absolute_error: 0.2126 - val_loss: 0.1117 - val_mean_absolute_error: 0.2087\n",
      "Epoch 288/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1096 - mean_absolute_error: 0.2139 - val_loss: 0.1076 - val_mean_absolute_error: 0.2094\n",
      "Epoch 289/300\n",
      "203/203 [==============================] - 0s 2ms/step - loss: 0.1030 - mean_absolute_error: 0.2123 - val_loss: 0.1075 - val_mean_absolute_error: 0.2071\n",
      "Epoch 290/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1030 - mean_absolute_error: 0.2102 - val_loss: 0.1120 - val_mean_absolute_error: 0.2147\n",
      "Epoch 291/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1121 - mean_absolute_error: 0.2147 - val_loss: 0.1068 - val_mean_absolute_error: 0.1985\n",
      "Epoch 292/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1094 - mean_absolute_error: 0.2137 - val_loss: 0.1155 - val_mean_absolute_error: 0.2120\n",
      "Epoch 293/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1018 - mean_absolute_error: 0.2108 - val_loss: 0.1115 - val_mean_absolute_error: 0.2030\n",
      "Epoch 294/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1078 - mean_absolute_error: 0.2116 - val_loss: 0.1183 - val_mean_absolute_error: 0.2202\n",
      "Epoch 295/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1090 - mean_absolute_error: 0.2146 - val_loss: 0.1295 - val_mean_absolute_error: 0.2232\n",
      "Epoch 296/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1056 - mean_absolute_error: 0.2133 - val_loss: 0.1206 - val_mean_absolute_error: 0.2208\n",
      "Epoch 297/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1137 - mean_absolute_error: 0.2140 - val_loss: 0.1172 - val_mean_absolute_error: 0.2089\n",
      "Epoch 298/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1194 - mean_absolute_error: 0.2143 - val_loss: 0.1215 - val_mean_absolute_error: 0.2198\n",
      "Epoch 299/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.1039 - mean_absolute_error: 0.2120 - val_loss: 0.1139 - val_mean_absolute_error: 0.2077\n",
      "Epoch 300/300\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 0.0999 - mean_absolute_error: 0.2093 - val_loss: 0.1161 - val_mean_absolute_error: 0.2207\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f4916c1c48>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4 = keras.Sequential(name='model-4')\n",
    "model_4.add(layers.Dense(64, activation='relu', input_shape=(21,)))\n",
    "model_4.add(layers.Dropout(0.3))\n",
    "model_4.add(layers.Dense(64, activation='relu'))\n",
    "model_4.add(layers.Dropout(0.3))\n",
    "model_4.add(layers.Dense(1))\n",
    "\n",
    "model_4.compile(keras.optimizers.Adam(0.001),\n",
    "                loss=keras.losses.MeanSquaredError(),\n",
    "                metrics=[keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "log_dir = os.path.join('lab2-logs', 'model-4')\n",
    "model_cbk = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "model_mckp = keras.callbacks.ModelCheckpoint(model_dir + '/Best-model-4.h5', \n",
    "                                             monitor='val_mean_absolute_error', \n",
    "                                             save_best_only=True, \n",
    "                                             mode='min')\n",
    "model_4.fit(x_train, y_train, \n",
    "            batch_size=64 ,\n",
    "            epochs=300, \n",
    "            validation_data=(x_val, y_val), \n",
    "            callbacks=[model_cbk, model_mckp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 驗證正則化的效能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test model 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_2: 13.31%\n"
     ]
    }
   ],
   "source": [
    "model_2 = keras.models.load_model('lab2-logs/models/Best-model-2.h5')\n",
    "y_pred = model_2.predict(x_test)\n",
    "y_pred = np.reshape(y_pred * std['price'] + mean['price'], y_test.shape)\n",
    "percentage_error = np.mean(np.abs(y_test - y_pred)) / np.mean(y_test) * 100\n",
    "print(\"Model_2: {:.2f}%\".format(percentage_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test model 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_3: 12.86%\n"
     ]
    }
   ],
   "source": [
    "model_3 = keras.models.load_model('lab2-logs/models/Best-model-3.h5')\n",
    "y_pred = model_3.predict(x_test)\n",
    "y_pred = np.reshape(y_pred * std['price'] + mean['price'], y_test.shape)\n",
    "percentage_error = np.mean(np.abs(y_test - y_pred)) / np.mean(y_test) * 100\n",
    "print(\"Model_3: {:.2f}%\".format(percentage_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test model 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_4: 13.57%\n"
     ]
    }
   ],
   "source": [
    "model_4 = keras.models.load_model('lab2-logs/models/Best-model-4.h5')\n",
    "y_pred = model_4.predict(x_test)\n",
    "y_pred = np.reshape(y_pred * std['price'] + mean['price'], y_test.shape)\n",
    "percentage_error = np.mean(np.abs(y_test - y_pred)) / np.mean(y_test) * 100\n",
    "print(\"Model_4: {:.2f}%\".format(percentage_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
